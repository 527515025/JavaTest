#琐事概念
#Linux
##linux cgroup
Linux CGroup全称Linux Control Group， 是Linux内核的一个功能，用来限制，控制与分离一个进程组群的资源（如CPU、内存、磁盘输入输出等）

最早的名称为进程容器（process containers）。在2007年时，因为在Linux内核中，容器（container）这个名词太过广泛，为避免混乱，被重命名为cgroup，


##!/bin/sh 与 !/bin/bash
/bin/sh 与 /bin/bash 虽然大体上没什么区别, 但仍存在不同的标准. 标记为 “#!/bin/sh” 的脚本不应使用任何 POSIX 没有规定的特性 (如 let 等命令, 但 “#!/bin/bash” 可以). Debian 曾经采用 /bin/bash 更改 /bin/dash，目的使用更少的磁盘空间、提供较少的功能、获取更快的速度。但是后来经过 shell 脚本测试存在运行问题。因为原先在 bash shell 下可以运行的 shell script (shell 脚本)，在 /bin/sh 下还是会出现一些意想不到的问题，不是100%的兼用。

#java

##java 字符串判断
判断某字符串是否为空或长度为0或由空白符(whitespace)构成
下面是示例：

```
StringUtils.isBlank(null) = true
StringUtils.isBlank("") = true
StringUtils.isBlank(" ") = true
StringUtils.isBlank(" ") = true
StringUtils.isBlank("\t \n \f \r") = true //对于制表符、换行符、换页符和回车符StringUtils.isBlank()均识为空白符
StringUtils.isBlank("\b") = false //"\b"为单词边界符
StringUtils.isBlank("bob") = false
StringUtils.isBlank(" bob ") = false
```
2.public static boolean isEmpty(String str)
判断某字符串是否为空，为空的标准是str==null或str.length()==0
下面是StringUtils判断是否为空的示例：

```
StringUtils.isEmpty(null) = true
StringUtils.isEmpty("") = true
StringUtils.isEmpty(" ") = false //注意在StringUtils中空格作非空处理
StringUtils.isEmpty(" ") = false
StringUtils.isEmpty("bob") = false
StringUtils.isEmpty(" bob ") = false
```
##java8 interface 的默认方法与abstract class的非抽象方法的区别？
1.语法层面上的区别

　　1）抽象类可以提供成员方法的实现细节，而接口中只能存在public abstract 方法；

　　2）抽象类中的成员变量可以是各种类型的，而接口中的成员变量只能是public static final类型的；

　　3）接口中不能含有静态代码块以及静态方法，而抽象类可以有静态代码块和静态方法；

　　4）一个类只能继承一个抽象类，而一个类却可以实现多个接口。

2.设计层面上的区别

　　1）抽象类是对一种事物的抽象，即对类抽象，而接口是对行为的抽象。抽象类是对整个类整体进行抽象，包括属性、行为，但是接口却是对类局部（行为）进行抽象。举个简单的例子，飞机和鸟是不同类的事物，但是它们都有一个共性，就是都会飞。那么在设计的时候，可以将飞机设计为一个类Airplane，将鸟设计为一个类Bird，但是不能将 飞行 这个特性也设计为类，因此它只是一个行为特性，并不是对一类事物的抽象描述。此时可以将 飞行 设计为一个接口Fly，包含方法fly( )，然后Airplane和Bird分别根据自己的需要实现Fly这个接口。然后至于有不同种类的飞机，比如战斗机、民用飞机等直接继承Airplane即可，对于鸟也是类似的，不同种类的鸟直接继承Bird类即可。从这里可以看出，继承是一个 "是不是"的关系，而 接口 实现则是 "有没有"的关系。如果一个类继承了某个抽象类，则子类必定是抽象类的种类，而接口实现则是有没有、具备不具备的关系，比如鸟是否能飞（或者是否具备飞行这个特点），能飞行则可以实现这个接口，不能飞行就不实现这个接口。

　　2）设计层面不同，抽象类作为很多子类的父类，它是一种模板式设计。而接口是一种行为规范，它是一种辐射式设计。什么是模板式设计？最简单例子，大家都用过ppt里面的模板，如果用模板A设计了ppt B和ppt C，ppt B和ppt C公共的部分就是模板A了，如果它们的公共部分需要改动，则只需要改动模板A就可以了，不需要重新对ppt B和ppt C进行改动。而辐射式设计，比如某个电梯都装了某种报警器，一旦要更新报警器，就必须全部更新。也就是说对于抽象类，如果需要添加新的方法，可以直接在抽象类中添加具体的实现，子类可以不进行变更；而对于接口则不行，如果接口进行了变更，则所有实现这个接口的类都必须进行相应的改动。
　　
　　
##java 对象的序列化和反序列化
 对象序列化可以将一个对象保存到一个文件，可以将通过流的方式在网络上传输，可以将文件的内容读取转化为一个对象。所谓对象流也就是将对象的内容流化，可以对流化后的对象进行读写操作，也可将流化后的对象传输于网络之间。序列化是为了解决在对象流进行读写操作时引发的问题。

   序列化的实现：将需要被序列化的类实现serializable接口，该接口没有需要实现的方法，implements Serializable只是为了标注该对象是可被序列化的，然后使用一个输出流（如FileOutputStream)来构造一个ObjectOutputStream（对象流）对象，接着使用ObjectOutputStream对象的writeObject（Object obj）方法就可以将参数obj的对象写出，要恢复的话则用输入流。


##jvm内存
* JDK1.7后，常量池被放入到堆空间中。方法，变量是放在栈里面的。
* 从栈内存里面去数据要快一些。
* JVM有两类存储区：常量缓冲池和方法区
* 常量缓冲池用于存储类名称、方法和字段名称以及字符串常量。
方法区则用于存储Java方法的字节码。

# jvm 的堆、栈、方法区
https://www.cnblogs.com/andy-zhou/p/5327288.html
https://www.cnblogs.com/woshimrf/p/jvm-garbage.html
http://hoyouly.top/2018/04/08/jvm/
https://blog.csdn.net/qq_31337311/article/details/78799262
https://blog.csdn.net/u012998254/article/details/81428621
###0、栈是运行时单位，而堆是存储的单位。

栈解决程序的运行问题，即程序如何执行，或者说如何处理数据；堆解决的是数据存储的问题，即数据怎么放、放在哪儿。

在Java中一个线程就会相应有一个线程栈与之对应，这点很容易理解，因为不同的线程执行逻辑有所不同，因此需要一个独立的线程栈。而堆则是所有线程共享的。栈因为是运行单位，因此里面存储的信息都是跟当前线程（或程序）相关信息的。包括局部变量、程序运行状态、方法返回值等等；而堆只负责存储对象信息。
### 1、java中的栈（stack）和堆（heap）是java在内存（ram）中存放数据的地方

* （1）当程序运行时，首先通过类装载器加载字节码文件，经过解析后装入方法区！在方法区中存了类的各种信息，包括类变量、常量及方法。对于同一个方法的调用，同一个类的不同实例调用的都是存在方法区的同一个方法。类变量的生命周期从程序开始运行时创建，到程序终止运行时结束！ 
* （2）当程序中new一个对象时，这个对象存在堆中，对象的变量存在栈中，指向堆中的引用！对象的成员变量都存在堆中，当对象被回收时，对象的成员变量随之消失！ 
* （3）当方法调用时，JVM会在栈中分配一个栈桢，存储方法的局部变量。当方法调用结束时，局部变量消失！

###2、堆中存什么？栈中存什么？

堆中存的是对象。栈中存的是基本数据类型和堆中对象的引用。一个对象的大小是不可估计的，或者说是可以动态变化的，但是在栈中，一个对象只对应了一个4btye的引用（堆栈分离的好处：））。

为什么不把基本类型放堆中呢？因为其占用的空间一般是1~8个字节——需要空间比较少，而且因为是基本类型，所以不会出现动态增长的情况——长度固定，因此栈中存储就够了，如果把他存在堆中是没有什么意义的（还会浪费空间，后面说明）。可以这么说，基本类型和对象的引用都是存放在栈中，而且都是几个字节的一个数，因此在程序运行时，他们的处理方式是统一的。但是基本类型、对象引用和对象本身就有所区别了，因为一个是栈中的数据一个是堆中的数据。最常见的一个问题就是，Java中参数传递时的问题。

对象的属性其实就是数据，存放在堆中；而对象的行为（方法），就是运行逻辑，放在栈中。

### 3、堆区  对象、成员变量

* 存储的全部是对象，每个对象都包含一个与之对应的class的信息.（class的目的是得到操作指令）；
* jvm只有一个heap区，被所有**线程共享**，不存放基本类型和对象引用，只存放对象本身。
* **堆的优劣势**：堆的优势是可以动态的分配内存大小，生存期也不必事先告诉编译器，java的垃圾收集器会自动收取这些不在使用的数据，但缺点是，由于要在运行时动态分配内存，存取速度慢。

### 3、栈区 局部变量 
* 每一个线程包含一个stack区，只保存**基本数据类型的对象和自定义对象的引用（不是对象**），对象都存放在共享heap中；每个栈中的数据（基本数据类型和对象引用）都是私有的，其他栈不能访问；栈分为3部分：基**本类型变量区**、**执行环境上下文**、操作指令区（存放操作指令）
* 栈的优势劣势：**存取速度比堆要快**，仅次于直接位于CPU的寄存器，但**必须确定的是存在stack中的数据大小与生存期**必须是确定的，**缺乏灵活性**。
* 单个stack的数据可以共享。在java中，所有基本类型和引用类型都在stack中储存，栈中数据的生存空间一般在当前scopes内

####方法区（Method Area）
方法区（Method Area）：与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。很多人都更愿意把方法区称为“永久代”（Permanent Generation）。从jdk1.7已经开始准备“去永久代”的规划，jdk1.7的HotSpot中，已经把**原本放在方法区中的静态变量、字符串常量池等移到堆内存**中。

**在jdk1.8中，永久代已经不存在，存储的类信息、编译后的代码数据等已经移动到了元空间**（MetaSpace）中，元空间并没有处于堆内存上，而是直接占用的本地内存（NativeMemory）

元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制，但可以通过以下参数来指定元空间的大小

### 4、方法区 类信息、类变量（静态变量和常量）、方法

* 1、方法区又叫静态区，跟堆一样，被所有的线程共享。方法区包含所有的class和static变量；
* 2、方法区中包含的都是在程序中永远的唯一的元素

*  常量池 (放在方法区)
     * Java中的常量池，实际上分为两种形态：静态常量池和运行时常量池。
     * 所谓静态常量池，即*.class文件中的常量池，class文件中的常量池不仅仅包含字符串(数字)字面量，还包含类、方法的信息，占用class文件绝大部分空间。
     * 而运行时常量池，则是jvm虚拟机在完成类装载操作后，将class文件中的常量池载入到内存中，并保存在方法区中，我们常说的常量池，就是指方法区中的运行时常量池
     * 方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。
     * 栈：在Java中，JVM中的栈记录了线程的方法调用。每个线程拥有一个栈。在某个线程的运行过程中，如果有新的方法调用，那么该线程对应的栈就会增加一个存储单元，即帧(frame)。在frame中，保存有该方法调用的参数、局部变量和返回地址。
     * 堆：是JVM中一块可自由分配给对象的区域。当我们谈论垃圾回收(garbage collection)时，我们主要回收堆(heap)的空间。
Java的普通对象存活在堆中。与栈不同，堆的空间不会随着方法调用结束而清空。因此，在某个方法中创建的对象，可以在方法调用结束之后，继续存在于堆中。这带来的一个问题是，如果我们不断的创建新的对象，内存空间将最终消耗殆尽。

##值传递和引用传递
* 基本类型(byte--short--int--long--float--double--boolean--char)的变量总是按值传递
* 就对象而言，不是将对象本身传递给方法，而是将对象的的引用或者说对象的首地址传递给方法；引用本身是按值传递的，通过对象的引用，方法可以直接操作该对象
* 如果传递的是数组的引用，则对数组元素的后续修改可以在原始数组中反映出来（因为数组本身就是个对象，int[] a = new int[2];，这里面的int是数组元素的类型，而数组元素的修改是操作对象）

##Java中的参数传递时传值呢？还是传引用？

要说明这个问题，先要明确两点：

1. 不要试图与C进行类比，Java中没有指针的概念
2. 程序运行永远都是在**栈**中进行的，因而参数传递时，只存在**传递基本类型和对象引用**的问题。不会直接传对象本身。
明确以上两点后。Java在方法调用传递参数时，因为没有指针，所以它都是进行传值调用（这点可以参考C的传值调用）。因此，很多书里面都说Java是进行传值调用，这点没有问题，而且也简化的C中复杂性。

但是传引用的错觉是如何造成的呢？在运行栈中，基本类型和引用的处理是一样的，都是传值，所以，如果是传引用的方法调用，也同时可以理解为“传引用值”的传值调用，即引用的处理跟基本类型是完全一样的。但是当进入被调用方法时，被传递的这个引用的值，被程序解释（或者查找）到堆中的对象，这个时候才对应到真正的对象。如果此时进行修改，修改的是引用对应的对象，而不是引用本身，即：修改的是堆中的数据。所以这个修改是可以保持的了。

对象，从某种意义上说，是由基本类型组成的。可以把一个对象看作为一棵树，对象的属性如果还是对象，则还是一颗树（即非叶子节点），基本类型则为树的叶子节点。程序参数传递时，被传递的值本身都是不能进行修改的，但是，如果这个值是一个非叶子节点（即一个对象引用），则可以修改这个节点下面的所有内容。

堆和栈中，栈是程序运行最根本的东西。程序运行可以没有堆，但是不能没有栈。而堆是为栈进行数据存储服务，说白了堆就是一块共享的内存。不过，正是因为堆和栈的分离的思想，才使得Java的垃圾回收成为可能。

Java中，栈的大小通过-Xss来设置，当栈中存储数据比较多时，需要适当调大这个值，否则会出现java.lang.StackOverflowError异常。常见的出现这个异常的是无法返回的递归，因为此时栈中保存的信息都是方法返回的记录点。
#按照基本回收策略分
* 引用计数（Reference Counting）:

比较古老的回收算法。原理是此对象有一个引用，即增加一个计数，删除一个引用则减少一个计数。垃圾回收时，只用收集计数为0的对象。**此算法最致命的是无法处理循环引用的问题**。

* 标记-清除（Mark-Sweep）:
此算法执行分两阶段。第一阶段从引用根节点开始标记所有被引用的对象，第二阶段遍历整个堆，把未标记的对象清除。**此算法需要暂停整个应用，同时，会产生内存碎片**。

* 复制（Copying）:

此算法把内存空间划为两个相等的区域，每次只使用其中一个区域。垃圾回收时，**遍历当前使用区域，把正在使用中的对象复制到另外一个区域中。**次算法每次只处理正在使用中的对象，因此复制成本比较小，同时复制过去以后还能进行相应的内存整理，不会出现“碎片”问题。当然，此**算法的缺点也是很明显的，就是需要两倍内存空间**。

**商业虚拟机用这个回收算法来回收新生代**

* 标记-整理（Mark-Compact）:

此算法结合了“标记-清除”和“复制”两个算法的优点。也是分两阶段，第一阶段从根节点开始标记所有被引用对象，第二阶段遍历整个堆，把清除未标记对象并且把存活对象“压缩”到堆的其中一块，按顺序排放。此算法避免了“标记-清除”的碎片问题，同时也避免了“复制”算法的空间问题。

**老年代标记-清理“和”标记-整理“算法来进行回收。**

##Java中可以作为GC Root的对象有

* 虚拟机栈中引用的对象（本地变量表）
* 方法区中静态属性的引用对象
* 方法区中常量引用对象
* 本地方法栈中引用对象（Native 对象）
* 主要执行在上下文中和全局性的引用
#分区对待的方式分
* 增量收集（Incremental Collecting）:
实时垃圾回收算法，即：在应用进行的同时进行垃圾回收。不知道什么原因JDK5.0中的收集器没有使用这种算法的。

* 分代收集（Generational Collecting）:
基于对对象生命周期分析后得出的垃圾回收算法。把对象分为年青代、年老代、持久代，对不同生命周期的对象使用不同的算法（上述方式中的一个）进行回收。现在的垃圾回收器（从J2SE1.2开始）都是使用此算法的。
#为什么要分代
分代的垃圾回收策略，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的收集方式，以便提高回收效率。

#什么情况下触发垃圾回收
由于对象进行了分代处理，因此垃圾回收区域、时间也不一样。GC有两种类型：Scavenge GC和Full GC。jdk1.8 后分为 Minor GC、Major GC和Full GC，清理Eden区和 Survivor区叫Minor GC。清理Old区叫Major GC。清理整个堆空间—包括年轻代和老年代叫Full GC。

##Scavenge GC

一般情况下，当新对象生成，并且在Eden申请空间失败时，就会触发Scavenge GC，对Eden区域进行GC，清除非存活对象，并且把尚且存活的对象移动到Survivor区。然后整理Survivor的两个区。这种方式的GC是对年轻代的Eden区进行，不会影响到年老代。因为大部分对象都是从Eden区开始的，同时Eden区不会分配的很大，所以Eden区的GC会频繁进行。因而，一般在这里需要使用速度快、效率高的算法，使Eden去能尽快空闲出来。

##Full GC

对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个对进行回收，所以比Scavenge GC要慢，因此应该尽可能减少Full GC的次数。在对JVM调优的过程中，很大一部分工作就是对于FullGC的调节。有如下原因可能导致Full GC：

* 年老代（Tenured）被写满
* 持久代（Perm）被写满 
* System.gc()被显示调用 
* 上一次GC之后Heap的各域分配策略动态变化

##GC
新生代由于其对象存活时间短，且需要经常gc，因此采用效率较高的复制算法，其将内存区分为一个eden区和两个suvivor区，eden区和survivor区的比例是8:1，分配内存时先分配eden区，当eden区满时，使用**复制算法**进行gc，将存活对象复制到一个survivor区，当一个survivor区满时，将其存活对象复制到另一个区中，当对象存活时间大于某一阈值时，将其放入老年代。 
老年代和永久代因为其存活对象时间长，因此使用**标记清除或标记整理算法**


#垃圾回收的瓶颈
传统分代垃圾回收方式，已经在一定程度上把垃圾回收给应用带来的负担降到了最小，把应用的吞吐量推到了一个极限。但是他无法解决的一个问题，就是Full GC所带来的应用暂停。在一些对实时性要求很高的应用场景下，GC暂停所带来的请求堆积和请求失败是无法接受的。这类应用可能要求请求的返回时间在几百甚至几十毫秒以内，如果分代垃圾回收方式要达到这个指标，只能把最大堆的设置限制在一个相对较小范围内，但是这样有限制了应用本身的处理能力，同样也是不可接收的。

分代垃圾回收方式确实也考虑了实时性要求而提供了并发回收器，支持最大暂停时间的设置，但是受限于分代垃圾回收的内存划分模型，其效果也不是很理想。

为了达到实时性的要求（其实Java语言最初的设计也是在嵌入式系统上的），一种新垃圾回收方式呼之欲出，它既支持短的暂停时间，又支持大的内存空间分配。可以很好的解决传统分代方式带来的问题。


##intern()
* intern()方法设计的初衷，就是重用String对象，以节省内存消耗。
* 使用intern() 方法创建字符串，当常量池中已经包含一个等于此 String 对象的字符串（用 equals(Object) 方法确定），则返回池中的字符串。否则，将此 String 对象添加到池中，并返回此 String 对象的引用。 

##replace和replaceAll的区别
* 1)replace的参数是char和CharSequence，即可以支持字符的替换，也支持字符串的替换(CharSequence即字符串序列的意思,说白了也就是字符串)；
* 2)replaceAll的参数是regex，即基于规则表达式的替换，比如，可以通过replaceAll("\\d", "*")把一个字符串所有的数字字符都换成星号;
* 相同点：都是全部替换，即把源字符串中的某一字符或字符串全部换成指定的字符或字符串，如果只想替换第一次出现的，可以使用replaceFirst()，这个方法也是基于规则表达式的替换，但与replaceAll()不同的是，只替换第一次出现的字符串；
* 另外，如果replaceAll()和replaceFirst()所用的参数据不是基于规则表达式的，则与replace()替换字符串的效果是一样的，即这两者也支持字符串的操作；
* 还有一点注意:：执行了替换操作后,源字符串的内容是没有发生改变的。

##StringBuilder & StringBuffer
* StringBuilder 类在 Java 5 中被提出，它和 StringBuffer 之间的最大不同在于 StringBuilder 的方法不是线程安全的（不能同步访问）。由于 StringBuilder 相较于 StringBuffer 有速度优势，所以多数情况下建议使用 StringBuilder 类。然而在应用程序要求线程安全的情况下，则必须使用 StringBuffer 类。
* String类是不可变类，任何对String的改变都 会引发新的String对象的生成(除了intern())；StringBuffer则是可变类，任何对它所指代的字符串的改变都不会产生新的对象。

#static
#final


##java 基本数据类型
又称为原始数据类型byte,short,char,int,long,float,double,boolean，他们之间的比较应该使用（==），比较的是他们的值。
##java  复合数据类型
当复合数据类型用（==）进行比较，比较的是他们在内存中的存放地址。
当复合数据类型之间进行equals比较时，这个方法的初始行为是比较对象在堆内存中的地址，但在一些诸如String,Integer,Date类中把Object中的这个方法覆盖了，作用被覆盖为比较内容是否相同。
##TreeMap和HashMap
* HashMap：适用于在Map中插入、删除和定位元素。 
* Treemap：适用于按自然顺序或自定义顺序遍历键(key)。 
* HashMap通常比TreeMap快一点(树和哈希表的数据结构使然)，建议多使用HashMap，在需要排序的Map时候才用TreeMap。 
###Treemap
Treemap的实现是红黑树算法的实现，红黑树是一颗自平衡的排序二叉树；对红黑二叉树而言它主要包括三大基本操作：左旋、右旋、着色。
一棵有效的红黑树二叉树而言我们必须增加如下规则：
       * 1、每个节点都只能是红色或者黑色
       * 2、根节点是黑色
       * 3、每个叶节点（NIL节点，空节点）是黑色的。
       * 4、如果一个结点是红的，则它两个子节点都是黑的。也就是说在一条路径上不能出现相邻的两个红色结点。
       * 5、从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。

##HashMap
当我们给put()方法传递键和值时，我们先对key调用hashCode()方法，返回hashCode**取模**来决定key会被放到数组里的位置。找到bucket位置来储存Entry对象。”这里关键点在于指出，HashMap是在bucket中储存键对象和值对象，作为Map.Entry

hashMap的数据结构是 数组＋单项链表（bucket）结构.
###取模运算
取余：rem(x,y)，遵循尽可能让商向0靠近的原则
取模：mod(x,y)，遵循尽可能让商向负无穷靠近的原则
**符号相同时**，两者不会冲突。如果都是正数，取余取模值一样。
7/3=2.3  
取余：向0 靠近，fix（2.3）=3
取模: 向负无穷靠近 floor（2.3）= 3
**如果是负数**则 取余是向0 靠近，取模是向负无穷靠近 例如
7/（-3）=-2.3，在这个运算中，x为7，y为-3，
取余：向0 靠近，fix（-2.3）=-2
取模: 向负无穷靠近 floor（-2.3）= -3
####当两个对象的hashcode相同会发生什么？
因为hashcode相同，所以它们的bucket位置相同，‘碰撞’会发生。因为HashMap使用链表存储对象，这个Entry(包含有键值对的Map.Entry对象)会存储在链表中。
####如果两个键的hashcode相同，你如何获取值对象？
当我们调用get()方法，HashMap会使用键对象的hashcode找到bucket位置，然后获取值对象，如果有两个值对象储存在同一个bucket，找到bucket位置之后，将会遍历链表直到找到值对象，会调用keys.equals()方法去找到链表中正确的节点，最终找到要找的值对象。

####如何减少碰撞的发生
使用不可变的、声明作final的对象，并且采用合适的equals()和hashCode()方法的话，将会减少碰撞的发生，提高效率。不可变性使得能够缓存不同键的hashcode，这将提高整个获取对象的速度，使用String，Interger这样的wrapper类作为键是非常好的选择。
####如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？
默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置。

####重新调整HashMap大小存在什么问题吗？
当重新调整HashMap大小的时候，**存在条件竞争**，因为如果两个线程都发现HashMap需要重新调整大小了（多线程建议使用ConcurrentHashMap），它们会同时试着调整大小。在调整大小的过程中，存储在链表中的元素的次序会反过来，因为移动到新的bucket位置的时候，HashMap并不会将元素放在链表的尾部，而是放在头部，这是为了避免尾部遍历(tail traversing)。如果条件竞争发生了，那么就死循环了。
####为什么String, Interger这样的wrapper类适合作为键？
而且String最为常用。因为String是不可变的，也是final的，而且已经重写了equals()和hashCode()方法了。其他的wrapper类也有这个特点。不可变性是必要的，因为为了要计算hashCode()，就要防止键值改变，如果键值在放入时和获取时返回不同的hashcode的话，那么就不能从HashMap中找到你想要的对象。不可变性还有其他的优点如线程安全。
####我们可以使用自定义的对象作为键吗？
当然你可能使用任何对象作为键，只要它遵守了equals()和hashCode()方法的定义规则，并且当对象插入到Map中之后将不会再改变了。如果这个自定义对象时不可变的，那么它已经满足了作为键的条件，因为当它创建之后就已经不能改变了。
####我们可以使用CocurrentHashMap来代替Hashtable吗
ConcurrentHashMap越来越多人用了。我们知道Hashtable是synchronized的，但是ConcurrentHashMap同步性能更好，因为它仅仅根据同步级别对map的一部分进行上锁。ConcurrentHashMap当然可以代替HashTable，但是HashTable提供更强的线程安全性

##HashMap在Java1.7与1.8中的区别
https://www.cnblogs.com/stevenczp/p/7028071.html
####JDK1.7中
使用一个Entry数组来存储数据，用key的hashcode**取模**来决定key会被放到数组里的位置，如果hashcode相同，或者hashcode取模后的结果相同（hash collision），那么这些key会被定位到Entry数组的同一个格子里，这些key会形成一个链表。

在hashcode特别差的情况下，比方说所有key的hashcode都相同，这个链表可能会很长，那么put/get操作都可能需要遍历这个链表也就是说时间复杂度在最差情况下会退化到O(n)
####JDK1.8中
使用一个Node数组来存储数据，但这个Node可能是链表结构，也可能是红黑树结构
如果插入的key的hashcode相同，那么这些key也会被定位到Node数组的同一个格子里。
如果同一个格子里的key不超过8个，使用链表结构存储。
如果超过了8个，那么会调用treeifyBin函数，将链表转换为红黑树。
那么即使hashcode完全相同，由于红黑树的特点，查找某个特定元素，也只需要O(log n)的开销。也就是说put/get的操作的时间复杂度最差只有O(log n)
####限制
听起来挺不错，但是真正想要利用JDK1.8的好处，有一个限制：
key的对象，必须正确的实现了Compare接口。如果没有实现Compare接口，或者实现得不正确（比方说所有Compare方法都返回0）那JDK1.8的HashMap其实还是慢于JDK1.7的
####为什么要这么操作呢？
我认为应该是为了避免Hash Collision DoS攻击
Java中String的hashcode函数的强度很弱，有心人可以很容易的构造出大量hashcode相同的String对象。如果向服务器一次提交数万个hashcode相同的字符串参数，那么可以很容易的卡死JDK1.7版本的服务器。
但是String正确的实现了Compare接口，因此在JDK1.8版本的服务器上，Hash Collision DoS不会造成不可承受的开销。
##HashMap和Hashtable
* HashMap几乎可以等价于Hashtable，除了HashMap是非synchronized的，并可以接受null(HashMap可以接受为null的键值(key)和值(value)，而Hashtable则不行)
* HashMap是非synchronized，而Hashtable是synchronized，这意味着Hashtable是线程安全的，多个线程可以共享一个Hashtable；而如果没有正确的同步的话，多个线程是不能共享HashMap的。Java 5提供了ConcurrentHashMap，它是HashTable的替代，比HashTable的扩展性更好。

##ConcurrentHashMap
数据结构 ConcurrentHashMap的目标是实现支持高并发、高吞吐量的线程安全的HashMap

一个ConcurrentHashMap由多个segment组成，每一个segment都包含了一个HashEntry数组的hashtable， 每一个segment包含了对自己的hashtable的操作，比如get，put，replace等操作，这些操作发生的时候，对自己的hashtable进行锁定。由于每一个segment写操作只锁定自己的hashtable，所以可能存在多个线程同时写的情况，性能无疑好于只有一个hashtable锁定的情况。

ConcurrentHashMap具体是线程安全的.它引入了一个“分段锁”的概念，具体可以理解为把一个大的Map拆分成N个小的HashTable，根据key.hashCode()来决定把key放到哪个HashTable中。
在ConcurrentHashMap中，就是把Map分成了N个Segment，put和get的时候，都是现根据key.hashCode()算出放到哪个Segment中


##什么是HashSet

HashSet实现了Set接口，它不允许集合中有重复的值，当我们提到HashSet时，第一件事情就是在将对象存储在HashSet之前，要先确保对象重写equals()和hashCode()方法，这样才能比较对象的值是否相等，以确保set中没有储存相等的对象。如果我们没有重写这两个方法，将会使用这个方法的默认实现。

HashSet使用**成员对象**来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性，如果两个对象不同的话，那么返回false

public boolean add(Object o)方法用来在Set中添加元素，当元素值重复时则会立即返回false，如果成功添加的话会返回true。



       
##Map.Entry
Map是java中的接口，Map.Entry是Map的一个内部接口。

Map提供了一些常用方法，如keySet()、entrySet()等方法，keySet()方法返回值是Map中key值的集合；entrySet()的返回值也是返回一个Set集合，此集合的类型为Map.Entry。

Map.Entry是Map声明的一个内部接口，此接口为泛型，定义为Entry<K,V>。它表示Map中的一个实体（一个key-value对）。接口中有getKey(),getValue方法。

###Map.Entry使用

你是否已经对每次从Map中取得关键字然后再取得相应的值感觉厌倦？使用Map.Entry类，你可以得到在同一时间得到所有的信息。

```
 //第三种：推荐，尤其是容量大时
      System.out.println("通过Map.entrySet遍历key和value");
      for (Map.Entry<String, String> entry : map.entrySet()) {
       System.out.println("key= " + entry.getKey() + " and value= " + entry.getValue());
      }
```

##java范型中E，T，？的区别？
自定义泛型类时，类持有者名称可以使用T(Type，一般指类) 超类

如果是容器的元素可以使用E(Element，一般指方法)若键值匹配可以用K(Key)和V(Value)等， 

若是<?>（一般指参数），则是默认是允许Object及其下的子类，也就是java的所有对象了。 

```
Set<T> 表示 集合里 是   T类的实例 
List<E> 表示  集合里 是  E类的实例 
List<?> 表示 集合里的对象类型不确定，未指定 
List 同 List<?> 是一样的。 
```
也就是说可以随便写咯

##Integer.valueof(String s)和Integer.parseInt(String s)的具体区别
Integer.valueof(String s)是将一个包装类,是一个实际值为数字的变量先转成string型再将它转成Integer型的包装类对象(相当于转成了int的对象)这样转完的对象就具有方法和属性了。
而Integer.parseInt(String s)只是将是数字的字符串转成数字，注意他返回的是int型变量不具备方法和属性。

设有下面两个赋值语句：
a=Integer.parseInt(“123”);
b=Integer.valueOf(“123”).intValue();
下述说法正确的是（d）。
A、a是整数类型变量，b是整数类对象。
B、a是整数类对象，b是整数类型变量。
C、a和b都是整数类对象并且值相等。
D、a和b都是整数类型变量并且值相等。

###解释：

parseInt(Strings)方法是类Integer的静态方法，它的作用就是将形参s转化为整数，比如：

```
Interger.parseInt("1")=1;
Integer.parseInt("20")=20;
Integer.parseInt("324")=324;
```
当然，s表示的整数必须合法，不然是会抛异常的。
valueOf(Strings)也是Integer类的静态方法，它的作用是将形参s转化为Integer对象，
什么是Integer对象，Integer就是基本数据类型int型包装类，就是将int包装成一个类，这样在很多场合下是必须的。如果理解不了，你就认为int是Integer的mini版，好用了很多，但也丢失了一些功能，好了，看代码：
Interger.valueOf("123")=Integer(123)
这时候Integer（123）就是整数123的对象表示形式，它再调用intValue()方法，就是将123的对象表示形式转化为基本数据123
所以，选择D

##Long和long区别
Long类型与long类型的区别导致的。Long类型变量表示的是一个对象，其值是对象的一个属性。相当于一个Long变量中包含了一个long类型的值。所以当进行两个Long类型变量比较时如果用的是==来比较，那么实际比较的是两个Long型变量指向的对象的地址，显然两个不同Long对象地址是不同的。

通过Long类型的equals方法来比较对象的值。equals方法是获取Long类型存储的值和其他Long对象或者值进行比较。如果equals的参数是Long类型，那么会取得参数的值与调用的对象的值进行比较，进而得出符合我们预期的结果

##spring

##spring4 时间

```
//使用瞬时时间 + 时区  
Instant instant = Instant.now();  
LocalDateTime d3 = LocalDateTime.ofInstant(Instant.now(), ZoneId.systemDefault());  
System.out.println(d3);  
```

###IOC

学 java 的人应该都知道spring，学spring的人呢都应该知道 IOC和 AOP 对吧。今天就简单的说一下spring 的IOC。

控制反转IoC(Inversion of Control)，是一种设计思想，DI(依赖注入)是实现IoC的一种方法。
其实spring就是一个容器，一个bean容器。主要是完成了完成对象的创建和依赖的管理注入。
###什么是控制反转呢？
所谓控制反转，就是把原先我们代码里面需要实现的对象创建、依赖的代码，反转给ioc容器来帮忙实现，也就是 ioc 容器帮我们做了原本应该我门自己实现的对象创建和依赖的内容。
好了那么ioc 容器是怎么帮我门创建 对象 和注入依赖呢？
1。读取xml
2。反射




ioc 控制反转 也称为 DI （dependenty injection 依赖注入）
优点：
spring 帮我们管理和创建对象，降低了耦合性。
通过xml 文件配置方便修改 灵活。
 
反转： 反转到容器控制，本来是要由我控制的现在交给容器帮忙控制，容器里面各种对象，相互之间各种依赖，随意装配 。 

spring ioc 帮我们创建和管理了我们需要创建的对象，并像搭乐高积木一样，来管理这个对象间的关系。

Spring Bean的创建是典型的工厂模式，bean 的生命周期默认是单例模式
##AOP
面向切面编程
AOP（Aspect-OrientedProgramming，面向方面编程），可以说是OOP（Object-Oriented Programing，面向对象编程）的补充和完善。
动态代理就是生成一个代理对象，对代理需要被代理的对象。 代理对象 是为了 代理被代理对象创建的对象。

面线切面编程就像是横着切了一刀。 使用场景 权限、日志、事务（start ，commit）、异常处理、

http://blog.csdn.net/moreevan/article/details/11977115/
http://www.cnblogs.com/hongwz/p/5764917.html
https://www.zhihu.com/question/24863332

如果你的类没有实现接口，spring 也能给你生成动态代理，spring直接生成二进制码，用继承。 

aspectj 是一个专门用来生成代理的框架
joinpoint 切入点 ；语法 ：execution(public void com.abel.dao.impl.UserDAOImpl.save(com.abel.model.User )
pointcut 连接点的集合 pointcut 是 joinpoint 的集合
语法 ：execution(* com.abel.dao.impl.*.*(..)
com.abel.dao.impl 路径下的所有类的（任何返回值）
所有方法

Aspect 就是切面类
advice @Befor 
target 代理对象
weave  织入


<aop:after> 后通知
<aop:after-returning> 返回后通知
<aop:after-throwing> 抛出后通知
<aop:around> 周围通知
<aop:aspect>定义一个切面
<aop:before>前通知

1. 引入包

##Spring如何解决循环依赖
###构造器循环依赖：
表示通过构造器注入构成的循环依赖，此依赖是无法解决的，只能抛出BeanCurrentlyInCreationException异常表示循环依赖。

如在创建CircleA类时，构造器需要CircleB类，那将去创建CircleB，在创建CircleB类时又发现需要CircleC类，则又去创建CircleC，最终在创建CircleC时发现又需要CircleA；从而形成一个环，没办法创建。

Spring容器将每一个正在创建的Bean 标识符放在一个“当前创建Bean池”中，Bean标识符在创建过程中将一直保持在这个池中，因此如果在创建Bean过程中发现自己已经在“当前创建Bean池”里时将抛出BeanCurrentlyInCreationException异常表示循环依赖；而对于创建完毕的Bean将从“当前创建Bean池”中清除掉。
setter循环依赖：表示通过setter注入方式构成的循环依赖。
###setter 注入造成的依赖 
setter循环依赖：表示通过setter注入方式构成的循环依赖。
对于setter注入造成的依赖是通过Spring容器提前暴露刚完成构造器注入但未完成其他步骤（如setter注入）的Bean来完成的，而且只能解决单例作用域的Bean循环依赖。
###为什么用set方式就不报错了呢 ？
    Spring先是用构造实例化Bean对象 ，此时Spring会将这个实例化结束的对象放到一个Map中，并且Spring提供了获取这个未设置属性的实例化对象引用的方法。   结合我们的实例来看，，当Spring实例化了StudentA、StudentB、StudentC后，紧接着会去设置对象的属性，此时StudentA依赖StudentB，就会去Map中取出存在里面的单例StudentB对象，以此类推，不会出来循环的问题喽、

# spring 注入接口
当接口中有范型的时候想当于多个 接口，此时注入接口报错
当接口多个实现类时，此时注入接口，报错。

# maven 跳过测试
mvn install -Dmaven.test.skip=true
##gradle
Gradle和Maven都是项目自动构建工具，编译源代码只是整个过程的一个方面.虽然两者都是项目工具，但是maven现在已经是行业标准，Gradle是后起之秀，Gradle抛弃了Maven的基于XML的繁琐配置，众所周知XML的阅读体验比较差，对于机器来说虽然容易识别，但毕竟是由人去维护的。取而代之的是Gradle采用了领域特定语言Groovy的配置，大大简化了构建代码的行数.

Gradle给我最大的有点是两点。其一是简洁，基于Groovy的紧凑脚本实在让人爱不释手，在表述意图方面也没有什么不清晰的地方。其二是灵活，各种在Maven中难以下手的事情，在Gradle就是小菜一碟，比如修改现有的构建生命周期，几行配置就完成了，同样的事情，在Maven中你必须编写一个插件，

范例 用 gradle 引入依赖

```
dependencies {
    compile('org.springframework:spring-core:2.5.6')
    compile('org.springframework:spring-beans:2.5.6')
    compile('org.springframework:spring-context:2.5.6')
    compile('com.google.code.kaptcha:kaptcha:2.3:jdk15')
    testCompile('junit:junit:4.7')
}
```


#WEB

##MVC
MVC本来是存在于Desktop程序中的，M是指数据模型，V是指用户界面，C则是控制器。使用MVC的目的是将M和V的实现代码分离，从而使同一个程序可以使用不同的表现形式。
##"GET方式提交的数据最多只能是1024字节"?  错

因为GET是通过URL提交数据，那么GET可提交的数据量就跟URL的长度有直接关系了。而实际上，URL不存在参数上限的问题，HTTP协议规范没有对URL长度进行限制。这个限制是特定的浏览器及服务器对它的限制。IE对URL长度的限制是2083字节(2K+35)。对于其他浏览器，如Netscape、FireFox等，理论上没有长度限制，其限制取决于操作系统的支持。

Get是向服务器发索取数据的一种请求，而Post是向服务器提交数据的一种请求，在FORM（表单）中，Method默认为"GET"，实质上，GET和POST只是发送机制不同，并不是一个取一个发！

##GET & POST
GET请求会被浏览器主动cache，而POST不会，除非手动设置。 GET请求只能进行url编码，而POST支持多种编码方式。 GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。 GET请求在URL中传送的参数是有长度限制的，而POST么有。 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。 GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。 GET参数通过URL传递，POST放在Request body中。

GET和POST是什么?HTTP协议中的两种发送请求的方法。
HTTP的底层是TCP/IP。所以GET和POST的底层也是TCP/IP，也就是说，GET/POST都是TCP链接。GET和POST能做的事情是一样一样的。你要给GET加上request body，给POST带上url参数，技术上是完全行的通的。


##GET & POST 重大区别
GET产生一个TCP数据包;POST产生两个TCP数据包。

对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200(返回数据);
而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)。

也就是说，GET只需要汽车跑一趟就把货送到了，而POST得跑两趟，第一趟，先去和服务器打个招呼“嗨，我等下要送一批货来，你们打开门迎接我”，然后再回头把货送过去。

1. GET与POST都有自己的语义，不能随便混用。
2. 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。
3. 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。

##PUT
在HTTP中，PUT被定义为idempotent的方法，POST则不是，这是一个很重要的区别。

PUT操作是幂等的。所谓幂等是指不管进行多少次操作，结果都一样。比如我用PUT修改一篇文章，然后在做同样的操作，每次操作后的结果并没有不同
##汽车TCP
在我大万维网世界中，TCP就像汽车，我们用TCP来运输数据，它很可靠，从来不会发生丢件少件的现象。
##交通规则HTTP 
HTTP给汽车运输设定了好几个服务类别，有GET, POST, PUT, DELETE等等，HTTP规定，当执行GET请求的时候，要给汽车贴上GET的标签(设置method为GET)，而且要求把传送的数据放在车顶上(url中)以方便记录。如果是POST请求，就要在车上贴上POST的标签，并把货物放在车厢里。当然，你也可以在GET的时候往车厢内偷偷藏点货物，但是这是很不光彩;也可以在POST的时候在车顶上也放一些数据，让人觉得傻乎乎的。HTTP只是个行为准则，而TCP才是GET和POST怎么实现的基本。

##运输公司 浏览器
不同的浏览器(发起http请求)和服务器(接受http请求)就是不同的运输公司。

虽然理论上，你可以在车顶上无限的堆货物(url中无限加参数)。但是运输公司可不傻，装货和卸货也是有很大成本的，他们会限制单次运输量来控制风险，数据量太大对浏览器和服务器都是很大负担。业界不成文的规定是，(大多数)浏览器通常都会限制url长度在2K个字节，而(大多数)服务器最多处理64K大小的url。超过的部分，恕不处理。如果你用GET服务，在request body偷偷藏了数据，不同服务器的处理方式也是不同的，有些服务器会帮你卸货，读出数据，有些服务器直接忽略，所以，虽然GET可以带request body，也不能保证一定能被接收到哦。

##Https
HTTPS（全称：Hypertext Transfer Protocol over Secure Socket Layer），是以安全为目标的HTTP通道，简单讲是HTTP的安全版。即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。


超文本传输协议 (HTTP-Hypertext transfer protocol) 是一种详细规定了浏览器和万维网服务器之间互相通信的规则，通过因特网传送万维网文档的数据传送协议。


##http和https区别
https协议需要到ca申请证书，一般免费证书很少，需要交费。http是超文本传输协议，信息是明文传输，https 则是具有安全性的ssl加密传输协议http和https使用的是完全不同的连接方式用的端口也不一样,前者是80,后者是443。http的连接很简单,是无状态的HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、

http的连接很简单,是无状态的。HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议 要比http协议安全

#java多线程
##产生线程不安全的原因

在同一程序中运行多个线程本身不会导致问题，问题在于多个线程访问了相同的资源。如，同一内存区（变量，数组，或对象）、系统（数据库，web services等）或文件。实际上，这些问题只有在一或多个线程向这些资源做了写操作时才有可能发生，只要资源没有发生变化,多个线程读取相同的资源就是安全的。
##竞态条件 & 临界区
当两个线程竞争同一资源时，如果对资源的访问顺序敏感，就称存在竞态条件。导致竞态条件发生的代码区称作**临界区**。上例中add()方法就是一个临界区,它会产生**竞态条件**。在临界区中使用适当的同步就可以避免竞态条件。

```
public class Counter {
    protected long count = 0;

    public void add(long value){
        this.count = this.count + value;  
    }
}

```
两个线程交替执行结果如下
```
this.count = 0;
   A:   读取 this.count 到一个寄存器 (0)
   B:   读取 this.count 到一个寄存器 (0)
   B:   将寄存器的值加2
   B:   回写寄存器值(2)到内存. this.count 现在等于 2
   A:   将寄存器的值加3
   A:   回写寄存器值(3)到内存. this.count 现在等于 3
```

##共享资源
允许被多个线程同时执行的代码称作线程安全的代码叫做共享资源。**线程安全的代码不包含竞态条件**。当多个线程同时更新共享资源时会引发竞态条件。
##局部变量
局部变量存储在线程自己的栈中。也就是说，局部变量永远也不会被多个线程共享。所以，基础类型的局部变量是线程安全的。

```
public void someMethod(){
  long threadSafeInt = 0;//局部变量
  threadSafeInt++;
}
```
##局部的对象引用
上面提到的局部变量是一个基本类型，如果局部变量是一个**对象类型**呢？对象的局部引用和基础类型的局部变量不太一样。尽管引用本身没有被共享，但引用所指的对象并没有存储在线程的栈内，**所有的对象都存在共享堆**中，所以对于局部对象的引用，有可能是线程安全的，也有可能是线程不安全的。

如果在某个方法中创建的对象不会被其他方法或全局变量获得，或者说方法中创建的对象没有逃出此方法的范围，那么它就是**线程安全**的。实际上，哪怕将这个对象作为参数传给其它方法，只要**别的线程获取不到这个对象**，那它仍是线程安全的。

```
public void someMethod(){
  LocalObject localObject = new LocalObject();
  localObject.callMethod();
  method2(localObject);
}

public void method2(LocalObject localObject){
  localObject.setValue("value");
}
```
上面样例中 LocalObject 对象没有被方法返回，也没有被传递给someMethod()方法外的对象，始终在someMethod()方法内部。**每个执行someMethod()的线程都会创建自己的LocalObject对象**，并赋值给localObject引用。因此，这里的LocalObject是线程安全的。事实上，整个someMethod()都是线程安全的。即使将LocalObject作为参数传给同一个类的其它方法或其它类的方法时，它仍然是**线程安全**的。当然，如果LocalObject通过某些方法被传给了别的线程，那它就不再是线程安全的了。
	
```
如果一个资源的创建，使用，销毁都在同一个线程内完成，且永
远不会脱离该线程的控制，则该资源的使用就是线程安全的。
```
##Java中实现线程安全的方法
* 最简单的方式，使用Synchronization关键字:
http://blog.csdn.net/suifeng3051/article/details/48711405
* 使用java.util.concurrent.atomic 包中的原子类，例如 AtomicInteger
* 使用java.util.concurrent.locks 包中的锁
* 使用线程安全的集合ConcurrentHashMap
* 使用volatile关键字，保证变量可见性（直接从内存读，而不是从线程cache读）

http://blog.csdn.net/suifeng3051/article/details/52164267

##synchronized 
* synchronized修饰非静态方法、同步代码块的synchronized (this)用法和synchronized (非this对象)的用法锁的是对象，线程想要执行对应同步代码，需要获得对象锁。     
* synchronized修饰非静态方法以及同步代码块的synchronized (类.class)用法锁的是类，线程想要执行对应同步代码，需要获得类锁。
* 在java中，同步加锁的是一个对象或者一个类，而不是代码

##synchronized 使用
synchronized关键字可标记四种代码块：

1. 实例方法
2. 静态方法
3. 实例方法中的代码块
4. 静态方法中的代码块

##synchronized的缺陷
　　synchronized是java中的一个关键字，也就是说是Java语言内置的特性。那么为什么会出现Lock呢？

　如果一个代码块被synchronized修饰了，当一个线程获取了对应的锁，并执行该代码块时，其他线程便只能一直等待，等待获取锁的线程释放锁，而这里获取锁的线程释放锁只会有两种情况：

　　1）获取锁的线程执行完了该代码块，然后线程释放对锁的占有；

　　2）线程执行发生异常，此时JVM会让线程自动释放锁。

　　那么如果这个获取锁的线程由于要等待IO或者其他原因（比如调用sleep方法）被阻塞了，但是又没有释放锁，其他线程便只能干巴巴地等待，影响程序执行效率。

##volatile 与 synchronized 的比较
* volatile是变量修饰符，其修饰的变量具有可见性。
* volatile主要用在多个线程感知实例变量被更改了场合，从而使得各个线程获得最新的值。它强制线程每次从主内存中取到变量，而不是从线程的私有内存中读取变量，从而保证了数据的可见性。
* ①volatile轻量级，只能修饰变量。synchronized重量级，还可修饰方法
* ②volatile只能保证数据的可见性，不能用来同步，因为多个线程并发访问volatile修饰的变量不会阻塞。
* synchronized不仅保证可见性，而且还保证原子性，因为，只有获得了锁的线程才能进入临界区，从而保证临界区中的所有语句都全部执行。多个线程争抢synchronized锁对象时，会出现阻塞。

##Lock 接口
lock：需要显示指定起始位置和终止位置。一般使用ReentrantLock类做为锁，多个线程中必须要使用一个ReentrantLock类做为对象才能保证锁的生效。且在加锁和解锁处需要通过lock()和unlock()显示指出。所以一般会在finally块中写unlock()以防死锁。

synchronized是托管给JVM执行的，而lock是java写的控制锁的代码。

Lock接口中每个方法的使用
* lock()用来获取锁。如果锁已被其他线程获取，则进行等待。
* tryLock()如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待，则返回true。
* tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。
* lockInterruptibly()是用来获取锁的。如果线程正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态。
* unLock()方法是用来释放锁的。

###synchronized和lock用途区别
 
synchronized原语和ReentrantLock在一般情况下没有什么区别，但是在非常复杂的同步应用中，请考虑使用ReentrantLock，特别是遇到下面2种需求的时候。
 
1.某个线程在等待一个锁的控制权的这段时间需要中断
2.需要分开处理一些wait-notify，ReentrantLock里面的Condition应用，能够控制notify哪个线程
3.具有公平锁功能，每个到来的线程都将排队等候

##Java的锁分为对象锁和类锁。

　　1. 当两个并发线程访问同一个对象object中的这个synchronized(this)同步代码块时，一个时间内针对该对象的操作只能有一个线程得到执行。另一个线程必须等待当前线程执行完这个代码块以后才能执行该代码块。

　　2. 然而，另一个线程仍然可以访问该object中的非synchronized(this)同步代码块。

　　3. 尤其关键的是，当一个线程访问object的一个synchronized(this)同步代码块时，其他线程对该object中所有其它synchronized(this)同步代码块的访问将被阻塞。

　　4. 同步加锁的是对象，而不是代码。因此，如果你的类中有一个同步方法，这个方法可以被两个不同的线程同时执行，只要每个线程自己创建一个的该类的实例即可。

　　5. 不同的对象实例的synchronized方法是不相干扰的。也就是说，其它线程照样可以同时访问相同类的另一个对象实例中的synchronized方法。

　　6. synchronized关键字是不能继承的，也就是说，基类的方法synchronized f(){} 在继承类中并不自动是synchronized f(){}，而是变成了f(){}。继承类需要你显式的指定它的某个方法为synchronized方法。

　　7.对一个全局对象或者类加锁时，对该类的所有对象都起作用
　　
##java 线程死锁
死锁的四个条件：

* 1、互斥使用，即当资源被一个线程使用(占有)时，别的线程不能使用
* 2、不可抢占，资源请求者不能强制从资源占有者手中夺取资源，资源只能由资源占有者主动释放。
* 3、请求和保持，即当资源请求者在请求其他的资源的同时保持对原有资源的占有。
* 4、循环等待，即存在一个等待队列：P1占有P2的资源，P2占有P3的资源，P3占有P1的资源。这样就形成了一个等待环路。

#java 线程生命周期
*  新建（new Thread）
当创建Thread类的一个实例（对象）时，此线程进入新建状态（未被启动）。
例如：Thread  t1=new Thread();

* 就绪（runnable）
线程已经被启动，正在等待被分配给CPU时间片，也就是说此时线程正在就绪队列中排队等候得到CPU资源。例如：t1.start();

* 运行（running）
线程获得CPU资源正在执行任务（run()方法），此时除非此线程自动放弃CPU资源或者有优先级更高的线程进入，线程将一直运行到结束。

* 死亡（dead）
当线程执行完毕或被其它线程杀死，线程就进入死亡状态，这时线程不可能再进入就绪状态等待执行。
 	* 自然终止：正常运行run()方法后终止
 	* 异常终止：调用stop()方法让一个线程终止运行
* 堵塞（blocked）
由于某种原因导致正在运行的线程让出CPU并暂停自己的执行，即进入堵塞状态。

	* 正在睡眠：用sleep(long t) 方法可使线程进入睡眠方式。一个睡眠着的线程在指定的时间过去可进入就绪状态。
	* 正在等待：调用wait()方法。（调用motify()方法回到就绪状态）
	* 被另一个线程所阻塞：调用suspend()方法。（调用resume()方法恢复）

## 2.常用方法
* void run()   创建该类的子类时必须实现的方法
* void start() 开启线程的方法
* static void sleep(long t) 释放CPU的执行权，不释放锁
* static void sleep(long millis,int nanos)
* final void wait()释放CPU的执行权，释放锁
* final void notify()
* static void yied()可以对当前线程进行临时暂停（让线程将资源释放出来）
##3 wait() 与notify()/notifyAll()
这三个方法都是Object的方法，并不是线程的方法！
* wait():释放占有的对象锁，线程进入等待池，释放cpu,而其他正在等待的线程即可抢占此锁，获得锁的线程即可运行程序。而sleep()不同的是，线程调用此方法后，会休眠一段时间，休眠期间，会暂时释放cpu，但并不释放对象锁。也就是说，在休眠期间，其他线程依然无法进入此代码内部。休眠结束，线程重新获得cpu,执行代码。wait()和sleep()最大的不同在于wait()会释放对象锁，而sleep()不会！ 
* notify(): 该方法会唤醒因为调用对象的wait()而等待的线程，其实就是对对象锁的唤醒，从而使得wait()的线程可以有机会获取对象锁。调用notify()后，并不会立即释放锁，而是继续执行当前代码，直到synchronized中的代码全部执行完毕，才会释放对象锁。JVM则会在等待的线程中调度一个线程去获得对象锁，执行代码。需要注意的是，wait()和notify()必须在synchronized代码块中调用。
* notifyAll()则是唤醒所有等待的线程。

#单列索引、组合索引
* 在 vc_Name字段 上建立了索引，查询时MYSQL不用扫描整张表，效率有所提高
* 在 vc_City 和 i_Age 分别建立的MySQL单列索引的效率相似。
* 如果分别在 vc_Name,vc_City，i_Age 上建立单列索引，让该表有 3 个单列索引，查询时和上述的组合索引效率，远远低于的组合索引。虽然此时有了三个索引，但 MySQL 只能用到其中的那个它认为似乎是最有效率的单列索引。
* 在什么情况下建立索引呢?一般来说，在WHERE和JOIN中出现的列需要建立索引，但也不完全如此，因为MySQL只对<，<=，=，>，>=，BETWEEN，IN，以及某些时候的LIKE才会使用索引


#oracle
打开cmd输入sqlplus

```
sqlplus
sys/manager as sysdba，以超级管理员的权限登录数据库
create user c##用户名 identified by 密码; 
授权
为刚创建的用户解锁：alter user c##用户名 account unlock;
授予新用户创建权限：grant create session to  c##用户名 ;
授予新用户数据库管理员权限：grant dba to c##用户名;
授予用户其它权限：
   GRANT CREATE USER,DROP USER,ALTER USER ,
            CREATE  ANY  VIEW , DROP ANY VIEW,
            EXP_FULL_DATABASE,IMP_FULL_DATABASE, 
            DBA,CONNECT,RESOURCE,CREATE SESSION  TO  c##用户名;  

```
到此，用户就创建成功了，到https://localhost:5500/em登录试试，登录成功。不过不能以管理员权限登录。 不用输入容器名

打开监控链接
https://jingyan.baidu.com/article/03b2f78c7a0ab75ea237ae33.html


# mysql 与 oracle
* oracle

由于其诞生早、结构严谨、高可用、高性能等特点，使其在传统数据库应用中大杀四方，金融、通信、能源、运输、零售、制造等各个行业的大型公司基本都是用了Oracle，早些年的时候，世界500强几乎100%都是Oracle的用户

主要在传统行业的数据化业务中，比如：银行、金融这样的对可用性、健壮性、安全性、实时性要求极高的业务；零售、物流这样对海量数据存储分析要求很高的业务。此外，高新制造业如芯片厂也基本都离不开Oracle；电商也有很多使用者，如京东（正在投奔Oracle）、阿里巴巴（计划去Oracle化）

* MySQL

MySQL的最初的核心思想，主要是开源、简便易用.
MySQL基本是生于互联网，长于互联网。其应用实例也大都集中于互联网方向，MySQL的高并发存取能力并不比大型数据库差，同时价格便宜，安装使用简便快捷，深受广大互联网公司的喜爱。

##为什么需要MyCat？

虽然云计算时代，传统数据库存在着先天性的弊端，但是NoSQL数据库又无法将其替代。如果传统数据易于扩展，可切分，就可以避免单机（单库）的性能缺陷。

MyCat的目标就是：低成本地将现有的单机数据库和应用平滑迁移到“云”端，解决数据存储和业务规模迅速增长情况下的数据瓶颈问题。2014年MyCat首次在上海的《中华架构师》大会上对外宣讲引发围观，更多的人参与进来，随后越来越多的项目采用了MyCat。

MyCat截至到2015年4月，保守估计已经有超过60个项目在使用，主要应用在电信领域、互联网项目，大部分是交易和管理系统，少量是信息系统。比较大的系统中，数据规模单表单月30亿。

##MyCat是什么？

从定义和分类来看，它是一个开源的分布式数据库系统，是一个实现了MySQL协议的服务器，前端用户可以把它看作是一个数据库代理，用MySQL客户端工具和命令行访问，而其后端可以用MySQL原生协议与多个MySQL服务器通信，也可以用JDBC协议与大多数主流数据库服务器通信，其核心功能是分表分库，即将一个大表水平分割为N个小表，存储在后端MySQL服务器里或者其他数据库里。

MyCat发展到目前的版本，已经不是一个单纯的MySQL代理了，它的后端可以支持MySQL、SQL Server、Oracle、DB2、PostgreSQL等主流数据库，也支持MongoDB这种新型NoSQL方式的存储，未来还会支持更多类型的存储。而在最终用户看来，无论是那种存储方式，在MyCat里，都是一个传统的数据库表，支持标准的SQL语句进行数据的操作，这样一来，对前端业务系统来说，可以大幅降低开发难度，提升开发速度

#Docker
##docker 机制与原理
docker是lxc的管理器，lxc是cgroup的管理工具，cgroup是namespace的用户空间的管理接口。namespace是linux内核在task_struct中对进程组管理的基础机制。

  Linux 内核从版本 2.4.19 开始陆续引入了 namespace 的概念。其目的是将某个特定的全局系统资源（global system resource）通过抽象方法使得namespace 中的进程看起来拥有它们自己的隔离的全局系统资源实例


#编码
##UTF-8
UTF-8（8-bit Unicode Transformation Format）是一种针对Unicode的可变长度字符编码，又称万国码。

 为了提高Unicode的编码效率，于是就出现了UTF-8编码。UTF-8可以根据不同的符号自动选择编码的长短。比如英文字母可以只用1个字节就够了。
 
 mysql支持的 utf8 编码最大字符长度为 3 字节，如果遇到 4 字节的宽字符就会插入异常了
 
 
##超集
 如果一个集合S2中的每一个元素都在集合S1中，且集合S1中可能包含S2中没有的元素，则集合S1就是S2的一个超集，反过来，S2是S1的子集。 S1是S2的超集，若S1中一定有S2中没有的元素，则S1是S2的真超集，反过来S2是S1的真子集。



#算法
##排序算法的稳定性？
排序算法可以根据稳定性分为两种：稳定和非稳定算法。那么怎么区分它们？

如果链表中存在两个相同元素，稳定排序算法可以在排序之后保持他两原来的次序，而非稳定性的则不能保证

##简单排序类别

有两种简单排序算法分别是插入排序和选择排序，两个都是数据量小时效率高。实际中插入排序一般快于选择排序，由于更少的比较和在有差不多有序的集合表现更好的性能。但是选择排序用到更少的写操作，所以当写操作是一个限制因素时它被使用到。




##希尔排序的时间性能优于直接插入排序的原因：
当文件初态基本有序时直接插入排序所需的比较和移动次数均较少。
当n值较小时，n和n2的差别也较小，即直接插入排序的最好时间复杂度O(n)和最坏时间复杂度0(n2)差别不大。
在希尔排序开始时增量较大，分组较多，每组的记录数目少，故各组内直接插入较快，后来增量di逐渐缩小，分组数逐渐减少，而各组的记录数目逐渐增多，但由于已经按di-1作为距离排过序，使文件较接近于有序状态，所以新的一趟排序过程也较快。



##插入排序与选择排序的区别

插入排序类似于选择排序，不同之处是插入排序是一个元素一个元素地往有序序列中插入，而选择排序则是在无序序列中选择最大(最小)元素放入有序队列末尾。一个主要操作有序队列，一个则是无序队列。这样就导致选择排序每次都要遍历一次无序队列，而插入排序则不需要遍历整个有序队列，只需要遍历到该元素应有的位置即可，这样就使得基本有序的队列的复杂度为O(n).
但同时这会导致插入排序用到更多的写操作，因为内部循环时他对数组进行大量的移位操作，大家知道移位操作对于数组是非常低效率的。而选择排序因为每次添加元素都是添加在末尾，所以不需要移位操作

##为什么梳排序和希尔排序都可以通过分组来提高效率呢？
因为插入排序和冒泡排序有几个相似的点：1.当文件初态基本有序时时间复杂度为O(n). 2.数据量小时效率更好，因为最好情况n和最坏情况n^2相差不大。


##归并
分治法 先"分割"再"合并"





#堆、栈、堆栈、队列
##堆：
###什么是堆？又该怎么理解呢？
* ①堆通常是一个可以被看做一棵树的数组对象。堆总是满足下列性质：
   ·堆中某个节点的值总是不大于或不小于其父节点的值；
   ·堆总是一棵完全二叉树。
将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。常见的堆有二叉堆、斐波那契堆等。
* ②堆是在程序运行时，而不是在程序编译时，申请某个大小的内存空间。即动态分配内存，对其访问和对一般内存的访问没有区别。
* ③堆是应用程序在运行的时候请求操作系统分配给自己内存，一般是申请/给予的过程。
* ④堆是指程序运行时申请的动态内存，而栈只是指一种使用堆的方法(即先进后出)。
父节点比子节点大的称为最大堆：
父节点比子节点小的为最小堆：
##栈：
###什么是栈？又该怎么理解呢？
* ①栈（stack）又名堆栈，它是一种运算受限的线性表。其限制是仅允许在表的一端进行插入和删除运算。这一端被称为栈顶，相对地，把另一端称为栈底。
* ②栈就是一个桶，后放进去的先拿出来，它下面本来有的东西要等它出来之后才能出来（先进后出）
* ③栈(Stack)是操作系统在建立某个进程时或者线程（在支持多线程的操作系统中是线程）为这个线程建立的存储区域，该区域具有FIFO的特性，在编译的时候可以指定需要的Stack的大小。

###堆栈：什么是堆栈？又该怎么理解呢？
* 注意：其实堆栈本身就是栈，只是换了个抽象的名字。
* 堆栈的特性： 最后一个放入堆栈中的物体总是被最先拿出来， 这个特性通常称为后进先出(LIFO)队列。 堆栈中定义了一些操作。 
* 两个最重要的是PUSH和POP。 PUSH操作在堆栈的顶部加入一 个元素。POP操作相反， 在堆栈顶部移去一个元素， 并将堆栈的大小减一。

###堆、栈区别总结：
####1.堆栈空间分配
 * ①栈（操作系统）：由操作系统自动分配释放 ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。
 * ②堆（操作系统）： 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收，分配方式倒是类似于链表。
 
####2.堆栈缓存方式
* ①栈使用的是一级缓存， 他们通常都是被调用时处于存储空间中，调用完毕立即释放。
* ②堆则是存放在二级缓存中，生命周期由虚拟机的垃圾回收算法来决定（并不是一旦成为孤儿对象就能被回收）。所以调用这些对象的速度要相对来得低一些。

####3.堆栈数据结构区别
* ①堆（数据结构）：堆可以被看成是一棵树，如：堆排序。
* ②栈（数据结构）：一种先进后出的数据结构。

##队列：什么是队列？又该怎么理解呢？
* ①队列是一种特殊的线性表，特殊之处在于它只允许在表的前端（front）进行删除操作，而在表的后端（rear）进行插入操作，和栈一样，队列是一种操作受限制的线性表。进行插入操作的端称为队尾，进行删除操作的端称为队头。
* ②队列中没有元素时，称为空队列。
* ③建立顺序队列结构必须为其静态分配或动态申请一片连续的存储空间，并设置两个指针进行管理。一个是队头指针front，它指向队头元素；另一个是队尾指针rear，它指向下一个入队元素的存储位置。
* ④队列采用的FIFO(first in first out)，新元素（等待进入队列的元素）总是被插入到链表的尾部，而读取的时候总是从链表的头部开始读取。每次读取一个元素，释放一个元素。所谓的动态创建，动态释放。因而也不存在溢出等问题。由于链表由结构体间接而成，遍历也方便。（先进先出）

###堆、栈、队列之间的区别是？
* ①堆是在程序运行时，而不是在程序编译时，申请某个大小的内存空间。即动态分配内存，对其访问和对一般内存的访问没有区别。
* ②栈就是一个桶，后放进去的先拿出来，它下面本来有的东西要等它出来之后才能出来。（后进先出）
* ③队列只能在队头做删除操作,在队尾做插入操作.而栈只能在栈顶做插入和删除操作。（先进先出）

###完全二叉树：
叶节点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树
###二叉排序树
二叉排序树或者是一棵空树，或者是具有下列性质的二叉树：

* （1）若左子树不空，则左子树上所有结点的值均小于或等于它的根结点的值；
* （2）若右子树不空，则右子树上所有结点的值均大于或等于它的根结点的值；
* （3）左、右子树也分别为二叉排序树；


##什么是CGI
1. 定义：
CGI(Common Gateway Interface)是HTTP服务器与你的或其它机器
上的程序进行“交谈”的一种工具，其程序须运行在网络服务器上。

最早的Web服务器简单地响应浏览器发来的HTTP请求，并将存储在服务器上的HTML文件返回给浏览器，也就是静态html。事物总是不 断发展，网站也越来越复杂，所以出现动态技术。但是服务器并不能直接运行 php，asp这样的文件，自己不能做，外包给别人吧，但是要与第三做个约定，我给你什么，然后你给我什么，就是握把请求参数发送给你，然后我接收你的处 理结果给客户端。那这个约定就是 common gateway interface，简称cgi。这个协议可以用vb，c，php，python 来实现。cgi只是接口协议，

##声明试

先把图建立出来才会运行


##定义式

rnn 循环神经网络

lstm  长短时记忆神经网路


## Git代码回滚
1. 重置－－混合合并到 需要重置的历史节点
2. 重置－－软合并到当前节点 ，此时即可获取到从历史节点到当前节点的所有修改记录，此时可以修改文件，进行新的提交。

# Iaas SaaS PaaS
* IaaS（Infrastructure as a Service）基础设施即服务
* SaaS（Software as a Service）软件即服务
* PaaS（Platform as a Service）平台即服务

#Redis（需更新）
redis 的高性能。亚毫秒延迟得益于经过优化的数据结构，由于让操作可以在邻近数据存储的地方执行，提高了效率。这种数据结构不仅可以高效地利用内存、降低应用程序的复杂性，还降低了网络开销、带宽消耗量和处理时间。


###redis的hash

redis 的hash 数据结构为 <key,hashMap>，jedis 将 hash 的key 和 value 用 SafeEncoder 进行编码 放hashMap，并将 key 也进行编码


###Redis
Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。

##Redis集群介绍
http://www.redis.cn/topics/cluster-tutorial.html

Redis 集群是一个提供在多个Redis间节点间共享数据的程序集。

Redis集群并不支持处理多个keys的命令,因为这需要在不同的节点间移动数据,从而达不到像Redis那样的性能,在高负载的情况下可能会导致不可预料的错误.

Redis 集群通过分区来提供一定程度的可用性,在实际环境中当某个节点宕机或者不可达的情况下继续处理命令. Redis 集群的优势:

自动分割数据到不同的节点上。
整个集群的部分节点失败或者不可达的情况下能够继续处理命令。
###Redis 集群的数据分片
Redis 集群没有使用一致性hash, 而是引入了 哈希槽的概念.

Redis 集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽.集群的每个节点负责一部分hash槽,举个例子,比如当前集群有3个节点,那么:

节点 A 包含 0 到 5500号哈希槽.
节点 B 包含5501 到 11000 号哈希槽.
节点 C 包含11001 到 16384号哈希槽.
这种结构很容易添加或者删除节点. 比如如果我想新添加个节点D, 我需要从节点 A, B, C中得部分槽到D上. 如果我像移除节点A,需要将A中得槽移到B和C节点上,然后将没有任何槽的A节点从集群中移除即可. 由于从一个节点将哈希槽移动到另一个节点并不会停止服务,所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态.
###Redis 集群的主从复制模型
为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有N-1个复制品.

在我们例子中具有A，B，C三个节点的集群,在没有复制模型的情况下,如果节点B失败了，那么整个集群就会以为缺少5501-11000这个范围的槽而不可用.

然而如果在集群创建的时候（或者过一段时间）我们为每个节点添加一个从节点A1，B1，C1,那么整个集群便有三个master节点和三个slave节点组成，这样在节点B失败后，集群便会选举B1为新的主节点继续服务，整个集群便不会因为槽找不到而不可用了

不过当B和B1 都失败后，集群是不可用的.

###Redis 一致性保证
Redis 并不能保证数据的强一致性. 这意味这在实际中集群在特定的条件下可能会丢失写操作.

第一个原因是因为集群是用了异步复制. 写操作过程:

客户端向主节点B写入一条命令.
主节点B向客户端回复命令状态.
主节点将写操作复制给他得从节点 B1, B2 和 B3.
主节点对命令的复制工作发生在返回命令回复之后， 因为如果每次处理命令请求都需要等待复制操作完成的话， 那么主节点处理命令请求的速度将极大地降低 —— 我们必须在性能和一致性之间做出权衡。 注意：Redis 集群可能会在将来提供同步写的方法。 Redis 集群另外一种可能会丢失命令的情况是集群出现了网络分区， 并且一个客户端与至少包括一个主节点在内的少数实例被孤立。

举个例子 假设集群包含 A 、 B 、 C 、 A1 、 B1 、 C1 六个节点， 其中 A 、B 、C 为主节点， A1 、B1 、C1 为A，B，C的从节点， 还有一个客户端 Z1 假设集群中发生网络分区，那么集群可能会分为两方，大部分的一方包含节点 A 、C 、A1 、B1 和 C1 ，小部分的一方则包含节点 B 和客户端 Z1 .

Z1仍然能够向主节点B中写入, 如果网络分区发生时间较短,那么集群将会继续正常运作,如果分区的时间足够让大部分的一方将B1选举为新的master，那么Z1写入B中得数据便丢失了.
（解释：也就是说B节点 和Z1 网络是畅通的，但是A 、C 、A1 、B1 和 C1 和B节点的网络是不通的，B是主节点，也就是需要一段时间（timeout）后 B 节点才会失效，B1被选举为主节点，在这段时间内Z1还是可以向B节点写数据，这部分数据也就丢失了。）

注意， 在网络分裂出现期间， 客户端 Z1 可以向主节点 B 发送写命令的最大时间是有限制的， 这一时间限制称为节点超时时间（node timeout）， 是 Redis 集群的一个重要的配置选项：

##微服务的优点
* 解耦，分解巨大单体式应用为多个服务方法解决了复杂性问题
* 独立发布，动态扩容，每个微服务独立的部署。
* 改善故障隔离。一个服务宕机不会影响其他的服务，每个服务独立扩展。
* 每个单体应用不局限于固定的技术栈，开发者可以自由选择开发技术，提供API服务
* 单一职责功能，每个服务都很简单，只关注于一个业务功能

##微服务的缺点
* 服务管理
* 测试工作更加困难
* 很难在不采用分布式事务的情况下跨服务实现功能
* 部署复杂度增高
* 内存占用曾高
#时间复杂度
##定义
时间复杂度是一个函数，它定性描述了该算法的运行时间。这是一个关于代表算法输入值的字符串的长度的函数。时间复杂度常用大O符号表述，不包括这个函数的低阶项和首项系数。
##计算
* 一般情况下，算法中基本操作重复执行的次数是问题规模n的某个函数，用T(n)表示，若有某个辅助函数f(n)，使得T(n)/f(n)的极限值（当n趋近于无穷大时）为不等于零的常数，则称f(n)是T(n)的同数量级函数。记作T(n)=O(f(n))，称O(f(n)) 为算法的渐进时间复杂度，简称时间复杂度。

* 分析：随着模块n的增大，算法执行的时间的增长率和 f(n) 的增长率成正比，所以 f(n) 越小，算法的时间复杂度越低，算法的效率越高。

* 在pascal中比较容易理解，容易计算的方法是：看看有几重for循环，只有一重则时间复杂度为O(n)，二重则为O(n^2)，依此类推，如果有二分则为O(logn)，二分例如快速幂、二分查找，如果一个for循环套一个二分，那么时间复杂度则为O(nlogn)。

