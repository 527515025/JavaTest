# GET和POST

##MVC

MVC本来是存在于Desktop程序中的，M是指数据模型，V是指用户界面，C则是控制器。使用MVC的目的是将M和V的实现代码分离，从而使同一个程序可以使用不同的表现形式。

##"GET方式提交的数据最多只能是1024字节"?  错

因为GET是通过URL提交数据，那么GET可提交的数据量就跟URL的长度有直接关系了。而实际上，URL不存在参数上限的问题，HTTP协议规范没有对URL长度进行限制。这个限制是特定的浏览器及服务器对它的限制。IE对URL长度的限制是2083字节(2K+35)。对于其他浏览器，如Netscape、FireFox等，理论上没有长度限制，其限制取决于操作系统的支持。

Get是向服务器发索取数据的一种请求，而Post是向服务器提交数据的一种请求，在FORM（表单）中，Method默认为"GET"，实质上，GET和POST只是发送机制不同，并不是一个取一个发！

##GET & POST

GET请求会被浏览器主动cache，而POST不会，除非手动设置。 GET请求只能进行url编码，而POST支持多种编码方式。 GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。 GET请求在URL中传送的参数是有长度限制的，而POST么有。 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。 GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。 GET参数通过URL传递，POST放在Request body中。

GET和POST是什么?HTTP协议中的两种发送请求的方法。
**HTTP的底层是TCP/IP。所以GET和POST的底层也是TCP/IP，也就是说，GET/POST都是TCP链接**。GET和POST能做的事情是一样一样的。你要给GET加上request body，给POST带上url参数，技术上是完全行的通的。


##GET & POST 重大区别

GET产生一个TCP数据包;POST产生两个TCP数据包。

对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200(返回数据);
而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)。

也就是说，GET只需要汽车跑一趟就把货送到了，而POST得跑两趟，第一趟，先去和服务器打个招呼“嗨，我等下要送一批货来，你们打开门迎接我”，然后再回头把货送过去。

1. GET与POST都有自己的语义，不能随便混用。
2. 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。
3. 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。

##PUT

在HTTP中，PUT被定义为idempotent的方法，POST则不是，这是一个很重要的区别。

PUT操作是幂等的。所谓幂等是指不管进行多少次操作，结果都一样。比如我用PUT修改一篇文章，然后在做同样的操作，每次操作后的结果并没有不同

##汽车TCP

在我大万维网世界中，TCP就像汽车，我们用TCP来运输数据，它很可靠，从来不会发生丢件少件的现象。

##交通规则HTTP 

HTTP给汽车运输设定了好几个服务类别，有GET, POST, PUT, DELETE等等，HTTP规定，当执行GET请求的时候，要给汽车贴上GET的标签(设置method为GET)，而且要求把传送的数据放在车顶上(url中)以方便记录。如果是POST请求，就要在车上贴上POST的标签，并把货物放在车厢里。当然，你也可以在GET的时候往车厢内偷偷藏点货物，但是这是很不光彩;也可以在POST的时候在车顶上也放一些数据，让人觉得傻乎乎的。HTTP只是个行为准则，而TCP才是GET和POST怎么实现的基本。

##运输公司 浏览器

不同的浏览器(发起http请求)和服务器(接受http请求)就是不同的运输公司。

虽然理论上，你可以在车顶上无限的堆货物(url中无限加参数)。但是运输公司可不傻，装货和卸货也是有很大成本的，他们会限制单次运输量来控制风险，数据量太大对浏览器和服务器都是很大负担。业界不成文的规定是，(大多数)浏览器通常都会限制url长度在2K个字节，而(大多数)服务器最多处理64K大小的url。超过的部分，恕不处理。如果你用GET服务，在request body偷偷藏了数据，不同服务器的处理方式也是不同的，有些服务器会帮你卸货，读出数据，有些服务器直接忽略，所以，虽然GET可以带request body，也不能保证一定能被接收到哦。

# HTTP 

HTTP 超文本传输协议 (HTTP-Hypertext transfer protocol) 是一种基于文本的传输协议，详细规定了浏览器和万维网服务器之间互相通信的规则，过因特网传送万维网文档的数据传送协议。它位于 OSI 网络模型中的应用层。

HTTP通过**客户端和服务器的请求应答来进行通讯**，目前协议由之前的 RFC 2616 拆分成立六个单独的协议说明（RFC 7230、RFC 7231、RFC 7232、RFC 7233、RFC 7234、RFC 7235），通讯报文如下：

## OSI的七层网络结构 

OSI的七层网络结构模型（虽然实际应用中基本上都是五层），它可以分为以下几层：（从上到下）

- 第一层：应用层。定义了用于在网络中进行通信和传输数据的接口；允许访问OSI环境的手段（应用协议数据单元APDU）
- 第二层：表示层。定义不同的系统中数据的传输格式，编码和解码规范、加解密等；
- 第三层：会话层。管理用户的会话，控制用户间逻辑连接的建立和中断；
- 第四层：传输层。管理着网络中的端到端的数据传输；提供端到端的可靠报文传递和错误恢复（段Segment）
- 第五层：网络层。定义网络设备间如何传输数据；负责数据包从源到宿的传递和网际互连（包PackeT）
- 第六层：链路层。将上面的网络层的数据包封装成数据帧，便于物理层传输；将比特组装成帧和点到点的传递（帧Frame）
- 第七层：物理层。这一层主要就是传输这些二进制数据。通过媒介传输比特,确定机械及电气规范（比特Bit）

**TCP/IP分层（4层）**：网络接口层、 网际层、运输层、 应用层。

**五层协议 （5层）**：物理层、数据链路层、网络层、运输层、 应用层。

实际应用过程中，五层协议结构里面是没有**表示层和会话层的。应该说它们和应用层合并了**。我们应该将重点放在应用层和传输层这两个层面。因为**HTTP是应用层协议**，而**TCP是传输层协议**

**每一层的协议如下：**

物理层：RJ45、CLOCK、IEEE802.3   （中继器，集线器，网关）；

数据链路：PPP、FR、HDLC、VLAN、MAC  （网桥，交换机）；

网络层：IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP、 （路由器）；

传输层：TCP、UDP、SPX；

会话层：NFS、SQL、NETBIOS、RPC；

表示层：JPEG、MPEG、ASII；

应用层：FTP、DNS、Telnet、SMTP、HTTP、WWW、NFS；**RPC服务**

## HTTP 中间人攻击

HTTP 协议使用起来确实非常的方便，但是它存在一个致命的缺点：不安全。

我们知道 HTTP 协议中的报文都是以明文的方式进行传输，不做任何加密。在 HTTP 传输过程中，中间人能看到并且修改 HTTP 通讯中所有的请求和响应内容，所以使用 HTTP 是非常的不安全的。

1.  攻防：防止中间人攻击将**报文加密AES**加密算法，如果第一次通信被拦截到了，那么秘钥就会泄露给中间人，中间人仍然可以解密后续的通信。

2. 防：采用**非对称加密**，我们可以通过 **RSA** 算法来实现。由服务器生成一对公私钥，服务器将公钥返回给客户端，客户端本地生成一串秘钥(AES_KEY)用于对称加密，并通过服务器发送的公钥进行加密得到(AES_KEY_SECRET)，之后返回给服务端，服务端通过私钥将客户端发送的AES_KEY_SECRET进行解密得到AEK_KEY,最后客户端和服务器通过AEK_KEY进行报文的加密通讯

3. 攻：中间人为了对应这种加密方法又想出了一个新的破解方案，既然拿不到AES_KEY，那我就**把自己模拟成一个客户端和服务器端的结合体**，在用户->中间人的过程中中间人模拟服务器的行为，这样可以拿到**用户请求的明文**，在中间人->服务器的过程中中间人模拟客户端行为，这样**可以拿到服务器响应的明文**。以此来进行中间人攻击，通信再次被中间人截获，中间人自己也伪造了一对公私钥，并将公钥发送给用户以此来窃取客户端生成的AES_KEY，在拿到AES_KEY之后就能轻松的进行解密了

##Https

HTTPS（全称：Hypertext Transfer Protocol over Secure Socket Layer），**是以安全为目标的HTTP通道，简单讲是HTTP的安全版**。即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。

HTTPS 其实是SSL+HTTP的简称,当然现在SSL基本已经被TLS取代了，不过我们还是统一以SSL作为简称，SSL协议其实不止是应用在HTTP协议上，还在应用在各种应用层协议上，例如：FTP、WebSocket。

其实SSL协议**大致就和上一节非对称加密**的性质一样，握手的过程中主要也是为了交换秘钥，然后再通讯过程中使用对称加密进行通讯，大概流程如下：


##http和https区别

**https协议需要到ca申请证书**，一般免费证书很少，需要交费。http是超文本传输协议，信息是明文传输，https 则是具有安全性的ssl加密传输协议http和https使用的是完全不同的连接方式用的端口也不一样,前者是80,后者是443。http的连接很简单,是无状态的HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、

http的连接很简单,是无状态的。HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议 要比http协议安全

### 为什么用了 HTTPS 就是安全的？

大家可能都听说过 HTTPS 协议之所以是安全的是因为 HTTPS 协议会对传输的数据进行加密，而加密过程是使用了**非对称加密实现**。但其实，**HTTPS 在内容传输的加密上使用的是对称加密，非对称加密只作用在证书验证阶段**。

HTTPS 的整体过程分为证书验证和数据传输阶段，

**证书验证阶段：**

- 浏览器发起 HTTPS 请求。
- 服务端返回 HTTPS 的 ssl 证书。通过 SSL 证书来传递公钥
- 客户端验证ssl证书是否合法，如果不合法则提示告警。证书认证体系CA认证就是确保SSL安全的关键

**数据传输阶段：**

- 当证书验证合法后，在本地生成随机数。
- 通过公钥加密随机数，并把加密后的随机数传输到服务端。
- 服务端通过私钥对随机数进行解密。
- 服务端通过客户端传入的随机数构造对称加密算法，对返回结果内容进行加密后传输。

### CA认证体系

客户端是通过 权威认证机构 校验服务器 SSL 证书的安全性。

在 CA 认证体系中，所有的证书都是由权威机构来颁发，而权威机构的 CA 证书都是已经在操作系统中内置的，我们把这些证书称之为CA根证书。

**签发证书**

我们的**应用服务器**如果想要使用 SSL 的话，需要**通过权威认证机构来签发CA证书**，我们**将服务器生成的公钥和站点相关信息发送给CA签发机构**，再由CA签发机构通过服务器发送的相关信息用CA签发机构进行加签，由此得到我们**应用服务器的证书**，证书会对应的生成证书内容的签名，并将该签名使用CA签发机构的**私钥**进行**加密得到证书指纹**，并且**与上级证书生成关系链**。

**如何验证服务器证书**

那么客户端(浏览器)又是如何对服务器证书做校验的呢，首先会**通过层级关系找到上级证书**，通过上级证书里的**公钥**来对服务器的**证书指纹进行解密**得到签名(sign1)，再通过签名算法算出服务器证书的签名(sign2)，通过对比sign1和sign2，如果相等就说明证书是没有被篡改也不是伪造的。

证书**校验用的 RSA 是通过私钥加密证书签名，公钥解密来巧妙的验证证书有效性**。

这样通过证书的认证体系，我们就可以避免了中间人窃取AES_KEY从而发起拦截和修改 HTTP 通讯的报文。

### 为什么数据传输是用对称加密？

首先，**非对称加密的加解密效率是非常低**的，而 HTTP 的应用场景中通常端与端之间存在大量的交互，非对称加密的效率是无法接受的。

另外，在 HTTPS 的场景中只有服务端保存了私钥，一对公私钥只能实现单向的加解密，所以 HTTPS 中内容传输加密采取的是对称加密，而不是非对称加密。

### 总结：

https 首先传递ssl证书和验证证书，非对称加密，数据传输堆成加密

# TCP/IP

TCP/IP协议模型（Transmission Control Protocol/Internet Protocol），包含了一系列构成互联网基础的网络协议，是Internet的核心协议。

基于TCP/IP的参考模型将协议分成四个层次，它们分别是**链路层、网络层、传输层和应用层**。下图表示TCP/IP模型与OSI模型各层的对照关系。

![image-20201210164904774](/Users/yangyibo/Library/Application Support/typora-user-images/image-20201210164904774.png)

TCP/IP协议族按照层次由上到下，层层包装。最上面的是应用层，这里面有http，ftp 等等我们熟悉的协议。而**第二层则是传输层，著名的TCP和UDP协议就在这个层次**。第三层是**网络层，IP协议就在这里，它负责对数据加上IP地址和其他的数据以确定传输的目标**。第四层是数据链路层，这个层次为待传送的数据**加入一个以太网协议头，并进行CRC编码**，为最后的数据传输做准备。

![image-20201210165018295](/Users/yangyibo/Library/Application Support/typora-user-images/image-20201210165018295.png)

上图清楚地表示了TCP/IP协议中每个层的作用，而TCP/IP协议通信的过程其实就对应着数据**入栈与出栈**的过程。**入栈的过程，数据发送方每层不断地封装首部与尾部，添加一些传输的信息，确保能传输到目的地。出栈的过程，数据接收方每层不断地拆除首部与尾部，得到最终传输的数据**。

HTTP协议为例，具体说明

![image-20201210165651321](/Users/yangyibo/Library/Application Support/typora-user-images/image-20201210165651321.png)

## 数据链路层

**物理层负责0、1比特流与物理设备电压高低、光的闪灭之间的互换**。**数据链路层负责将0、1序列划分为数据帧从一个节点传输到临近的另一个节点,这些节点是通过MAC来唯一标识的**(MAC,物理地址，一个主机会有一个MAC地址)。

![image-20201210165858702](/Users/yangyibo/Library/Application Support/typora-user-images/image-20201210165858702.png)

- 封装成帧: 把网络层数据报加头和尾，封装成帧,帧头中包括源MAC地址和目的MAC地址。
- 透明传输:零比特填充、转义字符。
- 可靠传输: 在出错率很低的链路上很少用，但是无线链路WLAN会保证可靠传输。
- 差错检测(CRC):接收者检测错误,如果发现差错，丢弃该帧。

## 网络层

### IP协议

IP协议是TCP/IP协议的核心，所有的**TCP，UDP，IMCP，IGMP的数据都以IP数据格式传输**。要注意的是，**IP不是可靠的协议**，这是说，IP协议没有提供一种数据未传达以后的处理机制，这被认为是上层协议：TCP或UDP要做的事情。

### IP地址

在**数据链路层中我们一般通过MAC地址来识别不同的节点**，而在IP层我们也要有一个类似的地址标识，这就是IP地址。

**32位IP地址分为网络位和地址位**，这样做**可以减少路由器中路由表记录的数目**，有了网络地址，就可以**限定拥有相同网络地址的终端都在同一个范围内**，那么路由表只需要维护一条这个网络地址的方向，就可以找到相应的这些终端了。

A类IP地址: 0.0.0.0~127.0.0.0
B类IP地址:128.0.0.1~191.255.0.0
C类IP地址:192.168.0.0~239.255.255.0

### IP协议头

![image-20201210170106938](/Users/yangyibo/Library/Application Support/typora-user-images/image-20201210170106938.png)

这里只介绍:八位的**TTL字段**。这个字段规定**该数据包在穿过多少个路由之后才会被抛弃。某个IP数据包每穿过一个路由器，该数据包的TTL数值就会减少1，当该数据包的TTL成为零，它就会被自动抛弃**。

这个字段的最大值也就是255，也就是说一个协议包也就在路由器里面穿行255次就会被抛弃了，根据系统的不同，这个数字也不一样，一般是32或者是64。

### ARP及RARP协议

ARP 是**根据IP地址获取MAC地址的一种协议**。

ARP（地址解析）协议是一种解析协议，本来主机是完全**不知道这个IP对应的是哪个主机的哪个接口**，当主机要发送一个IP包的时候，会首先查一下自己的ARP高速缓存（就是一个IP-MAC地址对应表缓存）。

如果查询的IP－MAC值对不存在，那么主机就向网络发送一个ARP协议广播包，这个广播包里面就有待查询的IP地址，而直接收到这份广播的包的所有主机都会查询自己的IP地址，如果收到广播包的某一个主机发现自己符合条件，那么就准备好一个包含自己的MAC地址的ARP包传送给发送ARP广播的主机。

而广播主机拿到ARP包后会更新自己的ARP缓存（就是存放IP-MAC对应表的地方）。发送广播的主机就会用新的ARP缓存数据准备好数据链路层的的数据包发送工作。

RARP协议的工作与此相反，不做赘述。通过MAC地址获取IP地址

### 3、ICMP协议

IP协议并是一个**不可靠**的协议，它不保证数据被送达，那么，自然的，保证数据送达的工作应该由其他的模块来完成。其中一个重要的模块就是ICMP(网络控制报文)协议。**ICMP是IP层的协议**。

当传送IP数据包发生错误。比如主机不可达，路由不可达等等，ICMP协议将会把错误信息封包，然后传送回给主机。给主机一个处理错误的机会，这 也就是为什么说建立在IP层以上的协议是可能做到安全的原因。

#### ping

**ping可以说是ICMP的最著名的应用，是TCP/IP协议的一部分**。利用“ping”命令可以检查网络是否连通，可以很好地帮助我们分析和判定网络故障。它**利用ICMP协议包来侦测另一个主机是否可达**。原理是用**类型码为0的ICMP发**请求，受到请求的主机则用**类型码为8的ICMP**回应。

### 5、 Traceroute

Traceroute是用来侦测主机到目的主机之间所经路由情况的重要工具，也是最便利的工具。

它收到到目的主机的IP后，首先给目的主机发送一个TTL=1的UDP数据包，而经过的第一个路由器收到这个数据包以后，就自动把TTL减1，而TTL变为0以后，路由器就把这个包给抛弃了，并同时产生 一个主机不可达的ICMP数据报给主机。主机收到这个数据报以后再发一个TTL=2的UDP数据报给目的主机，然后刺激第二个路由器给主机发ICMP数据 报。如此往复直到到达目的主机。这样，traceroute就拿到了所有的路由器IP。

### 6、 TCP/UDP

TCP/UDP都是是传输层协议，但是两者具有不同的特性，同时也具有不同的应用场景，下面以图表的形式对比分析。

![image-20201210171930605](/Users/yangyibo/Library/Application Support/typora-user-images/image-20201210171930605.png)

**面向报文**

面向报文的传输方式是应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。若报文太长，则IP层需要分片，降低效率。若太短，会是IP太小。

**面向字节流**

面向字节流的话，虽然**应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流**。TCP有一个缓冲，**当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送**。

关于拥塞控制，流量控制，是TCP的重点，后面讲解。

![image-20201210172057349](/Users/yangyibo/Library/Application Support/typora-user-images/image-20201210172057349.png)

### 7、DNS

DNS（Domain Name System，域名系统），因特网上**作为域名和IP地址相互映射的一个分布式数据库**，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。**DNS协议运行在UDP协议之上，使用端口号53**。

## TCP连接的建立与终止

### 三次握手（面向连接）

![image-20201210172401904](/Users/yangyibo/Library/Application Support/typora-user-images/image-20201210172401904.png)

* **第一次握手**：**建立连接**。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认；

* **第二次握手**：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态；

* **第三次握手**：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。

#### 为什么不是两次？

根本原因: 无法确认客户端的接收能力。

分析如下:

如果是两次，你现在发了 SYN 报文想握手，但是这个包**滞留**在了当前的网络中迟迟没有到达，TCP 以为这是丢了包，于是重传，两次握手建立好了连接。

看似没有问题，但是连接关闭后，如果这个**滞留**在网路中的包到达了服务端呢？这时候由于是两次握手，服务端只要接收到然后发送相应的数据包，就默认**建立连接**，但是现在客户端已经断开了。

看到问题的吧，这就带来了连接资源的浪费。

#### 为什么不是四次？

三次握手的目的是确认双方`发送`和`接收`的能力，那四次握手可以嘛？

当然可以，100 次都可以。但为了解决问题，三次就足够了，再多用处就不大了。

#### 三次握手过程中可以携带数据么？

第三次握手的时候，可以携带。前两次握手不能携带数据。

如果前两次握手能够携带数据，那么一旦有人想攻击服务器，那么他只需要在第一次握手中的 SYN 报文中放大量数据，那么服务器势必会消耗更多的**时间**和**内存空间**去处理这些数据，增大了服务器被攻击的风险。

第三次握手的时候，客户端已经处于`ESTABLISHED`状态，并且已经能够确认服务器的接收、发送能力正常，这个时候相对安全了，可以携带数据。

### 四次挥手

![image-20201210172733999](/Users/yangyibo/Library/Application Support/typora-user-images/image-20201210172733999.png)

**第一次分手**：主机1（可以使客户端，也可以是服务器端），设置Sequence Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了；

**第二次分手**：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求；
**第三次分手**：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态；

**第四次分手**：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。

#### 等待2MSL的意义

如果不等待会怎样？

如果不等待，客户端直接跑路，当服务端还有很多数据包要给客户端发，且还在路上的时候，若客户端的端口此时刚好被新的应用占用，那么就接收到了无用数据包，造成数据包混乱。所以，最保险的做法是等服务器发来的数据包都死翘翘再启动新的应用。

那，照这样说一个 MSL 不就不够了吗，为什么要等待 2 MSL?

- 1 个 MSL 确保四次挥手中主动关闭方最后的 ACK 报文最终能达到对端
- 1 个 MSL 确保对端没有收到 ACK 重传的 FIN 报文可以到达

这就是等待 2MSL 的意义。

#### 为什么是四次挥手而不是三次？

TCP是全双工模式，双端都可以发送数据。服务端在接收到`FIN`, 往往不会立即返回`FIN`, 必须等到服务端所有的报文都发送完毕了，才能发`FIN`。因此先发一个`ACK`表示已经收到客户端的`FIN`，延迟一段时间才发`FIN`。这就造成了四次挥手。

#### 如果是三次挥手会有什么问题？

等于说服务端将`ACK`和`FIN`的发送合并为一次挥手，这个时候长时间的延迟可能会导致客户端误以为`FIN`没有到达客户端，从而让客户端不断的重发`FIN`。

### TCP流量控制

对于发送端和接收端而言，TCP 需要把发送的数据放到**发送缓存区**, 将接收的数据放到**接收缓存区**。

而流量控制索要做的事情，就是在通过**接收缓存区的大小，控制发送端的发送**。如果对方的接收缓存区满了，就不能再继续发送了。

利用**滑动窗口机制**可以很方便地在TCP连接上实现对发送方的流量控制。

#### TCP 滑动窗口

TCP 滑动窗口分为两种: **发送窗口**和**接收窗口**（rwnd）。TCP的窗口单位是字节

##### 发送窗口

发送端的滑动窗口结构如下:

![image-20201210173709979](/Users/yangyibo/Library/Application Support/typora-user-images/image-20201210173709979.png)

其中包含四大部分:

- 已发送且已确认
- 已发送但未确认
- 未发送但可以发送
- 未发送也不可以发送

其中有一些重要的概念，我标注在图中:

![image-20201210173727239](/Users/yangyibo/Library/Application Support/typora-user-images/image-20201210173727239.png)

发送窗口就是图中被框住的范围。SND 即`send`, WND 即`window`, UNA 即`unacknowledged`, 表示未被确认，NXT 即`next`, 表示下一个发送的位置。

##### 接收窗口

接收端的窗口结构如下:

![image-20201210173750199](/Users/yangyibo/Library/Application Support/typora-user-images/image-20201210173750199.png)

REV 即 `receive`，NXT 表示下一个接收的位置，WND 表示接收窗口大小。

#### 流量控制过程

首先双方三次握手，初始化各自的窗口大小，均为 200 个字节。

假如当前发送端给接收端发送 100 个字节，那么此时对于发送端而言，SND.NXT 当然要右移 100 个字节，也就是说当前的`可用窗口`减少了 100 个字节，这很好理解。

现在这 100 个到达了接收端，被放到接收端的缓冲队列中。不过此时由于大量负载的原因，接收端处理不了这么多字节，只能处理 40 个字节，剩下的 `60` 个字节被留在了缓冲队列中。

注意了，此时接收端的情况是处理能力不够用啦，你发送端给我少发点，所以此时接收端的接收窗口应该缩小，具体来说，缩小 60 个字节，由 200 个字节变成了 140 字节，因为缓冲队列还有 60 个字节没被应用拿走。

因此，接收端会在 ACK 的报文首部带上缩小后的滑动窗口 140 字节，发送端对应地调整发送窗口的大小为 140 个字节。

此时对于发送端而言，已经发送且确认的部分增加 40 字节，也就是 SND.UNA 右移 40 个字节，同时**发送窗口**缩小为 140 个字节。

这也就是**流量控制**的过程。尽管回合再多，整个控制的过程和原理是一样的。

### TCP拥塞控制

**流量控制**发生在发送端跟接收端之间，并没有考虑到整个网络环境的影响，如果说当前网络特别差，特别容易丢包，那么发送端就应该注意一些了。而这，也正是`拥塞控制`需要处理的问题。

对于拥塞控制来说，TCP 每条连接都需要维护两个核心状态:

- 拥塞窗口（Congestion Window，cwnd）
- 慢启动阈值（Slow Start Threshold，ssthresh）

涉及到的算法有这几个:

- 慢启动
- 拥塞避免
- 快速重传和快速恢复

#### 拥塞窗口

- 接收窗口(rwnd)是`接收端`给的限制
- 拥塞窗口(cwnd)是`发送端`的限制

发送方维持一个拥塞窗口 cwnd ( congestion window )的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。

发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。

```
发送窗口大小 = min(rwnd, cwnd)
```

### 慢启动

刚开始进入传输数据的时候，你是不知道现在的网路到底是稳定还是拥堵的，如果做的太激进，发包太急，那么疯狂丢包，造成雪崩式的网络灾难。

因此，较好的方法是 先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。这种算法叫`慢启动`。运作过程如下:

- 首先，三次握手，双方宣告自己的接收窗口大小
- 双方初始化自己的**拥塞窗口**(cwnd)大小
- 在开始传输的一段时间，发送端每收到一个 ACK，拥塞窗口大小加 1，也就是说，**每经过一个 RTT，cwnd 翻倍**。如果说初始窗口为 10，那么第一轮 10 个报文传完且发送端收到 ACK 后，cwnd 变为 20，第二轮变为 40，第三轮变为 80，依次类推。

它的阈值叫做**慢启动阈值**，当 cwnd 到达这个阈值之后，就涨的慢了，接下来这就是拥塞避免做的事情了。

### 拥塞避免

让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。也就是说，以前一个 RTT 下来，`cwnd`翻倍，现在`cwnd`只是增加 1 而已。

当然，**慢启动**和**拥塞避免**是一起作用的，是一体的。

### 快速重传和快速恢复

#### 快速重传

在 TCP 传输的过程中，如果发生了丢包，即接收端发现数据段不是按序到达的时候，接收端的处理是**重复发送之前的 ACK。**

比如第 5 个包丢了，即使第 6、7 个包到达的接收端，接收端也一律返回第 4 个包的 ACK。当发送端收到 3 个重复的 ACK 时，意识到丢包了，于是马上进行重传，不用等到一个 RTO 的时间到了才重传。

这就是**快速重传**，它解决的是**是否需要重传**的问题。

#### 选择性重传

那你可能会问了，既然要重传，那么只重传第 5 个包还是第5、6、7 个包都重传呢？

当然第 6、7 个都已经到达了，TCP 的设计者也不傻，已经传过去干嘛还要传？干脆记录一下哪些包到了，哪些没到，针对性地重传。

在收到发送端的报文后，接收端回复一个 ACK 报文，那么在这个报文首部的可选项中，就可以加上`SACK`这个属性，通过`left edge`和`right edge`告知发送端已经收到了哪些区间的数据报。因此，即使第 5 个包丢包了，当收到第 6、7 个包之后，接收端依然会告诉发送端，这两个包到了。剩下第 5 个包没到，就重传这个包。这个过程也叫做**选择性重传(SACK，Selective Acknowledgment)**，它解决的是**如何重传**的问题。

#### 快速恢复

当然，发送端收到三次重复 ACK 之后，发现丢包，觉得现在的网络已经有些拥塞了，自己会进入**快速恢复**阶段。

在这个阶段，发送端如下改变：

- 拥塞阈值降低为 cwnd 的一半
- cwnd 的大小变为拥塞阈值
- cwnd 线性增加

以上就是 TCP 拥塞控制的经典算法: **慢启动**、**拥塞避免**、**快速重传和快速恢复**。 









### **半连接队列和 SYN Flood 攻击的关系**

三次握手前，服务端的状态从`CLOSED`变为`LISTEN`, 同时在内部创建了两个队列：**半连接队列**和**全连接队列**，即**SYN队列**和**ACCEPT队列**。

#### 半连接队列

当客户端发送`SYN`到服务端，服务端收到以后回复`ACK`和`SYN`，状态由`LISTEN`变为`SYN_RCVD`，此时这个连接就被推入了**SYN队列**，也就是**半连接队列**。

#### 全连接队列

当客户端返回`ACK`, 服务端接收后，三次握手完成。这个时候连接等待被具体的应用取走，在被取走之前，它会被推入另外一个 TCP 维护的队列，也就是**全连接队列(Accept Queue)**。

#### SYN Flood 攻击原理

SYN Flood 属于典型的 DoS/DDoS 攻击。其攻击的原理很简单，就是用客户端在短时间内伪造大量不存在的 IP 地址，并向服务端疯狂发送`SYN`。对于服务端而言，会产生两个危险的后果:

1. 处理大量的`SYN`包并返回对应`ACK`, 势必有大量连接处于`SYN_RCVD`状态，从而占满整个**半连接队列**，无法处理正常的请求。
2. 由于是不存在的 IP，服务端长时间收不到客户端的`ACK`，会导致服务端不断重发数据，直到耗尽服务端的资源。

#### 如何应对 SYN Flood 攻击？

1. 增加 SYN 连接，也就是增加半连接队列的容量。
2. 减少 SYN + ACK 重试次数，避免大量的超时重发。
3. 利用 SYN Cookie 技术，在服务端接收到`SYN`后不立即分配连接资源，而是根据这个`SYN`计算出一个Cookie，连同第二次握手回复给客户端，在客户端回复`ACK`的时候带上这个`Cookie`值，服务端验证 Cookie 合法之后才分配连接资源

### **TCP 快速打开的原理(TFO)**

第一节讲了 TCP 三次握手，每次都三次握手好麻烦呀！能不能优化一点？

可以啊。今天来说说这个优化后的 TCP 握手流程，也就是 TCP 快速打开(TCP Fast Open, 即TFO)的原理。

优化的过程是这样的，还记得我们说 SYN Flood 攻击时提到的 SYN Cookie 吗？这个 Cookie 可不是浏览器的`Cookie`, 用它同样可以实现 TFO。

### TFO 流程

#### 首轮三次握手

首先客户端发送`SYN`给服务端，服务端接收到。

注意哦！现在服务端不是立刻回复 SYN + ACK，而是通过计算得到一个`SYN Cookie`, 将这个`Cookie`放到 TCP 报文的 `Fast Open`选项中，然后才给客户端返回。

客户端拿到这个 Cookie 的值缓存下来。后面正常完成三次握手。

首轮三次握手就是这样的流程。而后面的三次握手就不一样啦！

#### 后面的三次握手

在后面的三次握手中，客户端会将之前缓存的 `Cookie`、`SYN` 和`HTTP请求`(是的，你没看错)发送给服务端，服务端验证了 Cookie 的合法性，如果不合法直接丢弃；如果是合法的，那么就正常返回`SYN + ACK`。

重点来了，现在服务端能向客户端发 HTTP 响应了！这是最显著的改变，三次握手还没建立，仅仅验证了 Cookie 的合法性，就可以返回 HTTP 响应了。

当然，客户端的`ACK`还得正常传过来，不然怎么叫三次握手嘛。

![image-20201210173128974](/Users/yangyibo/Library/Application Support/typora-user-images/image-20201210173128974.png)

注意: 客户端最后握手的 ACK 不一定要等到服务端的 HTTP 响应到达才发送，两个过程没有任何关系。

### TFO 的优势

TFO 的优势并不在与首轮三次握手，而在于后面的握手，在拿到客户端的 Cookie 并验证通过以后，可以直接返回 HTTP 响应，充分利用了**1 个RTT**(Round-Trip Time，往返时延)的时间**提前进行数据传输**，积累起来还是一个比较大的优势。

#  UDP 和 TCP

TCP 叫做`传输控制协议(TCP，Transmission Control Protocol)`，通过名称可以大致知道 TCP 协议有控制传输的功能，主要体现在其可控，可控就表示着可靠，确实是这样的，TCP 为应用层提供了一种**可靠的、面向连接**的服务，它能够将分组可靠的传输到服务端。

UDP 叫做 `用户数据报协议(UDP，User Datagram Protocol)`，通过名称可以知道 UDP 把重点放在了数据报上，它为应用层提供了一种无需建立连接就可以直接发送数据报的方法。

### UDP

**优点**

* **数据结构简单**，不需要大量的数据结构、处理逻辑、包头字段
* **需要资源少，适合网络情况比较好的内网**，或者对于丢包不敏感的应用。
* 不需要一对一沟通来建立连接，可以广播的应用。

**缺点**

* **不会建立连接**，通过端口号发送、接收数据
* 不会根据网络情况进行拥塞控制，无论网络丢包多严重，我还是照样发~
* 会丢包

**应用场景**

主要应用在需要处理速度快，时延低，可以容忍少数丢包的情况。即使网络情况不佳，发包就是~。UDP 常用在实时竞技游戏，IoT 物联网，移动通信领域。

### TCP

* 面向连接 ，三次握手，四次挥手。UDP 是面向无连接。
* 面向字节流，发的是一个数据流，没头没尾。TCP 自己维护流状态，UDP 基于 IP 数据报，一个一个地发，一个一个地收。
* 拥塞控制，根据网络和丢包情况，控制自己的发数据行为行为，udp则一直发
* 有状态服务，记录发送状态，记录发送和接收情况。不出差错。有状态可以理解为：我记录了哪些发送了，哪些没有发送，哪些接收到了，哪些没接收到，应该接收哪个了，一点差错都不行。

### 解释

* **面向连接**

**面向连接**，就是为了**在客户端和服务端维护连接**，而建立**一定的数据结构来维护双方交互的状态**，用这样的数据来保证所谓的面向连接的特性

TCP 提供**可靠交付**，通过 TCP 连接传输的数据，可以无差错、不丢失、不重复、并且**按序**到达。而 **UDP 继承了 IP 包**的特性，**不保证不丢失，不保证按顺序到达**。

* **面向字节流**

TCP 是面向字节流，所谓字节流，就是发的是一个流，没头没尾。TCP 自己维护流状态。

UDP 基于 IP 数据报，一个一个地发，一个一个地收。

* 拥塞控制

TCP 拥有拥塞控制，如果包丢弃了或者网络环境不好了，就会根据网络情况自行控制自己的行为，看下是发快点还是发慢点。

UDP 则没有这么智能了， 你让我发，我就发呗，反正是你让我发的，其他的一概不管~

* 有状态服务

TCP 是一个有状态的服务，有状态可以理解为：我记录了哪些发送了，哪些没有发送，哪些接收到了，哪些没接收到，应该接收哪个了，一点差错都不行。

而 UDP 则不是有状态的服务，我只管发，其他的就交给接收端。

## **如何让 UDP 实现 TCP 功能**？

1，建立连接上面已经讲到了，三次握手和四次握手，UDP 也可以模拟去做。

- 顺序问题
- 丢包问题
- 流量控制
- 拥塞控制

**顺序问题和丢包问题**可以利用**确认**与**重发**的机制。假如包收到了，可以做一个确认，发送一个 ACK 给发送端，告诉他我收到了。假如**有的包提前到了，就缓存**着。假如有包丢失了，就可以超时重试。超时重试不宜过短，时间必须大于往返时间 RTT，否则会引起不必要的重传。也不宜过长，如果超时时间过长，访问就变慢了。那怎么**确定这个时间，可以通过采样 RTT 的时间，进行加权平均**。还需要根据网络状况，动态变化。可以了解下**自适应重传算法**。

**流量控制**就是根据网络情况调整发包的速率。利用的是滑动窗口。在对于包的确认中，同时会携带一个窗口的大小，只要利用好这个窗口大小，就能很好地调整发包速率，发的报文段不要超过窗口的大小就 OK

**拥塞控制**主要用来避免**包丢失和超时重传**，如果出现了这两种现象，就说明发的速率太快了。其实开始时只发送一个报文段数据，如果收到一个确认，则倍增报文段，依次类推。当**发现超时重传时，就又回到只发送一个报文段的情况**，这个就是慢启动，这种方式不合适。其实还有一种快速重传算法，简单来说就是**拥塞窗口减半，后续线性增速**。针对于算法怎么实现的，这里就不展开讲述了。

至此，我用大白话的方式讲解了 UDP 和 TCP 的区别，以及 UDP 缺什么功能，需要怎么去弥补才能实现 TCP 的功能。相信这样回答的思路可以让面试官觉得还是有点东西的。





# Socket

Socket 和 TCP/IP 没有必然联系，Socket 的出现只是方便了 TCP/IP 的使用，如何方便使用呢？你可以直接使用下面 Socket API 的这些方法。

![image-20201210185340175](/Users/yangyibo/Library/Application Support/typora-user-images/image-20201210185340175.png)







[TCP 协议灵魂 12 问，巩固你的网路底层基础！](https://mp.weixin.qq.com/s?__biz=MzAwMjg1NjY3Nw==&mid=2247502685&idx=1&sn=40103fef7cac3b1f061f14a734e3e2e8&chksm=9ac688d7adb101c17f8e10bf728aa49c5e39a14aa1712e8de81fc52ba9c726fa89cb69c68854&scene=132#wechat_redirect)

[15 张图， 把TCP/IP 讲得一清二楚！](https://mp.weixin.qq.com/s/lv1LOyp_AEe_UJ9rlm08oQ)

[为什么 HTTPS 是安全的？][https://mp.weixin.qq.com/s/YxmmwwZtiMFFfhgoYZzqwQ]