#java多线程



### 什么是进程
一文讲透 “进程、线程、协程”
https://mp.weixin.qq.com/s/BzJw4S3O7lZikTyhGa4P9A

进程-操作系统提供的**抽象概念**，是**系统进行资源分配和调度的基本单位**，是**操作系统结构的基础**。**程序是指令、数据及其组织形式的描述**，**进程是程序的实体**。**程序本身是没有生命周期的，它只是存在磁盘上的一些指令**,程序**一旦运行就是进程**

当程序需要运行时，操作系统将代码和所有**静态数据记载到内存和进程的地址空间**（**每个进程都拥有唯一的地址空间**，见下图所示）中，通过创建和初始化栈（局部变量，函数参数和返回地址)、分配堆内存以及与IO相关的任务，当前期准备工作完成，启动程序，OS将CPU的控制权转移到新创建的进程，进程开始运行。

![image-20200923231823035](/Users/yangyibo/Library/Application Support/typora-user-images/image-20200923231823035.png)

操作系统对**进程的控制和管理**通过PCB(Processing Control Block)，**PCB通常是系统内存占用区中的一个连续存区**，它**存放着操作系统用于描述进程情况及控制进程运行所需的全部信息**(进程标识号,进程状态,进程优先级,文件系统指针以及各个寄存器的内容等)，**进程的PCB是系统感知进程的唯一实体**。

一个进程至少具有5种基本状态：**初始态、执行状态、等待（阻塞）状态、就绪状态、终止状态**

- 初始状态：进程刚被创建，由于其他进程正占有CPU所以得不到执行，只能处于初始状态。
- 执行状态：任意时刻处于执行状态的进程只能有一个。
- 就绪状态：只有处于就绪状态的经过调度才能到执行状态
- 等待状态：**进程等待某件事件完成**
- 停止状态：进程结束

#### 进程间的切换

无论是在多核还是单核系统中，一个CPU看上去都像是在并发的执行多个进程，这是通过**处理器在进程间切换**来实现的。

操作系统对把**CPU控制权在不同进程之间交换执行的机制成为上下文切换**（context switch），即保存当前进程的上下文，恢复新进程的上下文，然后将CPU控制权转移到新进程，新进程就会从上次停止的地方开始。因此，进程是轮流使用CPU的，CPU被若干进程共享，使用某种调度算法来决定何时停止一个进程，并转而为另一个进程提供服务。

* 单核CPU双进程的情况 ：进程直接**特定的机制和遇到I/O中断的情况下，进行上下文切换**，轮流使用CPU资源

  ![image-20200923232108624](/Users/yangyibo/Library/Application Support/typora-user-images/image-20200923232108624.png)

* 双核CPU双进程的情况 ：**每一个进程独占一个CPU核心资源**，在处理I/O请求的时候，CPU处于阻塞状态

  ![image-20200923232121040](/Users/yangyibo/Library/Application Support/typora-user-images/image-20200923232121040.png)

#### 进程间数据共享

系统中的**进程与其他进程共享CPU和主存资源**，为了更好的管理主存，现在系统提供了一种对**主存的抽象概念**，即为**虚拟存储器（VM）**。它是一个抽象的概念，**它为每一个进程提供了一个假象，即每个进程都在独占地使用主存**。

虚拟存储器主要提供了三个能力：　

- 将主存看成是一个存储在磁盘上的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，更高效地使用主存
- 为每个进程提供了一致的地址空间，从而简化了存储器管理
- **保护了每个进程的地址空间不被其他进程破坏**

> 由于**进程拥有自己独占的虚拟地址空间**，CPU通过地址翻译将虚拟地址转换成真实的物理地址，**每个进程只能访问自己的地址空间**。因此，**在没有其他机制（进程间通信）的辅助下，进程之间是无法共享数据的**

### 进程间通讯

1. 管道pipe：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
2. 命名管道FIFO：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
3. 消息队列MessageQueue：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
4. 共享存储SharedMemory：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。
5. 信号量Semaphore：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
6. 套接字Socket：套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。
7. 信号 ( sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生

### 什么是线程

线程-也是**操作系统提供的抽象概念**，是程序执行中一个单一的顺序控制流程，是**程序执行流的最小单元**，是处**理器调度和分派的基本单位**。一个**进程可以有一个或多个线程**，同一进程中的多个线程将**共享该进程中的全部系统资源**，如虚拟地址空间，文件描述符和信号处理等等。但同一进程中的多个线程有**各自的调用栈和线程本地存储**（如下图所示）。

![image-20200924000037805](/Users/yangyibo/Library/Application Support/typora-user-images/image-20200924000037805.png)

系统利用PCB来完成对进程的控制和管理。同样，系统为线程分配一个线程控制块**TCB（Thread Control Block）**,将所有用于控制和管理线程的信息记录在线程的控制块中，TCB中通常包括：

- **线程标志符**
- **一组寄存器**
- 线程运行状态
- 优先级
- 线程专有存储区
- 信号屏蔽

和进程一样，线程同样有五种状态：初始态、执行状态、等待（阻塞）状态、就绪状态和终止状态,**线程之间的切换和进程一样也需要上下文切换**，这里不再赘述。

### 什么是协程

协程（Coroutine，又称微线程）是一种**比线程更加轻量级的存在**，**协程不是被操作系统内核所管理**，而**完全是由程序所控制**。协程与线程以及进程的关系见下图所示。

- **协程可以比作子程序**，但执行过程中，**子程序内部可中断，然后转而执行别的子程序**，在适当的时候再**返回来接着执行。协程之间的切换不需要涉及任何系统调用或任何阻塞调用**
- **协程只在一个线程中执行，是子程序之间的切换**，发生在用户态上。而且，**线程的阻塞状态是由操作系统内核来完成，发生在内核态上，因此协程相比线程节省线程创建和切换的开销**
- 协程中**不存在同时写变量冲突，因此，也就不需要用来守卫关键区块的同步性原语，比如互斥锁**、信号量等，并且**不需要来自操作系统的支持**。

**协程适用于IO阻塞且需要大量并发的场景，当发生IO阻塞，由协程的调度器进行调度**，通过将数据流**yield掉，**并且记录当前栈上的数据，**阻塞完后立刻再通过线程恢复栈**，并把阻塞的结果放到这个线程上去运行。

![image-20200924001540885](/Users/yangyibo/Library/Application Support/typora-user-images/image-20200924001540885.png)

#### 进程 VS 线程

- **进程是资源的分配和调度的独立单元**。进程**拥有完整的虚拟地址空间，当发生进程切换时，不同的进程拥有不同的虚拟地址空间**。而**同一进程的多个线程是可以共享同一地址空间**
- **线程是CPU调度的基本单元，一个进程包含若干线程**。
- **线程比进程小，基本上不拥有系统资源**。**线程的创建和销毁所需要的时间比进程小很多**
- 由于**线程之间能够共享地址空间，因此，需要考虑同步和互斥操作**
- **一个线程的意外终止会影响整个进程的正常运行，但是一个进程的意外终止不会影响其他的进程的运行。因此，多进程程序安全性更高。**

> 总之，**多进程程序安全性高，进程切换开销大**，效率低；多线程程序维护成本高，线程切换开销小，效率高。（**python的多线程是伪多线程，下文中将详细介绍**）

### 为什么要使用线程

 使用线程可以提高cpu 利用率。线程的创建和销毁所需要的时间比进程小，比进程轻量。线程间的通信代价小。

## 为什么使用多线程？

1.避免阻塞（异步调用） 。单个线程中的程序，是顺序执行的。如果前面的操作发生了阻塞，那么就会影响到后面的操作。这时候可以采用多线程，我感觉就等于是异步调用。这样的例子有很多： 

ajax调用，就是浏览器会启一个新的线程，不阻塞当前页面的正常操作；

2.避免CPU空转 ：以http server为例，如果只用单线程响应HTTP请求，即处理完一条请求，再处理下一条请求的话，CPU会存在大量的闲置时间 。因为处理一条请求，经常涉及到RPC、数据库访问、磁盘IO等操作，这些操作的速度比CPU慢很多，而在等待这些响应的时候，CPU却不能去处理新的请求，因此http server的性能就很差 

所以很多web容器，都采用对每个请求创建新线程来响应的方式实现，这样在等待请求A的IO操作的等待时间里，就可以去继续处理请求B，对并发的响应性就好了很多 

当然，这种设计方式并不是绝对的，现在像node.js、Nginx等新一代http server，采用了事件驱动的实现方式，用单线程来响应多个请求也是没问题的。甚至实现了更高的性能，因为多线程是一把双刃剑，在提升了响应性的同时，创建销毁线程都是需要开销的，另外CPU在线程之间切换，也会带来额外的开销。避免了这些额外开销，可能是node.js等http server性能优秀的原因之一吧 

3.提升性能，比如做饭，多个人配菜、切菜，提高做菜效率。

在满足条件的前提下，多线程确实能提升性能 

基本上，需要满足3个条件： 

* 第1，任务具有并发性，也就是可以拆分成多个子任务。并不是什么任务都能拆分的，条件还比较苛刻。 子任务之间不能有先后顺序的依赖，必须是允许并行的 

* 第2，只有在CPU是性能瓶颈的情况下，多线程才能实现提升性能的目的。比如一段程序，**瓶颈在于IO操作**，那么把这个程序拆分到2个线程中执行，也是无法提升性能的 

* 第3，有点像废话，就是需要有多核CPU才行。否则的话，虽然拆分成了多个可并行的子任务，但是没有足够的CPU，还是只有一个CPU在多个线程中切换来切换去，不但达不到提升性能的效果，反而由于增加了额外的开销，而降低了性能。例如： 把菜放到了2个锅里，但是只有1个炉子一样 

### 总结应用场景和方案

- CPU密集型：多进程
- IO密集型：多线程（协程维护成本较高,而且在读写文件方面效率没有显著提升）
- CPU密集和IO密集：多进程+协程



##产生线程不安全的原因

在同一程序中运行多个线程本身不会导致问题，问题在于多个线程访问了相同的资源。如，同一内存区（变量，数组，或对象）、系统（数据库，web services等）或文件。实际上，这些问题只有在一或多个线程向这些资源做了写操作时才有可能发生，只要资源没有发生变化,多个线程读取相同的资源就是安全的。

##竞态条件 & 临界区

当两个线程竞争同一资源时，如果对资源的访问顺序敏感，就称存在竞态条件。导致竞态条件发生的代码区称作**临界区**。上例中add()方法就是一个临界区,它会产生**竞态条件**。在临界区中使用适当的同步就可以避免竞态条件。

```
public class Counter {
    protected long count = 0;

    public void add(long value){
        this.count = this.count + value;  
    }
}

```

两个线程交替执行结果如下

```
this.count = 0;
   A:   读取 this.count 到一个寄存器 (0)
   B:   读取 this.count 到一个寄存器 (0)
   B:   将寄存器的值加2
   B:   回写寄存器值(2)到内存. this.count 现在等于 2
   A:   将寄存器的值加3
   A:   回写寄存器值(3)到内存. this.count 现在等于 3
```

##共享资源

允许被多个线程同时执行的代码称作线程安全的代码叫做共享资源。**线程安全的代码不包含竞态条件**。当多个线程同时更新共享资源时会引发竞态条件。

##局部变量

局部变量存储在线程自己的栈中。也就是说，局部变量永远也不会被多个线程共享。所以，基础类型的局部变量是线程安全的。

```
public void someMethod(){
  long threadSafeInt = 0;//局部变量
  threadSafeInt++;
}
```

##局部的对象引用

上面提到的局部变量是一个基本类型，如果局部变量是一个**对象类型**呢？对象的局部引用和基础类型的局部变量不太一样。尽管引用本身没有被共享，但引用所指的对象并没有存储在线程的栈内，**所有的对象都存在共享堆**中，所以对于局部对象的引用，有可能是线程安全的，也有可能是线程不安全的。

如果在某个方法中创建的对象不会被其他方法或全局变量获得，或者说方法中创建的对象没有逃出此方法的范围，那么它就是**线程安全**的。实际上，哪怕将这个对象作为参数传给其它方法，只要**别的线程获取不到这个对象**，那它仍是线程安全的。

```
public void someMethod(){
  LocalObject localObject = new LocalObject();
  localObject.callMethod();
  method2(localObject);
}

public void method2(LocalObject localObject){
  localObject.setValue("value");
}
```

上面样例中 LocalObject 对象没有被方法返回，也没有被传递给someMethod()方法外的对象，始终在someMethod()方法内部。**每个执行someMethod()的线程都会创建自己的LocalObject对象**，并赋值给localObject引用。因此，这里的LocalObject是线程安全的。事实上，整个someMethod()都是线程安全的。即使将LocalObject作为参数传给同一个类的其它方法或其它类的方法时，它仍然是**线程安全**的。当然，如果LocalObject通过某些方法被传给了别的线程，那它就不再是线程安全的了。
	

```
如果一个资源的创建，使用，销毁都在同一个线程内完成，且永
远不会脱离该线程的控制，则该资源的使用就是线程安全的。
```

##Java中实现线程安全的方法

* 最简单的方式，使用Synchronization关键字:
  http://blog.csdn.net/suifeng3051/article/details/48711405
* 使用java.util.concurrent.atomic 包中的原子类，例如 AtomicInteger
* 使用java.util.concurrent.locks 包中的锁
* 使用线程安全的集合ConcurrentHashMap
* 使用volatile关键字，保证变量可见性（直接从内存读，而不是从线程cache读）

http://blog.csdn.net/suifeng3051/article/details/52164267

## Happens-Before 规则

> 在JMM中，如果**一个操作执行的结果需要对另一个操作可见**，那么这**两个操作之间必须存在happens-before关系**。
>
> 原则定义：
>
> **1. 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。**
>
>
> **2. 两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。**

happens-before原则规则：

1. 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作；（**同一个线程中前面的所有写操作对后面的操作可见**）
2. **锁定规则**：一个unLock操作先行发生于后面对同一个锁的lock操作；（**如果线程1解锁了monitor a，接着线程2锁定了a，那么，线程1解锁a之前的写操作都对线程2可见（线程1和线程2可以是同一个线程）**）
3. volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；（**如果线程1写入了volatile变量v（临界资源），接着线程2读取了v，那么，线程1写入v及之前的写操作都对线程2可见（线程1和线程2可以是同一个线程）**）
4. 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；
5. 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作； （**假定线程A在执行过程中，通过执行ThreadB.start()来启动线程B，那么线程A对共享变量的修改在接下来线程B开始执行前对线程B可见。注意：线程B启动之后，线程A在对变量修改线程B未必可见**）
6. 线程中断规则：对**线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生**；（(**线程t1写入的所有变量，调用Thread.interrupt()中断线程2，被打断的线程t2，可以看到t1的全部操作**)）
7. 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；（**线程t1写入的所有变量，在任意其它线程t2调用t1.join()，或者t1.isAlive() 成功返回后，都对t2可见。**）
8. 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始；（**一个对象的初始化的完成，也就是构造函数执行的结束一定 happens-before它的finalize()方法**)

### 一言以蔽之，这些规则背后的道理

在程序运行过程中，所有的变更会先在寄存器或本地cache中完成，然后才会被拷贝到主存以跨越内存栅栏（本地或工作内存到主存之间的拷贝动作），此种跨越序列或顺序称为happens-before。
 **注：happens-before本质是顺序，重点是跨越内存栅栏**
 通常情况下，写操作必须要happens-before读操作，即写线程需要在所有读线程跨越内存栅栏之前完成自己的跨越动作，其所做的变更才能对其他线程可见。

## 

##synchronized 

* synchronized修饰非静态方法、同步代码块的synchronized (this)用法和synchronized (非this对象)的用法锁的是对象，线程想要执行对应同步代码，需要获得对象锁。     
* synchronized**修饰静态方法以及同步代码块的synchronized (类.class)用法锁的是类**，线程想要执行对应同步代码，需要获得类锁。
* 在java中，同步加锁的是一个对象或者一个类，而不是代码

对于synchronized关键字而言，javac在编译时，会生成对应的**monitorenter和monitorexit指令**分别对应synchronized同步块的进入和退出，有**两个monitorexit指令的原因是：为了保证抛异常的情况下也能释放锁**，所以javac为同步代码块添加了一个隐式的try-finally，在**finally中会调用monitorexit命令释放锁**。在JVM底层，对于这两种synchronized语义的实现大致相同

对于synchronized方法而言，javac为其生成了一个**ACCSYNCHRONIZED**关键字，在JVM进行方法调用时，发现调用的方法被ACCSYNCHRONIZED修饰，则会先尝试获得锁

### 锁的几种形式

传统的锁（也就是下文要说的**重量级锁**）依赖于**系统的同步函数**，在linux上使用**mutex互斥锁**，最底**层实现依赖于futex**，关于futex可以看这些文章，这**些同步函数都涉及到用户态和内核态的切换**、**进程的上下文切换，成本较高**。对于加了synchronized关键字但运行时并没有多线程竞争，或**两个线程接近于交替执行的情况，使用传统锁机制无疑效率是会比较低的**。

JDK 1.6之前,synchronized只有传统的锁机制。

JDK 1.6引入了两种新型锁机制：**偏向锁和轻量级锁**，它们的引入是为了解决在没有多线程竞争或基本没有竞争的场景下因使用传统锁机制带来的性能开销问题。

https://mp.weixin.qq.com/s/zaazbtl3_PCwaRqK2gy_Lw

#### 偏向锁加锁过程

case 1：当该对象第一次被线程获得锁的时候，发现是**匿名偏向状态**（mark word中的thread id为0，表示未偏向任何线程，也叫做匿名偏向(anonymously biased)。），则会用CAS指令，将mark word中的thread id由0改成当前线程Id。如果成功，则代表获得了偏向锁，继续执行同步块中的代码。否则，将偏向锁撤销，升级为轻量级锁。

case 2：当被偏向的线程再次进入同步块时，发现锁对象偏向的就是当前线程，在通过一些额外的检查后（细节见后面的文章），会往当前线程的栈中添加一条Displaced Mark Word为空的Lock Record中，然后继续执行同步块的代码，因为操纵的是线程私有的栈，因此不需要用到CAS指令；由此可见偏向锁模式下，当被偏向的线程再次尝试获得锁时，仅仅进行几个简单的操作就可以了，在这种情况下，synchronized关键字带来的性能开销基本可以忽略。

case 3.当其他线程进入同步块时，发现已经有偏向的线程了，则会进入到**撤销偏向锁的逻辑里**，**一般来说，会在safepoint（安全点）中去查看偏向的线程是否还存活，如果存活且还在同步块中则将锁升级为轻量级锁，原偏向的线程继续拥有锁，当前线程则走入到锁升级的逻辑里；如果偏向的线程已经不存活或者不在同步块中，则将对象头的mark word改为无锁状态（unlocked）**，之后再升级为轻量级锁。

由此可见，偏向锁升级的时机为：当锁已经发生偏向后，只要有另一个线程尝试获得偏向锁，则该偏向锁就会升级成轻量级锁。当然这个说法不绝对，因为还有批量重偏向这一机制

#### 偏向锁解锁过程

偏向锁不会自行解锁

**当有其他线程尝试获得锁时**，是根据对象的 mark word 中记录的 threadId 遍历偏向线程的lock record来确定该线程**是否还在执行同步块中的代码**。因此偏向锁的解锁很简单，仅仅将栈中的最近一条lock record的obj字段设置为null。需要注意的是，偏向锁的解锁步骤中并不会修改对象头中的thread id。

**一般来说，会在safepoint（安全点）中去查看偏向的线程是否还存活，如果存活且还在同步块中则将锁升级为轻量级锁，原偏向的线程继续拥有锁，当前线程则走入到锁升级的逻辑里；如果偏向的线程已经不存活或者不在同步块中，则将对象头的mark word改为无锁状态（unlocked）**

#### 批量重偏向与撤销

从上文偏向锁的加锁解锁过程中可以看出，当只有一个线程反复进入同步块时，偏向锁带来的性能开销基本可以忽略，但是当有其他线程尝试获得锁时，就需要等到safe point时将偏向锁撤销为无锁状态或升级为轻量级/重量级锁。safe point这个词我们在GC中经常会提到，其代表了一个状态，在该状态下所有线程都是暂停的（大概这么个意思），详细可以看这篇文章。总之，偏向锁的撤销是有一定成本的，如果说运行时的场景本身存在多线程竞争的，那偏向锁的存在不仅不能提高性能，而且会导致性能下降。因此，JVM中增加了一种批量重偏向/撤销的机制。

1.一个线程创建了大量对象并执行了初始的同步操作，之后在另一个线程中将这些对象的锁进行之后的操作。这种case下，会导致大量的偏向锁撤销操作。

2.存在明显多线程竞争的场景下使用偏向锁是不合适的，例如生产者/消费者队列。

**批量重偏向**（bulk rebias）机制是为了解决第一种场景。批量撤销（bulk revoke）则是为了解决第二种场景。

其做法是：以class为单位，为每个class维护一个偏向锁撤销计数器，每一次该class的对象发生偏向撤销操作时，该计数器+1，当这个**值达到重偏向阈值（默认20）**时，JVM就认为该class的偏向锁有问题，因此会进行**批量重偏向**。每个class对象会有一个对应的**epoch**字段，每个处于偏向锁状态对象的mark word中也有该字段，**其初始值为创建该对象时，class中的epoch的值**。每次发生**批量重偏向时，就将该值+1**，同时遍历JVM中所有线程的栈，找到该class所有正处于加锁状态的偏向锁，**将其epoch字段改为新值**（批量重偏向）。下次获得锁时，**发现当前对象的epoch值和class的epoch不相等，那就算当前已经偏向了其他线程**，也不会执行撤销操作，而是直接**通过CAS操作将其mark word的Thread Id 改成当前线程Id**。

当达到重偏向阈值后，假设该class计数器继续增长，当其达到**批量撤销的阈值后（默认40**），JVM就认为该class的使用场景存在多线程竞争，会标记该class为不可偏向，之后，对于该class的锁，直接走轻量级锁的逻辑。



####  轻量级锁解锁过程

遍历线程栈，找到对象的 markword 中记录的lock record ，且检查 lockrecord 的 obj 指针 指向的 对象地址是等于需解锁对象。使用原子的CAS将lock record 的 Displaced MarkWord 替换回对象头，如果成功，则表示没有竞争发生，如果替换失败则升级为重量级锁。

##synchronized 使用

synchronized关键字可标记四种代码块：

1. 实例方法
2. 静态方法
3. 实例方法中的代码块
4. 静态方法中的代码块

##有了 synchronized **那么为什么会出现Lock呢？**

　　synchronized是java中的一个关键字，是管程（monitor）的一个实现，也就是说是Java语言内置的特性。**那么为什么会出现Lock呢？**

　如果一个代码块被synchronized修饰了，当一个线程获取了对应的锁，并执行该代码块时，其他线程便只能一直等待，等待获取锁的线程释放锁，而这里获取锁的线程释放锁只会有两种情况：

　　1）获取锁的线程执行完了该代码块，然后线程释放对锁的占有；

　　2）线程执行发生异常，此时JVM会让线程自动释放锁。

　　那么如果这个获取锁的线程由于要等待IO或者其他原因（比如调用sleep方法）被阻塞了，但是又没有释放锁，其他线程便只能干巴巴地等待，影响程序执行效率。所以就搞了个Lock

Lock搞了3种方法来破环不可抢占的条件。
1、`void lockInterruptibly() throws InterruptedException;` 这是个支持中断的API。Synchronized进入阻塞之后就没办法唤醒它，所以针对这个问题想了个支持响应中断的方法，让线程阻塞(lock下是等待状态)的时候可以响应中断信号，从而有机会释放已占有的资源来破环不可抢占的条件。
2、`boolean tryLock();`这就是在获取锁的时候，如果获取不到就直接返回，这样也有机会释放已占有的资源来破环不可抢占的条件。
3、`boolean tryLock(long time, TimeUnit unit) throws InterrptedException;`这是个支持超时的API，也就是让在一段时间内获取不到资源的线程直接返回一个错误，不进入阻塞状态，那也有机会释放已占有的资源来破环不可抢占的条件。
然后再来说说Lock的实现类一共有三个，一个是ReentrantLock,另两个是ReentrantReadWriteLock类中的两个静态内部类ReadLock和WriteLock。实现思路大同小异。

##Lock 接口

lock：需要显示指定起始位置和终止位置。一般使用ReentrantLock类做为锁，多个线程中必须要使用一个ReentrantLock类做为对象才能保证锁的生效。且在加锁和解锁处需要通过lock()和unlock()显示指出。所以一般会在finally块中写unlock()以防死锁。

synchronized是托管给JVM执行的，而lock是java写的控制锁的代码。

Lock接口中每个方法的使用

* lock()用来获取锁。如果锁已被其他线程获取，则进行等待。
* tryLock()如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待，则返回true。
* tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。
* lockInterruptibly()是用来获取锁的。如果线程正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态。
* unLock()方法是用来释放锁的。

###synchronized和lock用途区别

synchronized原语和ReentrantLock在一般情况下没有什么区别，但是在非常复杂的同步应用中，请考虑使用ReentrantLock，特别是遇到下面2种需求的时候。

1.某个线程在等待一个锁的控制权的这段时间需要中断
2.需要分开处理一些wait-notify，ReentrantLock里面的Condition应用，能够控制notify哪个线程
3.具有公平锁功能，每个到来的线程都将排队等候

lock 接口的最大优势是它为读和写提供两个单独的锁，可以让你构建高性能数据结构，比如 ConcurrentHashMap 和条件阻塞。

##volatile 与 synchronized 的比较

* volatile是变量修饰符，其修饰的变量具有可见性。
* volatile主要用在多个线程感知实例变量被更改了场合，从而使得各个线程获得最新的值。它强制线程每次从主内存中取到变量，而不是从线程的私有内存中读取变量，从而保证了数据的可见性。
* ①volatile轻量级，只能修饰变量。synchronized重量级，还可修饰方法
* ②volatile只能保证数据的可见性，不能用来同步，因为多个线程并发访问volatile修饰的变量不会阻塞。
* synchronized不仅保证可见性，而且还保证原子性，因为，只有获得了锁的线程才能进入临界区，从而保证临界区中的所有语句都全部执行。多个线程争抢synchronized锁对象时，会出现阻塞。

##Java的锁分为对象锁和类锁。

     　　1. 当两个并发线程访问同一个对象object中的这个synchronized(this)同步代码块时，一个时间内针对该对象的操作只能有一个线程得到执行。另一个线程必须等待当前线程执行完这个代码块以后才能执行该代码块。
    
     　　2. 然而，另一个线程仍然可以访问该object中的非synchronized(this)同步代码块。
    
     　　3. 尤其关键的是，当一个线程访问object的一个synchronized(this)同步代码块时，其他线程对该object中所有其它synchronized(this)同步代码块的访问将被阻塞。
    
     　　4. 同步加锁的是对象，而不是代码。因此，如果你的类中有一个同步方法，这个方法可以被两个不同的线程同时执行，只要每个线程自己创建一个的该类的实例即可。
    
     　　5. 不同的对象实例的synchronized方法是不相干扰的。也就是说，其它线程照样可以同时访问相同类的另一个对象实例中的synchronized方法。
    
     　　6. synchronized关键字是不能继承的，也就是说，基类的方法synchronized f(){} 在继承类中并不自动是synchronized f(){}，而是变成了f(){}。继承类需要你显式的指定它的某个方法为synchronized方法。

7.对一个全局对象或者类加锁时，对该类的所有对象都起作用
　　

##java 线程死锁

死锁的四个条件：

* 1、互斥使用，即当资源被一个线程使用(占有)时，别的线程不能使用
* 2、不可抢占，资源请求者不能强制从资源占有者手中夺取资源，资源只能由资源占有者主动释放。
* 3、请求和保持，即当资源请求者在请求其他的资源的同时保持对原有资源的占有。
* 4、循环等待，即存在一个等待队列：P1占有P2的资源，P2占有P3的资源，P3占有P1的资源。这样就形成了一个等待环路。

#java 线程生命周期

*  新建（new Thread）
   当创建Thread类的一个实例（对象）时，此线程进入新建状态（未被启动）。
   例如：Thread  t1=new Thread();

*  就绪（runnable）
   线程已经被启动，正在等待被分配给CPU时间片，也就是说此时线程正在就绪队列中排队等候得到CPU资源。例如：t1.start();

*  运行（running）
   线程获得CPU资源正在执行任务（run()方法），此时除非此线程自动放弃CPU资源或者有优先级更高的线程进入，线程将一直运行到结束。

*  死亡（dead）
   当线程执行完毕或被其它线程杀死，线程就进入死亡状态，这时线程不可能再进入就绪状态等待执行。
   *  自然终止：正常运行run()方法后终止
   *  异常终止：调用stop()方法让一个线程终止运行
*  堵塞（blocked）
   由于某种原因导致正在运行的线程让出CPU并暂停自己的执行，即进入堵塞状态。
   * 正在睡眠：用sleep(long t) 方法可使线程进入睡眠方式。一个睡眠着的线程在指定的时间过去可进入就绪状态。
   * 正在等待：调用wait()方法。（调用motify()方法回到就绪状态）
   * 被另一个线程所阻塞：调用suspend()方法。（调用resume()方法恢复）

## 2.常用方法

* void run()   创建该类的子类时必须实现的方法
* void start() 开启线程的方法
* static void sleep(long t) 释放CPU的执行权，不释放锁
* static void sleep(long millis,int nanos)
* final void wait()释放CPU的执行权，释放锁
* final void notify()
* static void yied()可以对当前线程进行临时暂停（让线程将资源释放出来）

##3 wait() 与notify()/notifyAll()/sleep

这三个方法都是Object的方法，并不是线程的方法！

* wait():释放占有的对象锁，线程进入等待池，释放cpu,而其他正在等待的线程即可抢占此锁，获得锁的线程即可运行程序。而sleep()不同的是，线程调用此方法后，会休眠一段时间，休眠期间，会暂时释放cpu，但并不释放对象锁。也就是说，在休眠期间，其他线程依然无法进入此代码内部。休眠结束，线程重新获得cpu,执行代码。wait()和sleep()最大的不同在于wait()会释放对象锁，而sleep()不会！ 
* notify(): 该方法会唤醒因为调用对象的wait()而等待的线程，其实就是对对象锁的唤醒，从而使得wait()的线程可以有机会获取对象锁。调用notify()后，并不会立即释放锁，而是继续执行当前代码，直到synchronized中的代码全部执行完毕，才会释放对象锁。JVM则会在等待的线程中调度一个线程去获得对象锁，执行代码。需要注意的是，wait()和notify()必须在synchronized代码块中调用。
* notifyAll()则是唤醒所有等待的线程。
* sleep方法在等待时不会释放任何锁或监视器







##java线程池

###在什么情况下使用线程池？ 

* 1.单个任务处理的时间比较短 
* 2.需处理的任务的数量大 

###使用线程池的好处:

* 1.减少在**创建和销毁线程**上所花的时间以及系统资源的开销 
* 2.如不使用线程池，有可能造成系统创建大量线程而导致消耗完系统内存

###线程池包括以下四个基本组成部分：

* 1、线程池管理器（ThreadPool）：用于创建并管理线程池，包括 创建线程池，销毁线程池，添加新任务；
* 2、工作线程（PoolWorker）：线程池中线程，在没有任务时处于等待状态，可以循环的执行任务；
* 3、任务接口（Task）：每个任务必须实现的接口，以供工作线程调度任务的执行，它主要规定了任务的入口，任务执行完后的收尾工作，任务的执行状态等；
* 4、任务队列（taskQueue）：用于存放没有处理的任务。提供一种缓冲机制。

###线程池的核心参数

ThreadPoolExecutor 有四个构造方法，前三个都是调用最后一个(最后一个参数最全)

```
 public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue) {
        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
             Executors.defaultThreadFactory(), defaultHandler);
    }

   
    public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory) {
        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
             threadFactory, defaultHandler);
    }

  
    public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              RejectedExecutionHandler handler) {
        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
             Executors.defaultThreadFactory(), handler);
    }

    // 都调用它
    public ThreadPoolExecutor(// 核心线程数
    int corePoolSize, 
                              // 最大线程数
                              int maximumPoolSize,  
                              // 闲置线程存活时间
                              long keepAliveTime,  
                              // 时间单位
                              TimeUnit unit, 
                              // 线程队列
                              BlockingQueue<Runnable> workQueue,  
                              // 线程工厂  
                              ThreadFactory threadFactory,                
                              // 队列已满,而且当前线程数已经超过最大线程数时的异常处理策略              
                              RejectedExecutionHandler handler   ) {
        if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }

```

* corePoolSize：核心线程数
  *  核心线程会一直存活，即使没有任务需要执行
  *  当线程数小于核心线程数时，即使有线程空闲，线程池也会优先创建新线程处理
  *  设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭
* maxPoolSize：最大线程数
  * 当线程数>=corePoolSize，且任务队列已满时。线程池会创建新线程来处理任务
  * 当线程数=maxPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常
* keepAliveTime：线程空闲时间
  * 当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量=corePoolSize
  * 如果allowCoreThreadTimeout=true，则会直到线程数量=0
* workQueue：一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择：
  * ArrayBlockingQueue;
  * LinkedBlockingQueue;
  * SynchronousQueue;
  * ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。
* threadFactory：线程工厂，主要用来创建线程；
* rejectedExecutionHandler：任务拒绝处理器，两种情况会拒绝处理任务：
  * 当线程数已经达到maxPoolSize，切队列已满，会拒绝新任务
  * 当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务
* 当拒绝处理任务时线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置默认是AbortPolicy，会抛出异常。ThreadPoolExecutor类有几个内部实现类来处理这类情况：
  * AbortPolicy 丢弃任务，抛运行时异常
  * CallerRunsPolicy 执行任务
  * DiscardPolicy 忽视，什么都不会发生
  * DiscardOldestPolicy 从队列中踢出最先进入队列（最后一个执行）的任务
  * 实现RejectedExecutionHandler接口，可自定义处理器

###Java线程池 ExecutorService 的创建

* Executors.newCachedThreadPool 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
* Executors.newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
* Executors.newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。
* Executors.newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

备注：Executors只是一个工厂类，它所有的方法返回的都是ThreadPoolExecutor、ScheduledThreadPoolExecutor这两个类的实例。

###  springBoot 的使用配置

```
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

/**
 * 数据收集配置，主要作用在于Spring启动时自动加载一个ExecutorService对象.
 * @author Bruce
 * @date 2017/2/22
 * 
 * update by Cliff at 2027/11/03
 */
@Configuration
public class ThreadPoolConfig {

    @Bean
    public ExecutorService getThreadPool(){
        return Executors.newCachedThreadPool();
    }


}

```

###ExecutorService有如下几个执行方法

- executorService.execute(Runnable);这个方法接收一个Runnable实例，并且异步的执行
- executorService.submit(Runnable)
- executorService.submit(Callable)
- executorService.invokeAny(...)
- executorService.invokeAll(...)

###execute(Runnable)

这个方法接收一个Runnable实例，并且异步的执行

```
executorService.execute(new Runnable() {
public void run() {
    System.out.println("Asynchronous task");
}
});

executorService.shutdown();
```

###submit(Runnable)

submit(Runnable)和execute(Runnable)区别是前者可以返回一个Future对象，通过返回的Future对象，我们可以检查提交的任务是否执行完毕，请看下面执行的例子：

```
Future future = executorService.submit(new Runnable() {
public void run() {
    System.out.println("Asynchronous task");
}
});

future.get();  //returns null if the task has finished correctly.

```

###submit(Callable)

submit(Callable)和submit(Runnable)类似，也会返回一个Future对象，但是除此之外，submit(Callable)接收的是一个Callable的实现，Callable接口中的call()方法有一个返回值，可以返回任务的执行结果，而Runnable接口中的run()方法是void的，没有返回值。请看下面实例：

```
Future future = executorService.submit(new Callable(){
public Object call() throws Exception {
    System.out.println("Asynchronous Callable");
    return "Callable Result";
}
});

System.out.println("future.get() = " + future.get());
```

如果任务执行完成，future.get()方法会返回Callable任务的执行结果。注意，future.get()方法会产生阻塞。

###invokeAny(…)

invokeAny(...)方法接收的是一个Callable的集合，执行这个方法不会返回Future，但是会返回所有Callable任务中其中一个任务的执行结果。这个方法也无法保证返回的是哪个任务的执行结果，反正是其中的某一个。

```
ExecutorService executorService = Executors.newSingleThreadExecutor();

Set<Callable<String>> callables = new HashSet<Callable<String>>();

callables.add(new Callable<String>() {
public String call() throws Exception {
    return "Task 1";
}
});
callables.add(new Callable<String>() {
public String call() throws Exception {
    return "Task 2";
}
});
callables.add(new Callable<String>() {
    public String call() throws Exception {
    return "Task 3";
}
});

String result = executorService.invokeAny(callables);
System.out.println("result = " + result);
executorService.shutdown();
```

###invokeAll(…)

invokeAll(...)与 invokeAny(...)类似也是接收一个Callable集合，但是前者执行之后会返回一个Future的List，其中对应着每个Callable任务执行后的Future对象。

```
List<Future<String>> futures = executorService.invokeAll(callables);

for(Future<String> future : futures){
System.out.println("future.get = " + future.get());
}

executorService.shutdown();
```

https://www.cnblogs.com/dolphin0520/p/3932921.html
https://www.cnblogs.com/waytobestcoder/p/5323130.html

**ThreadLocal是什么**

从名字我们就可以看到ThreadLocal叫做线程变量，意思是ThreadLocal中填充的变量属于**当前**线程，该变量对其他线程而言是隔离的。ThreadLocal为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量。 









