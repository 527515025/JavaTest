#琐事
Vmware vSphere Client安装redhat7.4虚拟机教程
```
http://blog.csdn.net/yangs_2012/article/details/78784764
https://jingyan.baidu.com/article/90808022f92fdcfd91c80faf.html
```
##查看redhat ip

```
ip addr 
```
##查看LInux 的文件编码
```
$ file -i tivoli_eif_zyb.log
tivoli_eif_zyb.log: text/plain; charset=utf-8
```
##修改Linux 的静态ip
```
/etc/sysconfig/network-scripts/ifcfg-eth0

 BOOTPROTO=static
 IPADDR=192.168.100.5 #静态IP    
 
 NETMASK=255.255.255.0 #子网掩码    
 GATEWAY=192.168.100.1 #默认网关 
 ONBOOT=yes
```
rhel7 断网 注释GATEWAY=192.168.100.1

##redhat7.1 网卡设置
ifcfg-ens32 网卡文件 配置静态ip
ifcfg-lo 本地网卡配置文件 应该配置为127.0.0.1
##Linux解决Device eth0 does not seem to be present 
解决办法：

首先，打开/etc/udev/rules.d/70-persistent-net.rules内容如下面例子所示：

```
# vi /etc/udev/rules.d/70-persistent-net.rules
# This file was automatically generated by the /lib/udev/write_net_rules
# program, run by the persistent-net-generator.rules rules file.
#
# You can modify it, as long as you keep each rule on a single
# line, and change only the value of the NAME= key.
# PCI device 0x1022:0x2000 (pcnet32)
SUBSYSTEM=="net", ACTION=="add", DRIVERS=="?*", ATTR{address}=="00:0c:29:8f:89:9
7", ATTR{type}=="1", KERNEL=="eth*", NAME="eth0"
# PCI device 0x1022:0x2000 (pcnet32)
SUBSYSTEM=="net", ACTION=="add", DRIVERS=="?*", ATTR{address}=="00:0c:29:50:bd:1
7", ATTR{type}=="1", KERNEL=="eth*", NAME="eth1"

记录下，eth1网卡的mac地址00:0c:29:50:bd:17

接下来，打开/etc/sysconfig/network-scripts/ifcfg-eth0

# vi /etc/sysconfig/netwonrk-scripts/ifcfg-eth0

将 DEVICE="eth0"  改成  DEVICE="eth1"  ,
将 HWADDR="00:0c:29:8f:89:97" 改成上面的mac地址  HWADDR="00:0c:29:50:bd:17"

最后，重启网络

# service network restart
redhat 7 用
systemctl restart network.service  
```
参考：http://www.linuxidc.com/Linux/2012-12/76248.htm

##redhat6.5修改主机名

```
vi /etc/sysconfig/network
修改HOSTNAME项
HOSTNAME=XXX
reboot
```

## redhat7.1 修改主机名
```
vi /etc/hostname
poc-kafka3-87
```

##配置Linux 联网
编辑 /etc/resolv.conf 添加内容如下：

```
nameserver 8.8.8.8
nameserver 8.8.4.4
```
##查看Linux版本
```
uname -a 
或
cat /proc/version
或
cat /etc/redhat-release  
或 
cat /etc/issue     －－redhat 6.5 一下。
或
cat /etc/redhat-release
```
## 查看LInux cpu
```
  cat /proc/cpuinfo |grep "model name" && cat /proc/cpuinfo |grep "physical id"

```
## 查看内存
```
cat /proc/meminfo |grep MemTotal
```
## linux 关闭防火墙

### rhel 7.1 关闭防火墙
```
systemctl stop firewalld.service
systemctl disable firewalld.service	
systemctl status firewalld.service
```

### rhel 6.5 关闭防火墙
* 关闭防火墙-----service iptables stop
* 启动防火墙-----service iptables start
* 重启防火墙-----service iptables restart
* 查看防火墙状态--service iptables status
* 永久关闭防火墙--chkconfig iptables off
* 永久关闭后启用--chkconfig iptables on
* 最后两个命令同时运行，运行完成后查看防火墙关闭状态 
* service iptables status

##linux rpm包下载
http://vault.centos.org/6.3/os/x86_64/Packages/
http://rpm.pbone.net/index.php3

##rpm 包命令
```
安装rpm  
rpm -ivh

--force 参数为重复替换
--nodeps 参数为强制安装，忽略依赖

列出rpm包的内容：
rpm -qpl *.rpm

解压rpm包的内容：（没有安装，就像解压tgz包一样rpm包）
rpm2cpio *.rpm | cpio -div

删除rpm包 
rpm -e <包的名字>
```
##linux 修改时区
1. 执行tzselect命令-->选择Asia-->选择China-->选择east China - Beijing, Guangdong, Shanghai, etc-->然后输入1

	如果不想用tzselect命令，可以修改文件变更时区。  vi /etc/sysconfig/clock  

	```
	ZONE=Asia/Shanghai（查/usr/share/zoneinfo下面的文件） 
	UTC=false 
	ARC=false
	```
2. rm /etc/localtime3、链接到上海时区文件       
3. ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime  重启机器

##Linux 修改时间
date -s "2017-06-15 09:55:25"
date -s "09:55:25"
##Redhat7.1
vi /etc/hostname
hostnamectl set-hostname your_hostname 
修改 redhat 7.1 的hostname
##创建新用户
#### useradd  -d /usr/cpic -m cpic (- 复制转译可能有误)
此命令创建了一个用户cpic，
其中-d和-m选项用来为登录名cpic产生一个主目录/usr/cpic（/usr为默认的用户主目录所在的父目录）。
useradd testuser 创建用户testuser
passwd cpic 给已创建的用户testuser设置密码

#### useradd -s /bin/sh -g group –G adm,root gem (- 复制转译可能有误)
此命令新建了一个用户gem，该用户的登录Shell是/bin/sh，它属于group用户组，同时又属于adm和root用户组，其中group用户组是其主组。
这里可能新建组：#groupadd group及groupadd adm　
增加用户账号就是在/etc/passwd文件中为新用户增加一条记录，同时更新其他系统文件如/etc/shadow, /etc/group等。
Linux提供了集成的系统管理工具userconf，它可以用来对用户账号进行统一管理。

####userdel testuser 删除用户testuser
####rm -rf testuser 删除用户testuser所在目录

##修改普通用户的环境变量
vi .bashrc
source .bashrc


```
export JAVA_HOME=/usr/cpic/apps/jdk1.8.0_121
export PATH=$JAVA_HOME/bin:$PATH
```

#shell
eval命令将会首先扫描命令行进行所有的替换，憨厚再执行命令。
##shell生成随机数
生成1-60 的随机数

```
 #!/bin/bash
 
 echo "$((($RANDOM)%60))"
```
##判断上一条命令是否执行成功
```
if [ $? -eq 0 ];
then
	echo "执行成功";
else
	echo "执行失败";
fi
```
##shell 判断

```
#!/bin/sh
myPath="/var/log/httpd/"
myFile="/var /log/httpd/access.log"

# 这里的-x 参数判断$myPath是否存在并且是否具有可执行权限
if [ ! -x "$myPath"]; then
 mkdir "$myPath"
fi
# 这里的-d 参数判断$myPath是否是一个目录
if [ ! -d "$myPath"]; then
 mkdir "$myPath"
fi

# 这里的-f参数判断$myFile 文件是否存在
if [ ! -f "$myFile" ]; then
 touch "$myFile"
fi

# 这里的-s参数判断$myFile 判断文件存在且非空 
if [ ! -s "$myFile" ]; then
 touch "$myFile"
fi

# 其他参数还有-n,-n是判断一个变量是否是否有值 如果string 非空(非0），返回0(true)  
if [ ! -n "$myVar" ]; then
 echo "$myVar is empty"
 exit 0
fi

# 这里的-z 参数判断$myPath是否为空
if [ ! -z "$myPath"]; then
 mkdir "$myPath"
fi

# 两个变量判断是否相等
if [ "$var1" = "$var2" ]; then
 echo '$var1 eq $var2'
else
 echo '$var1 not eq $var2'
fi



#-eq  -ne  -lt  -nt只能用于整数，不适用于字符串，字符串等于用赋值号=
if [ int1 -eq int2 ]    如果int1等于int2   
if [ int1 -ne int2 ]    如果不等于    
if [ int1 -ge int2 ]       如果>=
if [ int1 -gt int2 ]       如果>
if [ int1 -le int2 ]       如果<=
if [ int1 -lt int2 ]       如果<

```

##从终端读取参数
-t 30 等待30s

-p "The para is params "  // 提示信息

```
#!/bin/sh
params=0;
#Read the params . Set The finalEnv. Pay Attention 'read' NOT 'Read'
read -t 30 -p "The para is params " params ;
echo "$params"
```
##从配置文件中读取数据
env.properties

```
flume_path=/opt/apps/wh.agent/current
epp_path=/opt/apps/epp_manager

prop_package=epp-manager
prop_appRoot=/opt/apps
```
注意：参数名不要用点隔开，应用下划线。 //test.sh

```
#!/bin/sh
. env.properties
finalPackage=${flume_path}
echo "$finalPackage"
```
##从配置文件中读取（二）

```
	VALUES=`grep "^flume_path" env.properties|grep -v \# |cut -d'=' -f2`;

```
通过查询的方式获取参数 ，^ 以此为开头。 grep -v \# 忽略以＃开头的记录

##wc  文件名   

- c 统计字节数。  

- l 统计行数。  

- w 统计字数。  

 该命令统计给定文件中的字节数、字数、行数。如果没有给出文件名，则从标准输入读取。wc同时也给出所有指定文件的总统计数。字是由空格字符区分开的最大字符串。  
##数组

```
#declare -a: define an array
#declare -i: define an integer
declare -i index=1
declare -a envMap
declare -a formatMap=(["1"]="docker" ["2"]="springboot")


#scan the env  all dir to envMap
for i in env/* ; do 
 if [ -d ${i} ]; then
	envMap["${index}"]="`basename ${i}`"
	index=index+1
 fi
done

#使用@ 或 * 可以获取数组中的所有元素
#print envMap all element
for i in ${!envMap[@]} ;do
	echo [${i}]:${envMap[${i}]}
done

```
##shell运算符

```
==	相等。用于比较两个数字，相同则返回 true。	[ $a == $b ] 返回 false。

-eq	检测两个数是否相等，相等返回 true。	[ $a -eq $b ] 返回 false。

=	检测两个字符串是否相等，相等返回 true。	[ $a = $b ] 返回 false。

!=	检测两个字符串是否相等，不相等返回 true。	[ $a != $b ] 返回 true。

-z	检测字符串长度是否为0，为0返回 true。	[ -z $a ] 返回 false。

-n	检测字符串长度是否为0，不为0返回 true。	[ -n $a ] 返回 true。

-d file	检测文件是否是目录，如果是，则返回 true。	[ -d $file ] 返回 false。

-f file	检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。	[ -f $file ] 返回 true。
```
##egrep
Linux egrep命令用于在文件内查找指定的字符串。
egrep执行效果与"grep-E"相似，使用的语法及参数可参照grep指令，与grep的不同点在于解读字符串的方法。
egrep是用extended regular expression语法来解读的，而grep则用basic regular expression 语法解读，extended regular expression比basic regular expression的表达更规范。

```
egrep [范本模式] [文件或目录] 
egrep Linux * 
 //查找当前目录下所有文件中包含字符串"Linux"的文件
```
##echo -e
```
echo -e "OK! \n" # -e 开启转义

echo "$NAME"   #此时 $NAME 取变量值
echo '$NAME'  #此时把$NAME 当作字符串输出
echo '"$NAME"'  #此时把$NAME 当作字符串输出

```
##sed -i
Linux sed命令是利用script来处理文本文件。
sed可依照script的指令，来处理、编辑文本文件。
Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。

####选项与参数：

* -n ：使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN 的数据一般都会被列出到终端上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。
* -e ：直接在命令列模式上进行 sed 的动作编辑；
* -f ：直接将 sed 的动作写在一个文件内， -f filename 则可以运行 filename 内的 sed 动作；
* -r ：sed 的动作支持的是延伸型正规表示法的语法。(默认是基础正规表示法语法)
* -i ：直接修改读取的文件内容，而不是输出到终端。

####function：

* a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～
* c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！
* d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚；
* i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；
* p ：列印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～
* s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！

```
sed -i 's/原字符串/新字符串/' /home/1.txt
sed -i 's/原字符串/新字符串/g' /home/1.txt
#原串支持正则匹配哦。 ？ 为sed 的分隔符 # 和 / 也可以作为 sed 命令的分隔符
sed -i 's?^db.jdbc.url=.*?db.jdbc.url='$url'?' ../conf/application.properties;
```

##sh -c  "。。。"
从String中读取命令 并处理他们
##curl 
-d 传递参数 -o将输出重定向到一个文件（多用于下载文件）-s curl 在安静模式下执行，不会发送任何数据到stdout
```
curl -d "status=pedding" -o /dev/null -s $URL
```

##redhat ssh免密登录
B 机的.ssh 文件夹要是 通过 ssh-keygen -t rsa 命令创建的，因为redhat 的 ssh 文件夹用命令生成的，和手动生成的权限不一样（应该改为600 权限）。所以ssh 免密登录时有坑

```
在B机之行
ssh-keygen -t rsa
cp id_rsa.pub authorized_keys
chmod 600 authorized_keys

拷贝A 机的 id_rsa.pub 到B机的authorized_keys 中
此时可以从A 机免密登录B机
```


##redhat7.4 ssh免密无效
redhat7.4 默认没有启动 ssh 无密登录，修噶 /etc/ssh/sshd_config 其中 的2 行配置如果不存在则添加，每台服务器都要设置。(此操作用root 账户)

```
RSAAuthentication yes
PubkeyAuthentication yes
```

ssh配置文件位置 
修改后重启(此操作用root 账户)
service sshd restart

##截取字符串
shell 字符串截取

```
${varible##*string} 从左向右截取最后一个string后的字符串
${varible#*string}从左向右截取第一个string后的字符串
${varible%%string*}从右向左截取最后一个string后的字符串
${varible%string*}从右向左截取第一个string后的字符串
```
例子：获取test 输出结果 reserved. 后的字符串

```
#!bin/sh
re=`sh test.sh`
echo "${re##*reserved. }"
```

##脚本
###读取界面输入的数值。
read -t 30 -p "The username of the machine to be ssh .(default:root)" usernameTmp ;
读取界面输入的数值。
-t 30 为停留 30S
-p 是输出提示
usernameTmp 为接收的参数

###dirname
```
【`】，学名叫“倒引号”， 如果被“倒引号”括起来，  表示里面需要执行的是命令。
比如 `dirname $0`，  就表示需要执行   dirname $0  这个命令

在命令行状态下单纯执行 $ cd `dirname $0` 是毫无意义的。因为他返回当前路径的"."。
这个命令写在脚本文件里才有作用，他返回这个脚本文件放置的目录，并可以根据这个目录来定位所要运行程序的相对位置（绝对位置除外
```

###basename
```
`basename ${i}`
1、basename
该命令的作用是从路径中提取出文件名，使用方法为basename NAME [SUFFIX]。

1）从路径中提出出文件名（带后缀），例子如下：
￼
```
###getopts
由于shell命令行的灵活性，自己编写代码判断时，复杂度会比较高。使用内部命令 getopts 可以很方便地处理命令行参数。

getopts 的设计目标是在循环中运行，每次执行循环，getopts 就检查下一个命令行参数，并判断它是否合法。即检查参数是否以 - 开头，后面跟一个包含在 options 中的字母。如果是，就把匹配的选项字母存在指定的变量 variable 中，并返回退出状态0；如果 - 后面的字母没有包含在 options 中，就在 variable 中存入一个 ？，并返回退出状态0；如果命令行中已经没有参数，或者下一个参数不以 - 开头，就返回不为0的退出状态。
```
while getopts h:ms option
do 
    case "$option" in
     	 h)
            echo "option:h, value $OPTARG"
            echo "next arg index:$OPTIND";;
        m)
            echo "option:m"
            echo "next arg index:$OPTIND";;
        s)
            echo "option:s"
            echo "next arg index:$OPTIND";;
 esac  
done 
    
调用 ./args -h 100 -ms
```

getopts 允许把选项堆叠在一起（如 -ms）

2.如要带参数，须在对应选项后加 :（如h后需加参数 h:ms）。此时选项和参数之间至少有一个空白字符分隔，这样的选项不能堆叠。

3.如果在需要参数的选项之后没有找到参数，它就在给定的变量中存入 ? ，并向标准错误中写入错误消息。否则将实际参数写入特殊变量 ：OPTARG

4.另外一个特殊变量：OPTIND，反映下一个要处理的参数索引，初值是 1，每次执行 getopts 时都会更新。

#java



##GC
新生代由于其对象存活时间短，且需要经常gc，因此采用效率较高的复制算法，其将内存区分为一个eden区和两个suvivor区，eden区和survivor区的比例是8:1，分配内存时先分配eden区，当eden区满时，使用**复制算法**进行gc，将存活对象复制到一个survivor区，当一个survivor区满时，将其存活对象复制到另一个区中，当对象存活时间大于某一阈值时，将其放入老年代。 
老年代和永久代因为其存活对象时间长，因此使用**标记清除或标记整理算法**

##spring

##spring4 时间

```
//使用瞬时时间 + 时区  
Instant instant = Instant.now();  
LocalDateTime d3 = LocalDateTime.ofInstant(Instant.now(), ZoneId.systemDefault());  
System.out.println(d3);  
```



# maven 跳过测试
mvn install -Dmaven.test.skip=true
##gradle
Gradle和Maven都是项目自动构建工具，编译源代码只是整个过程的一个方面.虽然两者都是项目工具，但是maven现在已经是行业标准，Gradle是后起之秀，Gradle抛弃了Maven的基于XML的繁琐配置，众所周知XML的阅读体验比较差，对于机器来说虽然容易识别，但毕竟是由人去维护的。取而代之的是Gradle采用了领域特定语言Groovy的配置，大大简化了构建代码的行数.

Gradle给我最大的有点是两点。其一是简洁，基于Groovy的紧凑脚本实在让人爱不释手，在表述意图方面也没有什么不清晰的地方。其二是灵活，各种在Maven中难以下手的事情，在Gradle就是小菜一碟，比如修改现有的构建生命周期，几行配置就完成了，同样的事情，在Maven中你必须编写一个插件，

范例 用 gradle 引入依赖

```
dependencies {
    compile('org.springframework:spring-core:2.5.6')
    compile('org.springframework:spring-beans:2.5.6')
    compile('org.springframework:spring-context:2.5.6')
    compile('com.google.code.kaptcha:kaptcha:2.3:jdk15')
    testCompile('junit:junit:4.7')
}
```




#java多线程

##java线程池
###在什么情况下使用线程池？ 
* 1.单个任务处理的时间比较短 
* 2.需处理的任务的数量大 

###使用线程池的好处:
* 1.减少在创建和销毁线程上所花的时间以及系统资源的开销 
* 2.如不使用线程池，有可能造成系统创建大量线程而导致消耗完系统内存

###线程池包括以下四个基本组成部分：
* 1、线程池管理器（ThreadPool）：用于创建并管理线程池，包括 创建线程池，销毁线程池，添加新任务；
* 2、工作线程（PoolWorker）：线程池中线程，在没有任务时处于等待状态，可以循环的执行任务；
* 3、任务接口（Task）：每个任务必须实现的接口，以供工作线程调度任务的执行，它主要规定了任务的入口，任务执行完后的收尾工作，任务的执行状态等；
* 4、任务队列（taskQueue）：用于存放没有处理的任务。提供一种缓冲机制。
###线程池的核心参数
ThreadPoolExecutor 有四个构造方法，前三个都是调用最后一个(最后一个参数最全)

```
 public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue) {
        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
             Executors.defaultThreadFactory(), defaultHandler);
    }

   
    public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              ThreadFactory threadFactory) {
        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
             threadFactory, defaultHandler);
    }

  
    public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue,
                              RejectedExecutionHandler handler) {
        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
             Executors.defaultThreadFactory(), handler);
    }

    // 都调用它
    public ThreadPoolExecutor(// 核心线程数
    int corePoolSize, 
                              // 最大线程数
                              int maximumPoolSize,  
                              // 闲置线程存活时间
                              long keepAliveTime,  
                              // 时间单位
                              TimeUnit unit, 
                              // 线程队列
                              BlockingQueue<Runnable> workQueue,  
                              // 线程工厂  
                              ThreadFactory threadFactory,                
                              // 队列已满,而且当前线程数已经超过最大线程数时的异常处理策略              
                              RejectedExecutionHandler handler   ) {
        if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }

```
主要参数

* corePoolSize：核心线程数
	*  核心线程会一直存活，即使没有任务需要执行
	*  当线程数小于核心线程数时，即使有线程空闲，线程池也会优先创建新线程处理
	* 设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭
* maxPoolSize：最大线程数
	* 当线程数>=corePoolSize，且任务队列已满时。线程池会创建新线程来处理任务
	* 当线程数=maxPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常
* keepAliveTime：线程空闲时间
	* 当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量=corePoolSize
	* 如果allowCoreThreadTimeout=true，则会直到线程数量=0
* workQueue：一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择：
	* ArrayBlockingQueue;
	* LinkedBlockingQueue;
	* SynchronousQueue;
	* ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。
* threadFactory：线程工厂，主要用来创建线程；
* rejectedExecutionHandler：任务拒绝处理器，两种情况会拒绝处理任务：
	* 当线程数已经达到maxPoolSize，切队列已满，会拒绝新任务
	* 当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务
* 当拒绝处理任务时线程池会调用rejectedExecutionHandler来处理这个任务。如果没有设置默认是AbortPolicy，会抛出异常。ThreadPoolExecutor类有几个内部实现类来处理这类情况：
	* AbortPolicy 丢弃任务，抛运行时异常
	* CallerRunsPolicy 执行任务
	* DiscardPolicy 忽视，什么都不会发生
	* DiscardOldestPolicy 从队列中踢出最先进入队列（最后一个执行）的任务
	* 实现RejectedExecutionHandler接口，可自定义处理器
	
###Java线程池 ExecutorService 的创建
* Executors.newCachedThreadPool 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
* Executors.newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
* Executors.newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。
* Executors.newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

备注：Executors只是一个工厂类，它所有的方法返回的都是ThreadPoolExecutor、ScheduledThreadPoolExecutor这两个类的实例。
###  springBoot 的使用配置
```
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

/**
 * 数据收集配置，主要作用在于Spring启动时自动加载一个ExecutorService对象.
 * @author Bruce
 * @date 2017/2/22
 * 
 * update by Cliff at 2027/11/03
 */
@Configuration
public class ThreadPoolConfig {

    @Bean
    public ExecutorService getThreadPool(){
        return Executors.newCachedThreadPool();
    }


}

```

###ExecutorService有如下几个执行方法
- executorService.execute(Runnable);这个方法接收一个Runnable实例，并且异步的执行
- executorService.submit(Runnable)
- executorService.submit(Callable)
- executorService.invokeAny(...)
- executorService.invokeAll(...)

###execute(Runnable)
这个方法接收一个Runnable实例，并且异步的执行

```
executorService.execute(new Runnable() {
public void run() {
    System.out.println("Asynchronous task");
}
});

executorService.shutdown();
```
###submit(Runnable)
submit(Runnable)和execute(Runnable)区别是前者可以返回一个Future对象，通过返回的Future对象，我们可以检查提交的任务是否执行完毕，请看下面执行的例子：

```
Future future = executorService.submit(new Runnable() {
public void run() {
    System.out.println("Asynchronous task");
}
});

future.get();  //returns null if the task has finished correctly.

```
###submit(Callable)
submit(Callable)和submit(Runnable)类似，也会返回一个Future对象，但是除此之外，submit(Callable)接收的是一个Callable的实现，Callable接口中的call()方法有一个返回值，可以返回任务的执行结果，而Runnable接口中的run()方法是void的，没有返回值。请看下面实例：

```
Future future = executorService.submit(new Callable(){
public Object call() throws Exception {
    System.out.println("Asynchronous Callable");
    return "Callable Result";
}
});

System.out.println("future.get() = " + future.get());
```
如果任务执行完成，future.get()方法会返回Callable任务的执行结果。注意，future.get()方法会产生阻塞。
###invokeAny(…)
invokeAny(...)方法接收的是一个Callable的集合，执行这个方法不会返回Future，但是会返回所有Callable任务中其中一个任务的执行结果。这个方法也无法保证返回的是哪个任务的执行结果，反正是其中的某一个。

```
ExecutorService executorService = Executors.newSingleThreadExecutor();

Set<Callable<String>> callables = new HashSet<Callable<String>>();

callables.add(new Callable<String>() {
public String call() throws Exception {
    return "Task 1";
}
});
callables.add(new Callable<String>() {
public String call() throws Exception {
    return "Task 2";
}
});
callables.add(new Callable<String>() {
    public String call() throws Exception {
    return "Task 3";
}
});

String result = executorService.invokeAny(callables);
System.out.println("result = " + result);
executorService.shutdown();
```
###invokeAll(…)
invokeAll(...)与 invokeAny(...)类似也是接收一个Callable集合，但是前者执行之后会返回一个Future的List，其中对应着每个Callable任务执行后的Future对象。

```
List<Future<String>> futures = executorService.invokeAll(callables);

for(Future<String> future : futures){
System.out.println("future.get = " + future.get());
}

executorService.shutdown();
```

https://www.cnblogs.com/dolphin0520/p/3932921.html
https://www.cnblogs.com/waytobestcoder/p/5323130.html
#MYSQL
##mysql报错

ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: YES)

为密码错误

_:6zvQ=KtIa<
##Mysql 变量
mysql中变量不用事前申明，在用的时候直接用“@变量名”使用就可以了。

第一种用法：set @num=1; 或set @num:=1; //这里要使用变量来保存数据，直接使用@num变量
第二种用法：select @num:=1; 或 select @num:=字段名 from 表名 where ……

##Mysql为日期增加一个时间间隔：date_add()
set @dt = now();

select date_add(@dt, interval 1 day);   - 加1天

select date_add(@dt, interval 1 hour);   -加1小时

select date_add(@dt, interval 1 minute);    - 加1分钟

select date_add(@dt, interval 1 second); -加1秒

select date_add(@dt, interval 1 microsecond);-加1毫秒

select  (@dt, interval 1 week);-加1周

select date_add(@dt, interval 1 month);-加1月

select date_add(@dt, interval 1 quarter);-加1季

select date_add(@dt, interval 1 year);-加1年

###示例
MySQL adddate(), addtime()函数，可以用date_add() 来替代。下面是date_add() 实现addtime() 功能示例：

mysql> set @dt = '2009-09-09 12:12:33';

mysql>

mysql> select date_add(@dt, interval '01:15:30' hour_second);-加上1小时15分30秒

 date_add(@dt, interval '01:15:30' hour_second)

 

结果:2009-09-09 13:28:03

##Mysql 所在机器的时区影响时间函数
mysql 所在机器的时区不正确会导致  

date_add  函数失效 （计算错误）
FROM_UNIXTIME 失效 （where中使用该函数只能大于等于，不能小于）
##mysql 使用正则
mysql sql 语句使用 REGEXP (正则匹配关键字)需要在 数据库连接字符串中添加如下配置

```
&useUnicode=true&characterEncoding=UTF-8
```

#单列索引、组合索引
* 在 vc_Name字段 上建立了索引，查询时MYSQL不用扫描整张表，效率有所提高
* 在 vc_City 和 i_Age 分别建立的MySQL单列索引的效率相似。
* 如果分别在 vc_Name,vc_City，i_Age 上建立单列索引，让该表有 3 个单列索引，查询时和上述的组合索引效率，远远低于的组合索引。虽然此时有了三个索引，但 MySQL 只能用到其中的那个它认为似乎是最有效率的单列索引。
* 

#oracle
打开cmd输入sqlplus

```
sqlplus
sys/manager as sysdba，以超级管理员的权限登录数据库
create user c##用户名 identified by 密码; 
授权
为刚创建的用户解锁：alter user c##用户名 account unlock;
授予新用户创建权限：grant create session to  c##用户名 ;
授予新用户数据库管理员权限：grant dba to c##用户名;
授予用户其它权限：
   GRANT CREATE USER,DROP USER,ALTER USER ,
            CREATE  ANY  VIEW , DROP ANY VIEW,
            EXP_FULL_DATABASE,IMP_FULL_DATABASE, 
            DBA,CONNECT,RESOURCE,CREATE SESSION  TO  c##用户名;  

```
到此，用户就创建成功了，到https://localhost:5500/em登录试试，登录成功。不过不能以管理员权限登录。 不用输入容器名

打开监控链接
https://jingyan.baidu.com/article/03b2f78c7a0ab75ea237ae33.html

##注意
oracle中 表名和 字段需要加 "" 
```
SELECT * from "person" where "create_time" > to_date('2017-10-25 11:45:20','yyyy-mm-dd HH:mi:ss');
```
#Docker
##批量删除已停止的容器

```
docker rm `docker ps -a |awk '{print $1}' |grep -v 1c3e744ba21d| grep [0-9a-z]`
```
##docker 机制与原理
docker是lxc的管理器，lxc是cgroup的管理工具，cgroup是namespace的用户空间的管理接口。namespace是linux内核在task_struct中对进程组管理的基础机制。

  Linux 内核从版本 2.4.19 开始陆续引入了 namespace 的概念。其目的是将某个特定的全局系统资源（global system resource）通过抽象方法使得namespace 中的进程看起来拥有它们自己的隔离的全局系统资源实例

#折线图
打点问题，数据库group 问题，比如说14:29秒的数据每分钟聚合一次的话会 将 14：00 －14:59 秒 的数据都统计到 14:00 这个点，实际上  14：00 －14:59  的数据应该显示在15:00 这个点的。所以需要将数据库查询到的记录统一后移。

#mybatis
nternal error : nested exception is org.apache.ibatis.reflection.ReflectionException: There is no getter for property named 'langId' in 'class java.lang.Integer'

mybatis 有内置对象 _parameter ，对于单个参数的判断应该用 _parameter 代代替 例如：

```
<select id="getUsersWithOnLine" parameterType="int" resultMap="userMap">
		SELECT u.* FROM user u
		<where>
			<if test="_parameter != null">
				u.status != #{status}
			</if>
		</where>
	</select>
```



#设计模式
##中介者模式
是为了降低耦合，遵守迪米特法则


##树状结构 mysql 查询
树状应该记录 父节点 和 子节点，然后循环递归查询。

将查询结果映射到java bean ，java bean应该 也是 嵌套设计
这样就可以将查询出来的 树 映射出来

```
public class Tree {
	private Integer id;
	private String description;
	private String severity;
	private List<Tree> childTree;
```
 
使用mysql 函数

```
DROP FUNCTION IF EXISTS getSituationTreeLst;  

delimiter //
CREATE FUNCTION `getSituationTreeLst`(rootId INT)
	RETURNS varchar(1000)
    BEGIN
    DECLARE sTemp VARCHAR(1000);
    DECLARE sTempChd VARCHAR(1000);
		SET sTemp = '$';
		SET sTempChd = cast(rootId as CHAR);
		WHILE sTempChd is not null DO
			SET sTemp = concat(sTemp,',',sTempChd);
			
			SELECT
		group_concat(s2.id)  INTO sTempChd
		FROM
			situation s2
		WHERE
			FIND_IN_SET(sTempChd , s2.story)
		END WHILE;
		RETURN sTemp;
END //
``` 

#Redis
redis 的高性能。亚毫秒延迟得益于经过优化的数据结构，由于让操作可以在邻近数据存储的地方执行，提高了效率。这种数据结构不仅可以高效地利用内存、降低应用程序的复杂性，还降低了网络开销、带宽消耗量和处理时间。


###Redis 安装
需要安装GCC

错误“centOS6.3 安装redis make报错 zmalloc.h:50:31: 错误：jemalloc/jemalloc.h：没有那个文件或目录” 
解决办法: make MALLOC=libc 代替 make 

Connected to the target VM, address: '127.0.0.1:50142', transport: 'socket'
