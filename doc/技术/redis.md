#Redis

redis 的高性能。亚毫秒延迟得益于经过优化的数据结构，由于让操作可以在邻近数据存储的地方执行，提高了效率。这种数据结构不仅可以高效地利用内存、降低应用程序的复杂性，还降低了网络开销、带宽消耗量和处理时间。


###redis的hash

redis 的hash 数据结构为 <key,hashMap>，jedis 将 hash 的key 和 value 用 SafeEncoder 进行编码 放hashMap，并将 key 也进行编码


###Redis

Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。

#### 数据类型

redis提供五种数据类型：string，hash，list，set及zset(sorted set)。

https://mp.weixin.qq.com/s/DGI4qZVxsCDzB23MsRYhyg

1. `String`：字符串类型 `int、raw、embstr` String类型得数据结构得应用也还有常规计数

2. `List`：列表类型： Redis中的列表在3.2之前的版本是使用`ziplist`和`linkedlist`进行实现的。在3.2之后的版本就是引入了`quicklist`。linkedlist是一个双向链表，他和普通的链表一样都是由指向前后节点的指针。插入、修改、更新的时间复杂度尾O(1)，但是查询的时间复杂度确实O(n)。

   linkedlist和quicklist的底层实现是采用**链表**进行实现，在c语言中并没有内置的链表这种数据结构，Redis实现了自己的链表结构。

   * 每一个节点都有指向前一个节点和后一个节点的指针。

   * 头节点和尾节点的prev和next指针指向为null，所以链表是无环的。

   * 链表有自己长度的信息，获取长度的时间复杂度为O(1)。

   **应用：** Redis中的列表可以实现**「阻塞队列」**，结合lpush和brpop命令就可以实现。生产者使用lupsh从列表的左侧插入元素，消费者使用brpop命令从队列的右侧获取元素进行消费。

   

3. `Set`：无序集合类型 ：Redis中列表和集合都可以用来存储字符串，但是**「Set是不可重复的集合，而List列表可以存储相同的字符串」**，Set集合是**无序的**这个和后面讲的ZSet有序集合相对。

   Set的底层实现是**「hashtable和intset」**，哈希表 前面已经了解过，下面我们来看看inset类型的存储结构。

   inset也叫做整数集合（数组），用于保存整数值的数据结构类型。

   **应用：**Set集合的应用场景可以用来**「去重、抽奖、共同好友、二度好友」**等业务类型

4. `ZSet`：有序集合类型： ZSet是有序集合，ZSet的底层实现是`ziplist`和`skiplist`实现的，ziplist结构 hash会写，这里来讲解skiplist的结构实现。

   `skiplist`也叫做**「跳跃表」**，跳跃表是一种有序的数据结构，它通过每一个节点维持多个指向其它节点的指针，从而达到快速访问的目的。

   skiplist有如下几个特点：

   * 有很多层组成，由上到下节点数逐渐密集，最上层的节点最稀疏，跨度也最大。

   * 每一层都是一个有序链表，至少包含两个节点，头节点和尾节点。

   * 每一层的每一个每一个节点都含有指向同一层下一个节点和下一层同一个位置节点的指针。

   * 如果一个节点在某一层出现，那么该以下的所有链表同一个位置都会出现该节点。

   **应用：**ZSet在实现排序类型的业务是比较常见的，比如在首页推荐10个最热门的帖子，阅读量由高到低。

5. `Hash`：哈希表类型 ：Hash对象的实现方式有两种分别是`ziplist、hashtable`，其中hashtable的存储方式key是String类型的，value也是以`key value`的形式进行存储。字典类型的底层就是hashtable实现的。

   压缩列表`（ziplist）`是一组连续内存块组成的顺序的数据结构，压缩列表能够节省空间，压缩列表中使用多个节点来存储数据。**「压缩列表并不是以某种压缩算法进行压缩存储数据，而是它表示一组连续的内存空间的使用，节省空间」**

   哈希表相对于String类型存储信息更加直观，存储更加方便，经常会用来做用户数据的管理，存储用户的信息。





##Redis集群介绍

http://www.redis.cn/topics/cluster-tutorial.html

Redis 集群是一个提供在多个Redis间节点间共享数据的程序集。

Redis集群并不支持处理多个keys的命令,因为这需要在不同的节点间移动数据,从而达不到像Redis那样的性能,在高负载的情况下可能会导致不可预料的错误.

Redis 集群通过分区来提供一定程度的可用性,在实际环境中当某个节点宕机或者不可达的情况下继续处理命令. Redis 集群的优势:

自动分割数据到不同的节点上。
整个集群的部分节点失败或者不可达的情况下能够继续处理命令。

###Redis 集群的数据分片

Redis 集群没有使用一致性hash, 使用的是hash取模策略。引入了 哈希槽的概念.

Redis 集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽.集群的每个节点负责一部分hash槽,举个例子,比如当前集群有3个节点,那么:

节点 A 包含 0 到 5500号哈希槽.
节点 B 包含5501 到 11000 号哈希槽.
节点 C 包含11001 到 16384号哈希槽.
这种结构很容易添加或者删除节点. 比如如果我想新添加个节点D, 我需要从节点 A, B, C中得部分槽到D上. 如果我像移除节点A,需要将A中得槽移到B和C节点上,然后将没有任何槽的A节点从集群中移除即可. 由于从一个节点将哈希槽移动到另一个节点并不会停止服务,所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态.

## 一致性哈希算法

**判定哈希算法好坏四个定义**








###Redis 集群的主从复制模型

为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有N-1个复制品.

在我们例子中具有A，B，C三个节点的集群,在没有复制模型的情况下,如果节点B失败了，那么整个集群就会以为缺少5501-11000这个范围的槽而不可用.

然而如果在集群创建的时候（或者过一段时间）我们为每个节点添加一个从节点A1，B1，C1,那么整个集群便有三个master节点和三个slave节点组成，这样在节点B失败后，集群便会选举B1为新的主节点继续服务，整个集群便不会因为槽找不到而不可用了

不过当B和B1 都失败后，集群是不可用的.

###Redis 一致性保证

Redis 并不能保证数据的强一致性. 这意味这在实际中集群在特定的条件下可能会丢失写操作.

第一个原因是因为集群是用了异步复制. 写操作过程:

客户端向主节点B写入一条命令.
主节点B向客户端回复命令状态.
主节点将写操作复制给他得从节点 B1, B2 和 B3.
主节点对命令的复制工作发生在返回命令回复之后， 因为如果每次处理命令请求都需要等待复制操作完成的话， 那么主节点处理命令请求的速度将极大地降低 —— 我们必须在性能和一致性之间做出权衡。 注意：Redis 集群可能会在将来提供同步写的方法。 Redis 集群另外一种可能会丢失命令的情况是集群出现了网络分区， 并且一个客户端与至少包括一个主节点在内的少数实例被孤立。

举个例子 假设集群包含 A 、 B 、 C 、 A1 、 B1 、 C1 六个节点， 其中 A 、B 、C 为主节点， A1 、B1 、C1 为A，B，C的从节点， 还有一个客户端 Z1 假设集群中发生网络分区，那么集群可能会分为两方，大部分的一方包含节点 A 、C 、A1 、B1 和 C1 ，小部分的一方则包含节点 B 和客户端 Z1 .

Z1仍然能够向主节点B中写入, 如果网络分区发生时间较短,那么集群将会继续正常运作,如果分区的时间足够让大部分的一方将B1选举为新的master，那么Z1写入B中得数据便丢失了.
（解释：也就是说B节点 和Z1 网络是畅通的，但是A 、C 、A1 、B1 和 C1 和B节点的网络是不通的，B是主节点，也就是需要一段时间（timeout）后 B 节点才会失效，B1被选举为主节点，在这段时间内Z1还是可以向B节点写数据，这部分数据也就丢失了。）

注意， 在网络分裂出现期间， 客户端 Z1 可以向主节点 B 发送写命令的最大时间是有限制的， 这一时间限制称为节点超时时间（node timeout）， 是 Redis 集群的一个重要的配置选项：



## redis的过期失效

Sentinel可以管理多个Redis服务器，它提供了监控，提醒以及自动的故障转移的功能；Replication则是负责让一个Redis服务器可以配备多个备份的服务器。Redis也是利用这两个功能来保证Redis的高可用的。此外，Sentinel功能则是对Redis的发布和订阅功能的一个利用。

twemproxy， codis

那就是分布式服务中所有服务器以及其能提供的服务的信息。这些信息无论如何也是要存在的，区别在于第一个路子是把这部分信息单独来管理，用这些信息来协调后端的多个独立的redis服务器；第二个路子则是让每一个redis服务器都持有这份信息，彼此知道对方的存在，来达成和第一个路子一样的目的，优点是不再需要一个额外的组件来处理这部分事情。

Redis Cluster的具体实现细节则是采用了Hash槽的概念，即预先分配出来16384个槽：在客户端通过对Key进行CRC16（key）% 16384运算得到对应的槽是哪一个；在redis服务端则是每个服务器负责一部分槽，当有新的服务器加入或者移除的时候，再来迁移这些槽以及其对应的数据，同时每个服务器都持有完整的槽和其对应的服务器的信息，这就使得服务器端可以进行对客户端的请求进行重定向处理。

当服务器内存有限时，如果大量使用缓存键且生存时间设置的过长就会导致redis 占满内存，另一方面如果为了防止redis占用内存过大而将缓存键的生存时间设置的太短，就可能导致缓存命中率过低，并且大量内存白白地闲置。实际开发中会发现很难为缓存设置合理的生存时间，为此可以让redis 按照一定的规则淘汰不需要的缓存键。

具体方法：Maxmemory 参数 设定redis 最大可用内存 单位字节，超出这个限制时会 根据 maxmemory—policy 参数指定的策略来杉树不需要的键，直到redis 占用的内存小于指定的内存。

volatile-lru  使用**lru** 算法删除一个键 （只针对设置了生存时间的键）

allkeys-lru   使用lru 算法删除一个键 

volatile-random  随机删除一个键（只针对设置了生存时间的键）

allkeys-random  随机删除一个键

volatile-ttl   删除生存时间最近的一个键

noeviction    不删除键，只返回错误

如果没有键满足回收的前提条件的话，策略**volatile-lru**, **volatile-random**以及**volatile-ttl**就和noeviction 差不多了。

选择正确的回收策略是非常重要的，这取决于你的应用的访问模式，不过你可以在运行时进行相关的策略调整，并且监控缓存命中率和没命中的次数，通过RedisINFO命令输出以便调优。

一般的经验规则:

- 使用**allkeys-lru**策略：当你希望你的请求符合一个幂定律分布，也就是说，你希望部分的子集元素将比其它其它元素被访问的更多。如果你不确定选择什么，这是个很好的选择。.
- 使用**allkeys-random**：如果你是循环访问，所有的键被连续的扫描，或者你希望请求分布正常（所有元素被访问的概率都差不多）。
- 使用**volatile-ttl**：如果你想要通过创建缓存对象时设置TTL值，来决定哪些对象应该被过期。

**allkeys-lru** 和 **volatile-random**策略对于当你想要单一的实例实现缓存及持久化一些键时很有用。不过一般运行两个实例是解决这个问题的更好方法。

为了键设置过期时间也是需要消耗内存的，所以使用**allkeys-lru**这种策略更加高效，因为没有必要为键取设置过期时间当内存有压力时。

#### **缓存穿透**

缓存穿透是指查询一条数据库和缓存都没有的一条数据，就会一直查询数据库，对数据库的访问压力就会增大，缓存穿透的解决方案，有以下两种：

1. **缓存空对象**：代码维护较简单，但是效果不好。
2. **布隆过滤器**：代码维护复杂，效果很好。

###### **缓存空对象**

缓存空对象是指当一个请求过来缓存中和数据库中都不存在该请求的数据，第一次请求就会跳过缓存进行数据库的访问，并且访问数据库后返回为空，此时也将该空对象进行缓存。

若是再次进行访问该空对象的时候，就会直接**击中缓存**，而不是再次**数据库**。但是缓存空对象会带来比较大的问题，就是缓存中会存在很多空对象，占用**内存的空间**，浪费资源，一个**解决**的办法就是设置空对象的**较短的过期时间**

#### **缓存击穿**

**缓存击穿**是指一个`key`非常热点，在不停的扛着大并发，**大并发**集中对这一个点进行访问，当这个key在失效的瞬间，持续的**大并发**就穿破缓存，直接请求数据库，瞬间对数据库的访问压力增大。

缓存击穿这里强调的是**并发**，造成缓存击穿的原因有以下两个：

1. 该数据没有人查询过 ，第一次就大并发的访问。（冷门数据）
2. 添加到了缓存，reids有设置数据失效的时间 ，这条数据刚好失效，大并发访问（热点数据）

对于缓存击穿的**解决**方案就是加锁，当用户出现**大并发**访问的时候，在查询缓存的时候和查询数据库的过程加锁，只能第一个进来的请求进行执行，当第一个请求把该数据放进缓存中，接下来的访问就会直接集中缓存，防止了**缓存击穿**。

业界比价普遍的一种做法，即根据key获取value值为空时，锁上，从数据库中`load`数据后再释放锁。若其它线程获取锁失败，则等待一段时间后重试。这里要注意，分布式环境中要使用**分布式锁**，**单机**的话用普通的锁（`synchronized`、`Lock`）就够了。

#### **缓存雪崩**

缓存雪崩 是指在某一个时间段，缓存集中过期失效。此刻无数的请求直接绕开缓存，直接请求数据库。

造成缓存雪崩的原因，有以下两种：

1. reids宕机

2. 大部分数据失效

比如天猫双11，马上就要到双11零点，很快就会迎来一波抢购，这波商品在23点集中的放入了缓存，假设缓存一个小时，那么到了凌晨24点的时候，这批商品的缓存就都过期了。
而对这批商品的访问查询，都落到了数据库上，对于数据库而言，就会产生周期性的压力波峰，对数据库造成压力，甚至压垮数据库。

对于缓存雪崩的**解决**方案有以下两种：

搭建高可用的集群，防止单机的redis宕机。
设置不同的过期时间，防止同一时间内大量的key失效。



## redis 的 Reactor 设计模式（IO多路复用）

Redis基于Reactor（反应器模式）模式开发了**网络事件处理器**，这个处理器被称为**文件事件处理器**。它的组成结构为4部分：多个套接字（**多个Socket**）、IO多路复用程序（I/O 多路复用模块封装了底层的 select、epoll、avport 以及 kqueue 这些 I/O 多路复用函数）、**文件事件分派器**、事件处理器（命令请求处理器、命令回复处理器、连接应答处理器等）。因为文件**事件分派器队列的消费是单线程**的，所以Redis才叫单线程模型。

它采用IO多路复用机制来**同时监听多个Socket**，根据Socket上的**事件类型来选择对应的事件处理器**来处理这个事件。

多个 Socket 可能并发的产生不同的操作，每个操作对应不同的文件事件，但是IO多路复用程序会监听多个 Socket，会将 Socket 放入一个队列中排队，**每次从队列中取出一个 Socket 给事件分派器**，**事件分派器把 Socket 给对应的事件处理器**。

然后一个 Socket 的事件处理完之后，IO多路复用程序才会将队列中的下一个 Socket 给事件分派器。文件事件分派器会根据每个 Socket 当前产生的事件，来选择对应的事件处理器来处理。

如果被监听的 Socket 准备好执行accept、read、write、close等操作的时候，跟操作对应的文件事件就会产生，这个时候文件事件处理器就会调用之前关联好的事件处理器来处理这个事件。

**文件事件处理器是单线程模式运行的，但是通过IO多路复用机制监听多个Socket，可以实现高性能的网络通信模型，又可以跟内部其他单线程的模块进行对接，保证了 Redis 内部的线程模型的简单性**。

### 

## 为什么说Redis是单线程

Redis基于Reactor（反应器模式）模式开发了**网络事件处理器**，这个处理器被称为**文件事件处理器**。它的组成结构为4部分：多个套接字（**多个Socket**）、IO多路复用程序（I/O 多路复用模块封装了底层的 select、epoll、avport 以及 kqueue 这些 I/O 多路复用函数）、**文件事件分派器**、事件处理器（命令请求处理器、命令回复处理器、连接应答处理器等）。因为文件**事件分派器队列的消费是单线程**的，所以Redis才叫单线程模型。

它采用IO多路复用机制来**同时监听多个Socket**，根据Socket上的**事件类型来选择对应的事件处理器**来处理这个事件。

多个 Socket 可能并发的产生不同的操作，每个操作对应不同的文件事件，但是IO多路复用程序会监听多个 Socket，会将 Socket 放入一个队列中排队，**每次从队列中取出一个 Socket 给事件分派器**，**事件分派器把 Socket 给对应的事件处理器**。

然后一个 Socket 的事件处理完之后，IO多路复用程序才会将队列中的下一个 Socket 给事件分派器。文件事件分派器会根据每个 Socket 当前产生的事件，来选择对应的事件处理器来处理。

如果被监听的 Socket 准备好执行accept、read、write、close等操作的时候，跟操作对应的文件事件就会产生，这个时候文件事件处理器就会调用之前关联好的事件处理器来处理这个事件。

**文件事件处理器是单线程模式运行的，但是通过IO多路复用机制监听多个Socket，可以实现高性能的网络通信模型，又可以跟内部其他单线程的模块进行对接，保证了 Redis 内部的线程模型的简单性**。

### 为什么 Redis 中要使用 I/O 多路复用这种技术呢？

首先，Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 I/O 多路复用就是为了解决这个问题而出现的。

### I/O 多路复用实现：

I/O 多路复用模块封装了底层的 select、epoll、avport 以及 kqueue 这些I/O 多路复用函数，为上层提供了相同的接口。整个 I/O 多路复用模块抹平了不同平台上 I/O 多路复用函数的差异性，提供了相同的接口。因为 Redis 需要在多个平台上运行，同时为了最大化执行的效率与性能，所以会根据编译平台的不同选择不同的 I/O 多路复用函数作为子模块

通常服务器往往不会只处理一次请求，往往是多个请求，这时候每来一个请求，就会生成一个进程或线程。在这些请求线程或者进程中，大部分都处于等待阶段，只有少部分是接收数据。这样一来，非常耗费资源，而且这些线程或者进程的管理，也是个事儿。于是，有人想到一个办法：我们只用一个线程或者进程来和系统内核打交道，并想办法把每个应用的I/O流状态记录下来，一有响应变及时返回给相应的应用。

select/poll将 每个应用的I/O流状态记录 在消息列表中。每次都要遍历成千上万个消息列表了，才可以定位哪个socket有数据。

而epoll 就不一样了。早期的时候 epoll的实现是一个哈希表，但是后来由于占用空间比较大，改为了红黑树和链表

其中链表中全部为活跃的链接，红黑树中放的是所有事件。两部分各司其职。这样一来，当收到内核的数据时，只需遍历链表中的数据就行了，而注册read事件或者write事件的时候，向红黑树中记录。

结果导致：

- 创建\修改\删除消息效率非常高：O(logN)。
- 获取活跃链接也非常快，因为在一个时间内，大部分是不活跃的链接，活跃的链接是少数，只需要遍历少数活跃的链接就好了

select：将之前传入的fd_set拷贝传出到用户态并返回就绪的文件描述符总数。用户态并不知道是哪些文件描述符处于就绪态，需要遍历来判断。

epoll：epoll_wait只用观察就绪链表中有无数据即可，最后将链表的数据返回给数组并返回就绪的数量。内核将就绪的文件描述符放在传入的数组中，所以只用遍历依次处理即可。这里返回的文件描述符是通过mmap让内核和用户空间共享同一块内存实现传递的，减少了不必要的拷贝。

### 为啥Redis单线程模型也能效率这么高？

**1）纯内存操作**

Redis 将所有数据放在内存中，内存的响应时长大约为 100 纳秒，这是 redis 的 QPS 过万的重要基础。

**2）核心是基于非阻塞的IO多路复用机制**

有了非阻塞 IO 意味着线程在读写 IO 时可以不必再阻塞了，读写可以瞬间完成然后线程可以继续干别的事了。

redis 需要处理多个 IO 请求，同时把每个请求的结果返回给客户端。由于 redis 是单线程模型，同一时间只能处理一个 IO 事件，于是 redis 需要在合适的时间暂停对某个 IO 事件的处理，转而去处理另一个 IO 事件，这就需要用到IO多路复用技术了， 就好比一个管理者，能够管理个socket的IO事件，当选择了哪个socket，就处理哪个socket上的 IO 事件，其他 IO 事件就暂停处理了。

**3）单线程反而避免了多线程的频繁上下文切换带来的性能问题。**（百度多线程上下文切换）

第一，单线程可以简化数据结构和算法的实现。并发数据结构实现不但困难而且开发测试比较麻

第二，单线程避免了线程切换和竞态产生的消耗，对于服务端开发来说，锁和线程切换通常是性能杀手。

单线程的问题：对于每个命令的执行时间是有要求的。如果某个命令执行过长，会造成其他命令的阻塞，所以 redis 适用于那些需要快速执行的场景。

### 分布式锁

如果服务没有宕机，只是业务代码执行耗费的时间比较长，那么守护线程会每3s续一次命，保证锁不会失效。
如果服务宕机了，那么10S后锁失效，其他服务可以竞争到锁，解决了3.0版本存在的问题。

```java
@Component
public class RedisLock {
	@Autowired
	private RedisTemplate<String, Object> redisTemplate;
	private ConcurrentMap<String, String> keyMap = new ConcurrentHashMap<>(16);
	private ConcurrentMap<String, ContinueThread> threadMap = new ConcurrentHashMap<>(16);

	//加锁成功的同时，会得到一个锁签名，根据keySign来释放锁
	public String lock(String key){
		ValueOperations<String, Object> forValue = redisTemplate.opsForValue();
		String keySign = UUID.randomUUID().toString(true);
		//锁超时10s 10s后未释放锁，其他线程可以竞争
		while (!forValue.setIfAbsent(key, keySign, 10, TimeUnit.SECONDS)) {
			//竞争锁失败，暂时让出CPU资源
			Thread.yield();
		}
		//竞争锁成功
		keyMap.put(key, keySign);

		//守护线程续命
		ContinueThread continueThread = new ContinueThread(key, keySign);
		continueThread.setDaemon(true);
		threadMap.put(key, continueThread);
		continueThread.start();
		return keySign;
	}

	//释放锁
	public void unlock(String key, String keySign) {
		String s = keyMap.get(key);
		if (!keySign.equals(s)) {
			//不是我加的锁，不能释放
			return;
		}
		//是我加的锁，可以释放
		redisTemplate.delete(key);
		//续命线程停止
		ContinueThread thread = threadMap.get(key);
		if (thread != null) {
			thread.stopThread();
		}
	}

	//续命线程内部类
	private class ContinueThread extends Thread {
		private boolean stop = false;
		private String key;
		private String keySign;

		public ContinueThread(String key,String keySign) {
			super("Thread-"+UUID.randomUUID().toString(true));
			this.key = key;
			this.keySign = keySign;
		}

		public void stopThread(){
			this.stop = true;
		}

		@Override
		public void run() {
			while (!stop) {
				System.err.println(!isInterrupted());
				try {
					//3s续一次命
					Thread.sleep(10000/3);
				} catch (InterruptedException e) {}
				System.err.println("续命...");
				redisTemplate.opsForValue().set(key, keySign, 10, TimeUnit.SECONDS);
			}
		}
	}
}
```

https://blog.csdn.net/qq_32099833/article/details/103881721

# 操作

#Redis

redis 的高性能。亚毫秒延迟得益于经过优化的数据结构，由于让操作可以在邻近数据存储的地方执行，提高了效率。这种数据结构不仅可以高效地利用内存、降低应用程序的复杂性，还降低了网络开销、带宽消耗量和处理时间。


###Redis 安装

需要安装GCC

错误“centOS6.3 安装redis make报错 zmalloc.h:50:31: 错误：jemalloc/jemalloc.h：没有那个文件或目录” 
解决办法: make MALLOC=libc 代替 make 

Connected to the target VM, address: '127.0.0.1:50142', transport: 'socket'