**zookeeper在分布式集群的作用**

**1，数据发布与订阅（配置中心）**

发布与订阅模型，即所谓的配置中心，顾名思义就是讲发布者将数据发布到zk节点上，共订阅者动态获取数据，实现配置的集中式管理和动态更新。例如，全局的配置信息，服务服务框架的地址列表就非常适合使用。

1. 分布式环境下，配置文件管理和同步是一个常见问题

2. - 一个集群中，所有节点的配置信息是一致的，比如 Hadoop 集群、集群中的数据库配置信息等全局配置
   - 对配置文件修改后，希望能够快速同步到各个节点上。

3. 配置管理可交由 ZooKeeper 实现

4. - 可将配置信息写入 ZooKeeper 上的一个 Znode
   - 各个节点监听这个 Znode
   - 一旦 Znode 中的数据被修改，ZooKeeper 将通知各个节点

**2，统一命名服务(Naming Service)**

在分布式环境中，经常需要对**服务**进行统一命名，假如有一个服务部署了**2两个副**本，直接调用具体的服务肯定有些不合适，因为我们并不清楚哪个服务可以更快的处理我们的请求，这时候我们可以将这三个服务进行统一命名，然后其内部再去负载。这样就可以调用最优的那个服务了。例如Dubbo

常见的是发布者将自己的地址列表写到zookeeper的节点上，然后订阅者可以从固定名称的节点获取地址列表，链接到发布者进行相关通讯。

**3，分布式通知/协调**

这个利用的是zookeeper的watcher注册和异步通知机制，能够很好的实现分布式环境中不同系统间的通知与协调，实现对数据变更的实时处理。

**4，统一集群管理与Master选举**

集群管理，比如在线率，节点上线下线通知这些。Master选举可以使用临时顺序节点来实现。

1. 分布式环境中，**实时掌握**每个节点的状态是必要的，比如我们要知道集群中各机器状态、收集各个机器的运行时状态数据、服务器动态上下线等。

2. 交由 ZooKeeper 实现的方式

3. - 可将节点信息写入 ZooKeeper 上的一个 Znode
   - 监听这个 Znode 可获取它的实时状态变化
   - 典型应用：HBase 中 Master 状态监控和选举。

4. **Master选举**

   在分布式环境中，相同的业务应用分布在不同的机器上，有些业务逻辑（例如一些耗时的计算，网络I/O处理），往往只需要让**整个集群中的某一台机器**进行执行，其余机器可以共享这个结果，这样可以大大减少重复劳动，提高性能，于是这个master选举便是这种场景下的碰到的主要问题。

   利用 **Zookeeper 的强一致性**，能够**很好的保证在分布式高并发情况下节点的创建一定是全局唯一的**，即：同时有多个客户端请求创建 `/currentMaster` 节点，最终一定只有一个客户端请求能够创建成功。Zookeeper 通过这种节点唯一的特性，可以创建一个 Master 节点，其他客户端 Watcher 监控当前 Master 是否存活，一旦 Master 挂了，其他机器再创建这样的一个 Master 节点，用来重新选举。

**5，负载均衡**
 即软件负载均衡。最典型的是消息中间件的生产、消费者负载均衡。

**6，分布式锁**

分布式锁，这个主要得益于zookeeper数据的强一致性，利用的是**临时节点。锁服务分为两类，一个是独占锁，另一个是控制时序**。

独占，是指所有的客户端都来获取这把锁，最终只能有一个获取到。用的是临时节点。

控制时序，所有来获取锁的客户端，都会被安排得到锁，只不过要有个顺序。实际上是某个节点下的临时顺序子节点来实现的。

**7，分布式队列**

一种是FIFO，这个就是使用临时顺序节点实现的，和分布式锁服务控制时序一样。

第二种是等待队列的成员聚齐之后的才同意按序执行。实际上，是在队列的节点里首先创建一个/queue/num节点，并且赋值队列的大小。这样我们可以通过监控队列节点子节点的变动来感知队列是否已满或者条件已经满足执行的需要。这种，应用场景是有条件执行的任务，条件齐备了之后任务才能执行。



zookeeper的节点类型：持久节点（PERSISTENT），临时节点（EPHEMERAL）

持久顺序节点（PERSISTENT_SEQUENTIAL），临时顺序节点（EPHEMERAL_SEQUENTIAL）

Zkclient对zookeeper的listener实现总共有四种：IZkStateListener(监听会话状态，是否进行了超时重连等)，IZkDataListener(监听节点数据的变动)，IZkChildListener(监听子节点的变动)，IZkConnection (监听链接)。

**IZkStateListener**

主要作用是**会话超时**的监控，需要在处理函数里重新注册临时节点。主要方法两个:

handleStateChanged,zookeeper的链接状态改变的时候调用

handleNewSession,与zookeeper的会话超时，导致断开并新连接建立的时候会调用。需要在此方法中实现临时节点的注册。在kafka中主要有以下四个实现:

* **ZKSessionExpireListener**：所属对象为每个消费者，会话超时，会导致消费者进行再平衡
* **SessionExpirationListener**：所属对象Broker的Controller对象，会话超时会导致Crontroller再选举
* **ZkSessionExpireListener**：所属对象是给ZookeeperTopicEventWatcher对象，会话超时事件触发后都会重新将ZkTopicEventListener和"/brokers/topics"的目进行绑定。ZkTopicEventListener负责会监控该目录下的子节点，也即topic的增删。会在创建带topic过滤器的流的时候用到

# **认识zookeeper**

Zookeeper是Apache开源的一个分布式框架，它主要为分布式应用提供协调服务。

ZooKeeper 是用于维护配置信息，命名，提供分布式同步和提供组服务的集中式服务。所有这些类型的服务都以某种形式被分布式应用程序使用。主要**负责存储和管理大家都关心的数据**，一旦这些数据的状态发生变化，Zookeeper就会通知那些注册在Zookeeper上的服务。简单来讲就是**zookeeper=文件系统+通知机制**

###  设计目标

- **简单的数据结构** ：Zookeeper 使得分布式程序能够通过一个共享的树形结构的名字空间来进行相互协调，即Zookeeper 服务器内存中的数据模型由一系列被称为`ZNode`的数据节点组成，**Zookeeper 将全量的数据存储在内存中，以此来提高服务器吞吐、减少延迟的目的**。（但是内存限制了能够存储的容量不太大，此限制也是保持 znode 中存储的数据量较小的进一步原因）
- **可以构建集群** ：Zookeeper 集群通常由一组机器构成，组成 Zookeeper 集群的每台机器都会在内存中维护当前服务器状态，并且每台机器之间都相互通信。
- **顺序访问** ：对于来自客户端的每个更新请求，Zookeeper 都会**分配一个全局唯一的递增编号**，这个编号反映了所有事务操作的先后顺序。
- **高性能** ：Zookeeper 和 Redis 一样全量数据存储在内存中，100% 读请求压测 QPS 12-13W

## ZooKeeper 语义保证

1. **最终一致性：**client不论连接到哪个Server，展示给它都是同一个视图，这是zookeeper最重要的性能。
2. **可靠性：**具有简单、健壮、良好的性能，如果消息m被到一台服务器接受，那么它将被所有的服务器接受。
3. **实时性：**Zookeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。
4. **等待无关（wait-free）：**慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。
5. **原子性：**更新只能成功或者失败，没有中间状态。
6. **顺序性：**包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。

### ZooKeeper工作机制

ZooKeeper 从设计模式角度来理解：就是一个基于**观察者模式**设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生变化，ZK 就将负责通知已经在 ZK 上注册的那些观察者做出相应的反应，从而实现集群中类似 Master/Slave 管理模式。

## Zookeeper的节点

Zookeeper的数据结构与**Unix文件系统**很类似，整体上可以看作是**一棵树**，与Unix文件系统不同的是**Zookeeper的每个节点都可以存放数据**，**每个节点称作一个ZNode**，默认存储**`1MB`的数据，每个ZNode都可以通过其路径唯一标识**。

![zookeeper-node](/Users/yangyibo/Documents/技能点/整理知识点图/技术/zookeeper-node.png)

### ZNode类型

- **持久化目录节点 Persistent**：客户端与Zookeeper**断开连接后，该节点依旧存在**，一旦被创建，便不会意外丢失，即使服务器全部重启也依然存在。每个 Persist 节点即可包含数据，也可包含子节点。
- **临时目录节点 Ephemeral**：客户端与Zookeeper**断开连接后，该节点被删除**，在创建它的客户端与服务器间的 Session 结束时自动被删除。服务器重启会导致 Session 结束，因此 Ephemeral 类型的 znode 此时也会自动删除。
- **Sequence 顺序节点节点：** ZooKeeper还允许用户为每个节点添加一个特殊的属性,SEQUENTIAL 也被称为顺序节点，例如“**Ephemeral-Sequence** 和  **Persistent-Sequence**”，**创建出的节点名在指定的名称之后带有10位10进制数的序号**。多个客户端创建同一名称的节点时，都能创建成功，只是序号不同。
- **Non-sequence 节点：** **多个客户**端同时创建同一 Non-sequence 节点时，**只有一个可创建成功，其它匀失败**。并且创建出的**节点名称与创建时指定的节点名完全一样**。

说明：创建ZNode时**设置顺序标识**，ZNode名称后会附加一个值，**顺序号是一个单调递增的计数器，由父节点维护**。

### stat结构体，

Zookeeper 的每个 ZNode 上都会存储数据，Zookeeper 都会为其维护一个叫作 **Stat** 的数据结构，其中包含数据更改、ACL更改的版本号、时间戳等。

- **czxid**-创建节点的事务 **zxid（时间戳）**：每次修改 ZooKeeper 状态都会收到一个 **zxid 形式的时间戳，也就是 ZooKeeper 事务 ID**。事务 ID 是 **ZooKeeper 中所有修改总的次序**。每个修改都有唯一的 zxid，如果 zxid1 小于 zxid2，那么 zxid1 在 zxid2 之前发生。
- **mzxid**：znode **最后更新**的事务 zxid
- **pZxid**：znode 最后更新的**子节点 zxid**
- **ctime** ：znode **被创建的**毫秒数(从 1970 年开始)
- **mtime**：znode **最后修改**的毫秒数(从 1970 年开始)
- **cversion**：znode 子节点**变化号**，znode **子节点修改次数**
- **data**version：znode **数据变化号**
- **acl**Version：znode **访问控制列表**的变化号
- **ephemeral**Owner：如果是临时节点，这个是 znode **拥有者的 session id**。如果不是临时节点则是 0
- **dataLength**：znode 的**数据长度**
- **numChildren**：znode **子节点数量**

#### ZNode特点：

1. 每个子目录项如NameService都被称作为znode，这个znode是被它所在的路径唯一标识，如Server1这个znode的标识为/NameService/Server1。
2. znode可以有子节点目录，并且每个znode可以存储数据，默认存储`1MB`的数据。注意EPHEMERAL（临时的）类型的目录节点不能有子节点目录。
3. znode是有版本的（version），每个znode中存储的数据可以有多个版本，也就是一个访问路径中可以存储多份数据，version号自动增加。  
4. znode可以被监控，包括这个目录节点中存储的数据的修改，子节点目录的变化等，一旦变化可以通知设置监控的客户端，这个是Zookeeper的核心特性，Zookeeper的很多功能都是基于这个特性实现的。
5. ZXID：每次对Zookeeper的状态的改变都会产生一个zxid（ZooKeeper Transaction Id），zxid是全局有序的，如果zxid1小于zxid2，则zxid1在zxid2之前发生。

#### 会话（Session）

Session 指的是 ZooKeeper 服务器与客户端会话。

**在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的一个 TCP 长连接**。客户端启动的时候，首先会与服务器建立一个 TCP 连接，从第一次连接建立开始，客户端会话的生命周期也开始了。通过这个连接，客户端能够**通过心跳检测**与服务器保持**有效**的会话，也能够向 Zookeeper 服务器**发送请求并接受响应**，同时还能够通过**该连接接收来自服务器的 Watch 事件**通知。

Session 作为会话实体，用来代表客户端会话，其包括 4 个属性：

- **SessionID**，用来全局唯一识别会话；
- **TimeOut**，会话超时事件。客户端在创造 Session 实例的时候，会设置一个会话超时的时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在 sessionTimeout 规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效；
- **TickTime**，下次会话超时时间点；
- **isClosing**，当服务端如果检测到会话超时失效了，会通过设置这个属性将会话关闭。

#### 权限控制 ACL

Zookeeper 采用 ACL（Access Control Lists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。Zookeeper 定义了如下 5 种权限：

- **CREATE**: 创建子节点的权限
- **READ**: 获取节点数据和子节点列表的权限
- **WRITE**: 更新节点数据的权限
- **DELETE**: 删除子节点的权限
- **ADMIN**: 设置节点ACL的权限

其中尤其需要注意的是，CREATE 和 DELETE 这两种权限都是针对子节点的权限控制。


## 一致性

#### 版本控制

有了 Watcher 机制，就可以实现分布式协调/通知了，假设有这样的场景，两个客户端同时对 B 进行写入操作，这两个客户端就会存在竞争关系，通常需要对 B 进行**加锁**操作，ZK 通过 version 版本号来控制实现**乐观锁**中的“**写入校验**”机制。

ZNode 会维护一个叫作 **Stat** 的数据结构，Stat 中记录了这个 ZNode 的三个数据版本，分别是 **version**（当前ZNode的版本）、**cversion**（当前ZNode 子节点的版本）和 **aversion**（当前ZNode的ACL版本）。

## 事件监听（Watcher）

**One-time trigger（一次性触发）**

Zookeeper 允许用户在指定节点上注册一些 **Watcher**，当 Znode 发生变化时，将**触发并删除**一个 watch。监视事件可以理解为**一次性的触发**器。当 watch 被触发时客户端会收到一个数据包，指示 znode 已经被修改。如果客户端和 ZooKeeper 服务器之间的连接中断，客户端将收到本地通知。**该机制是 Zookeeper 实现分布式协调服务的重要特性**

3.6.0中的新增功能：客户端还可以在 znode 上设置永久性的递归监视，这些监视在触发时不会删除，并且会以递归方式触发已注册 znode 以及所有子 znode 的更改。

**Sent to the client（发送至客户端）**

监视事件是通过 socket **异步发送至监视者**的，Zookeeper 本身提供了**保序性**(ordering guarantee)：即**客户端只有首先看到了监视事件**后，才会**感知到它所设置监视的 znode 发生了变化**。网络延迟或者其他因素可能导致不同的客户端在不同的时刻感知某一监视事件，但是**不同的客户端所看到的一切具有一致的顺序**。

**The data for which the watch was set（被设置 watch 的数据）**

znode 节点本身具有不同的改变方式，可能改变的是znode也可能改变的是子节点。**`getData()` 和 `exists()` 设置数据监视，`getChildren()` 设置子节点监视**。或者，你也可以想象 Zookeeper 设置的不同监视返回不同的数据，**`getData()` 和 `exists()`返回 znode 节点的相关信息**，而 `g**etChildren()` 返回子节点列**表。

因此， `setData()` 会触发设置在某一节点上所设置的数据监视(假定数据设置成功)，而一次成功的 `create()` 操作则会触发当前节点上所设置的**数据监视**以及**父节点的子节点**监视。一次成功的 `delete()` 操作将会触发**当前节点的数据监视和子节点监视事件，同时也会触**发该节点父节点的 `child watch`**。

**exists()丢失监听**

Zookeeper 中的监视是轻量级的，容易设置、维护和分发。当客户端与 Zookeeper 服务器端失去联系时，客户端并不会收到监视事件的通知，只有当客户端重新连接后，若在必要的情况下，以前注册的监视会重新被注册并触发，对于开发人员来说这通常是透明的。只有一种情况会导致监视事件的丢失，即：通过 **`exists()`** 设置了某个 znode 节点的监视，但是如果某个客户端在此 znode 节点被创建和删除的时间间隔内与 zookeeper 服务器失去了联系，该客户端即使稍后重新连接 zookeepe r服务器后也得不到事件通知。

### 监听器的原理

Watcher 机制包括三个角色：客户端线程、客户端的 WatchManager 以及 ZooKeeper 服务器。Watcher 机制就是这三个角色之间的交互，整个过程分为注册、存储和通知三个步骤：

1. 客户端向 ZooKeeper 服务器注册一个 Watcher 监听；
2. 把这个监听信息存储到客户端的 WatchManager 中；
3. 当 ZooKeeper 中的节点发生变化时，会通知客户端，客户端会调用相应 Watcher 对象中的回调方法。

过程如下：

![zookeeper监听](/Users/yangyibo/Documents/技能点/整理知识点图/技术/zookeeper监听.png)

1. 客户端创建一个Main()线程
2. 在Main()线程中**创建两个线程**，一个负责**网络连接通信（connect），一个负责监听（listener）**
3. 通过connect线程将注册的监听事件发送给Zookeeper
4. 将注册的**监听事件添加到Zookeeper的注册监听器列表中**
5. Zookeeper**监听到有数据或路径发生变化时，把这条消息发送给Listener线程**
6. **Listener线程内部调用process()方法**

## Zookeeper集群

Zookeeper集群虽然没有指定Master和Slave。但是，在Zookeeper工作时，会通过**内部选举机制产生一个Leader节点，其他节点为Follower或者是Observer**。

![zookeeper集群](/Users/yangyibo/Documents/技能点/整理知识点图/技术/zookeeper集群.png)

## zookeeper 角色

Zookeeper集群是一个基于主从复制的高可用集群，每个服务器承担如下三种角色中的一种

* **Leader：** 一个Zookeeper集群同一时间只会有一个实际工作的Leader，它会发起并维护与各Follwer及Observer间的心跳。所有的写操作必须要通过Leader完成再由Leader将写操作广播给其它服务器。
* **Follower：** 一个Zookeeper集群可能同时存在多个Follower，它会响应Leader的心跳。Follower可直接处理并返回客户端的读请求，同时会将写请求转发给Leader处理，并且负责在Leader处理写请求时对请求进行投票。
* **Observer：** 角色与Follower类似，但是无投票权

##### server 状态

- LOOKING：寻找Leader状态
- LEADING：领导者状态，表明当前服务器角色是 Leader
- FOLLOWING：跟随者状态，表明当前服务器角色是 Follower
- OBSERVING：观察者状态，表明当前服务器角色是 Observer

被声明为**Observer**的节点，**不参与选举过程**，也不参与写操作的**”过半写成功**“策略。

**过半写成功策略**：Leader节点接收到写请求后，这个Leader会**将写请求广播给各个server**，各个server会将该写请求加入待写队列，并向Leader发送成功信息，当**Leader收到一半以上的成功**消息后，说明**该写操作可以执行**。Leader会向各个server发送提交消息，各个server收到消息后开始写。

**Follower和Observer只提供数据的读操作**，当他们**接收的写请求时，会将该请求转发给Leader节**点。

**集群中只要有半数以上的节点存活，Zookeeper集群就能正常服务**。因此Zookeeper集群适合安装**奇数台**机器。

### 选举机制

（1）服务器 1 启动，发起一次选举。服务器 1 投自己一票。此时服务器 1 票数一票，不够半数以上（3 票），选举无法完成，服务器 1 状态保持为 **LOOKING**；

（2）服务器 2 启动，再发起一次选举。服务器 1 和 2 分别投自己一票并交换选票信息：此时**服务器 1 发现服务器 2 的 ID 比自己目前投票推举的（服务器 1）大，更改选票为推举服务器 2**。此时服务器 1 票数 0 票，服务器 2 票数 2 票，没有半数以上结果，选举无法完成，服务器 1，2 状态保持 LOOKING；(**looking状态时，投票选择 ID 最大的服务器**）

（3）服务器 3 启动，发起一次选举。此时**服务器 1 和 2 都会更改选票为服务器 3**。此次投票结果：服务器 1 为 0 票，服务器 2 为 0 票，服务器 3 为 3 票。此时服务器 3 的票数已经超过半数，**服务器 3 当选 Leader**。服务器 1，2 更改状态为 **FOLLOWING**，服务器 3 更改状态为 **LEADING**；

（4）服务器 4 启动，发起一次选举。此时服务器 1，2，3 已经**不是 LOOKING 状态，不会更改选票信息**。交换选票信息结果：服务器 3 为 3 票，服务器 4 为 1 票。此时服务器 4服从多数，**更改选票信息为服务器 3**，并更改状态为 FOLLOWING；

（5）服务器 5 启动，同 4 一样当小弟。





- ZooKeeper 本身就是一个分布式程序（只要半数以上节点存活，ZooKeeper 就能正常服务）。

- 为了保证高可用，最好是以集群形态来部署 ZooKeeper，这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的。

- **ZooKeeper 将数据保存在内存中，这也就保证了高吞吐量和低延迟**（但是内存限制了能够存储的容量不太大，此限制也是保持 znode 中存储的数据量较小的进一步原因）。

- **ZooKeeper 是高性能的。在“读”多于“写”的应用程序中尤其的高性能，因为“写”会导致所有的服务器间同步状态。**（“读”多于“写”是协调服务的典型场景。）

- ZooKeeper 底层其实只提供了两个功能：

- - 管理（存储、读取）用户程序提交的数据
  - 为用户程序提交数据节点监听服务